{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5897a330",
   "metadata": {},
   "source": [
    "---\n",
    "title: Concept Similarity\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05541c4b",
   "metadata": {},
   "source": [
    "Our second hypothesis tests the effect of degree of misunderstanding on the magnitude of effort. \n",
    "\n",
    "We operationalize degree of misunderstanding as a conceptual similarity between target concept and answer offered by a guesser. To have a reproducible measure of conceptual similarity, we use the ConceptNet Numberbatch embeddings (REF). Alongside, in online anonymous rating study, we have collected data from XX people (XX English, XX Dutch) who were asked to rate the similarity between each pair of words. We then compare the 'perceived similarity' with cosine similarity computed from ConceptNet embeddings, to validate the use of ConceptNet embeddings as a measure of conceptual similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75022ba",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Code to load packages and prepare environment\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pingouin\n",
    "\n",
    "curfolder = os.getcwd()\n",
    "rawdata = curfolder + '\\\\..\\\\00_RAWDATA\\\\'\n",
    "answerfiles = glob.glob(rawdata + '*\\\\*.csv', recursive=True)\n",
    "datafolder = curfolder + '\\\\data\\\\'\n",
    "\n",
    "# load all files that have '_1_results' in the name \n",
    "answerfiles_1 = [f for f in answerfiles if '_1_results' in f]\n",
    "# loop over list and add it into one big df\n",
    "df_all1 = pd.DataFrame()\n",
    "for file in answerfiles_1:\n",
    "    df = pd.read_csv(file)\n",
    "    df_all1 = pd.concat([df_all1, df], ignore_index=True)\n",
    "\n",
    "df_all1['exp'] = 1 \n",
    "\n",
    "# load all files that have '_2_results' in the name\n",
    "answerfiles_2 = [f for f in answerfiles if '_2_results' in f]\n",
    "# loop over list and add it into one big df\n",
    "df_all2 = pd.DataFrame()\n",
    "for file in answerfiles_2:\n",
    "    df = pd.read_csv(file)\n",
    "    df_all2 = pd.concat([df_all2, df], ignore_index=True)\n",
    "\n",
    "df_all2['exp'] = 2\n",
    "\n",
    "# merge dfs\n",
    "df_all = pd.concat([df_all1, df_all2], ignore_index=True)\n",
    "\n",
    "# keep only columns word and answer\n",
    "df = df_all[['word', 'answer', 'exp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a517d",
   "metadata": {},
   "source": [
    "First we need to do some data-wrangling to get all in the right format for the embedding extraction and comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c1dd9a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Code to clean the data\"\n",
    "\n",
    "# concept list\n",
    "df_concepts = pd.read_excel(rawdata + '/conceptlist_info.xlsx')\n",
    "\n",
    "# in df_concepts, keep only English and Dutch\n",
    "df_concepts = df_concepts[['English', 'Dutch']]\n",
    "\n",
    "# rename Dutch to word\n",
    "df_concepts = df_concepts.rename(columns={'Dutch': 'word'})\n",
    "\n",
    "# merge df and df_concepts on word\n",
    "df = pd.merge(df, df_concepts, on='word', how='left')\n",
    "\n",
    "# show rows where English is NaN\n",
    "df[df['English'].isnull()]\n",
    "\n",
    "# add translations manually for each (these are practice trials)\n",
    "df.loc[df['word'] == 'bloem', 'English'] = 'flower'\n",
    "df.loc[df['word'] == 'dansen', 'English'] = 'to dance'\n",
    "df.loc[df['word'] == 'auto', 'English'] = 'car'\n",
    "df.loc[df['word'] == 'olifant', 'English'] = 'elephant'\n",
    "df.loc[df['word'] == 'comfortabel', 'English'] = 'comfortable'\n",
    "df.loc[df['word'] == 'bal', 'English'] = 'ball'\n",
    "df.loc[df['word'] == 'haasten', 'English'] = 'to hurry'\n",
    "df.loc[df['word'] == 'gek', 'English'] = 'crazy'\n",
    "df.loc[df['word'] == 'snijden', 'English'] = 'to cut'\n",
    "df.loc[df['word'] == 'koken', 'English'] = 'to cook'\n",
    "df.loc[df['word'] == 'juichen', 'English'] = 'to cheer'\n",
    "df.loc[df['word'] == 'zingen', 'English'] = 'to sing'\n",
    "df.loc[df['word'] == 'glimlach', 'English'] = 'smile'\n",
    "df.loc[df['word'] == 'klok', 'English'] = 'clock'\n",
    "df.loc[df['word'] == 'fiets', 'English'] = 'bicycle'\n",
    "df.loc[df['word'] == 'vliegtuig', 'English'] = 'airplane'\n",
    "df.loc[df['word'] == 'geheim', 'English'] = 'secret'\n",
    "df.loc[df['word'] == 'telefoon', 'English'] = 'telephone'\n",
    "df.loc[df['word'] == 'zwaaien', 'English'] = 'to wave'\n",
    "df.loc[df['word'] == 'sneeuw', 'English'] = 'snow'\n",
    "\n",
    "# make a list of English answers\n",
    "answers_en = ['party', 'to cheer', 'tasty', 'to shoot', 'to breathe', 'zombie', 'bee', 'sea', 'dirty', 'tasty', 'car', 'to eat', 'to eat', 'to blow', 'hose', 'hose', 'to annoy', 'to make noise', 'to make noise', 'to run away', 'elephant', 'to cry', 'cold', 'outfit', 'silence', 'to ski', 'wrong', 'to play basketball', 'to search', 'disturbed', 'to run', 'to lick', 'to lift', 'lightning', 'to think', 'to jump', 'to fall', 'to write', 'to dance', 'shoulder height', 'horn', 'dirty', 'boring', 'to drink', 'strong', 'elderly', 'to mix', 'fish', 'fish', 'dirty', 'wrong', 'smart', 'to box', 'to box', 'dog', 'to catch', 'to cheer', 'to sing', 'pregnant', 'hair', 'to shower', 'pain', 'burnt', 'hot', 'I', 'to chew', 'bird', 'airplane', 'to fly', 'to think', 'to choose', 'to doubt', 'graffiti', 'fireworks', 'bomb', 'to smile', 'to laugh', 'smile', 'clock', 'to wonder', 'height', 'big', 'height', 'space', 'to misjudge', 'to wait', 'satisfied', 'happy', 'fish', 'to smell', 'wind', 'pain', 'to burn', 'hot', 'to cycle', 'to fly', 'airplane', 'bird', 'to crawl', 'to drink', 'waterfall', 'water', 'fire', 'top', 'good', 'to hear', 'to point', 'distance', 'there', 'to whisper', 'quiet', 'to be silent', 'telephone', 'to blow', 'to distribute', 'to give', 'cat', 'to laugh', 'tasty', 'to eat', 'yummy', 'to sleep', 'mountain', 'dirty', 'to vomit', 'to be disgusted', 'to greet', 'hello', 'goodbye', 'to smell', 'nose', 'odor', 'to fly', 'fireworks', 'to blow', 'to cut', 'pain', 'hot', 'to slurp', 'to throw', 'to fall', 'to fall', 'whistle', 'heartbeat', 'mouse', 'to hit', 'to catch', 'to grab', 'to throw', 'to fall', 'to shoot', 'circus', 'trunk', 'to fall', 'to fight', 'pain', 'to push open', 'to growl', 'to cut', 'to eat', 'knife', 'to slurp', 'to drink', 'drink', 'to eat', 'delicious', 'tasty', 'to cough', 'sick', 'to cry', 'to cry']\n",
    "\n",
    "# replace skien with skiën in the df\n",
    "df['answer'] = df['answer'].str.replace('skien', 'skiën')\n",
    "\n",
    "# get rid of English 'to beat'\n",
    "df_final = df[df['English'] != 'to beat']\n",
    "# and to weep\n",
    "df_final = df[df['English'] != 'to weep']\n",
    "\n",
    "# add those to df as answers_en\n",
    "df['answer_en'] = answers_en\n",
    "\n",
    "# make a list of English targets\n",
    "meanings_en = list(df['English'])\n",
    "# Dutch targets\n",
    "meanings_nl = list(df['word'])\n",
    "# Dutch answers\n",
    "answers_nl = list(df['answer'])\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b48b06",
   "metadata": {},
   "source": [
    "Now we will load in ConceptNet numberbatch (version XX) and compute cosine similarity for each pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717de7c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Functions for calculating cosine similarity\"\n",
    "\n",
    "# Load embeddings from a file\n",
    "def load_embeddings(file_path):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "# Cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b9de9",
   "metadata": {},
   "source": [
    "We will use multilingual numberbatch to extract words in the original language of experiment - Dutch. While English has better representation in ConceptNet, the English numberbatch does not make distinction between nouns and verbs (so 'a drink' and 'to drink' have common representation - drink). Because this is important distinction for us, we opt for Dutch embeddings to avoid this problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f9c6d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Code to load in batch with embeddings\"\n",
    "\n",
    "# load embeddings\n",
    "embeddings = load_embeddings('numberbatch\\\\numberbatch.txt') # downloaded from https://github.com/commonsense/conceptnet-numberbatch?tab=readme-ov-file\n",
    "#embeddings_en = load_embeddings('numberbatch-en.txt') # downloaded from https://github.com/commonsense/conceptnet-numberbatch?tab=readme-ov-file\n",
    "\n",
    "# this is how words are represented\n",
    "vec_nl = embeddings.get('/c/nl/skiën')\n",
    "print(vec_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d149872",
   "metadata": {},
   "source": [
    "Now we take the list of target-answer pairs, transform them into embedding format and perform cosine similarity.\n",
    "\n",
    "There will probably be some answers that will not be represented in the numberbatch (e.g., if the answer has more than one word). So we will need to think about how to handle these.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea801a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Code XXX\"\n",
    "\n",
    "# get the embeddings for the words in the list meanings_en\n",
    "word_embeddings_t = {}\n",
    "for word in meanings_nl:\n",
    "    word_embed = '/c/nl/' + word\n",
    "    if word_embed in embeddings:\n",
    "        word_embeddings_t[word] = embeddings[word_embed]\n",
    "\n",
    "# get the embeddings for the words in the list answers_en\n",
    "word_embeddings_ans = {}\n",
    "for word in answers_nl:\n",
    "    word_embed = '/c/nl/' + word\n",
    "    if word_embed in embeddings:\n",
    "        word_embeddings_ans[word] = embeddings[word_embed]\n",
    "\n",
    "# calculate the similarity between the first word in the list meanings_en and first word in answers_en, second word in meanings_en and second word in answers_en, etc.\n",
    "cosine_similarities = []\n",
    "\n",
    "for i in range(len(meanings_nl)):\n",
    "    word1 = meanings_nl[i]\n",
    "    word2 = answers_nl[i]\n",
    "    vec1 = word_embeddings_t.get(word1)\n",
    "    vec2 = word_embeddings_ans.get(word2)\n",
    "    if vec1 is not None and vec2 is not None:\n",
    "        cosine_sim = cosine_similarity(vec1, vec2)\n",
    "        cosine_similarities.append(cosine_sim)\n",
    "    else:\n",
    "        # print which concepts could not be found\n",
    "        if vec1 is None:\n",
    "            print(f\"Concept not found: {word1}\")\n",
    "        if vec2 is None:\n",
    "            print(f\"Concept not found: {word2}\")\n",
    "        cosine_similarities.append(None)\n",
    "\n",
    "df['cosine_similarity'] = cosine_similarities\n",
    "df_final.to_csv(datafolder + 'conceptnet_clean.csv', index=False)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b452e4",
   "metadata": {},
   "source": [
    "# Comparing cosine similarity against perceived similarity\n",
    "\n",
    "To validate the use of ConceptNet embeddings as a measure of conceptual similarity, we compare the cosine similarity computed from ConceptNet embeddings with the 'perceived similarity' ratings collected in the online anonymous rating study. We use Pearson correlation to compare the two measures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5675db0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# load in excel similarity_en_survey\n",
    "df_survey = pd.read_excel(datafolder + '\\\\similarity_en_survey.xlsx')\n",
    "\n",
    "# get rid of Timestamp column\n",
    "df_survey = df_survey.drop(columns='Timestamp')\n",
    "\n",
    "# for each column, calculate the mean and save it to a df\n",
    "df_survey_means = pd.DataFrame(df_survey.mean()).reset_index()\n",
    "\n",
    "# separate the index, the first part is English, the second part is the answer_en\n",
    "df_survey_means['English'] = df_survey_means['index'].str.split(' - ').str[0]\n",
    "df_survey_means['answer_en'] = df_survey_means['index'].str.split(' - ').str[1]\n",
    "\n",
    "# get rid of the index column\n",
    "df_survey_means = df_survey_means.drop(columns='index')\n",
    "\n",
    "# rename the column 0 to mean_similarity\n",
    "df_survey_means = df_survey_means.rename(columns={0: 'mean_similarity'})\n",
    "\n",
    "# change to lightning into lightning\n",
    "df_survey_means.loc[df_survey_means['answer_en'] == 'to lightning', 'answer_en'] = 'lightning'\n",
    "# phone to telephone\n",
    "df_survey_means.loc[df_survey_means['answer_en'] == 'phone', 'answer_en'] = 'telephone'\n",
    "# scent to odor\n",
    "df_survey_means.loc[df_survey_means['answer_en'] == 'scent', 'answer_en'] = 'odor'\n",
    "\n",
    "df_survey_means.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9be60",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# merge df_survey_means with df on English and answer_en\n",
    "df_final = pd.merge(df, df_survey_means, on=['English', 'answer_en'], how='left')\n",
    "\n",
    "# get rid of English 'to beat'\n",
    "df_final = df_final[df_final['English'] != 'beat']\n",
    "# and to weep\n",
    "df_final = df_final[df_final['English'] != 'weep']\n",
    "\n",
    "# show me the rows where mean_similarity is NaN\n",
    "df_final[df_final['mean_similarity'].isnull()]\n",
    "\n",
    "# mean_similarity of row where English is sharp and answer_en is pain is 4.0 (don't know why it's NaN)\n",
    "df_final.loc[(df_final['English'] == 'sharp') & (df_final['answer_en'] == 'pain'), 'mean_similarity'] = 4.0\n",
    "\n",
    "# save it\n",
    "df_final.to_csv(datafolder + '/df_final_conceptnet.csv', index=False)\n",
    "\n",
    "df_final.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a9d696",
   "metadata": {},
   "source": [
    "Now we can finally run correlation, using `pingouin` package that offers also Bayes Factor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ee6c2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# get rid of all lines where mean_similarity is 10.0\n",
    "df_corr = df_final[df_final['mean_similarity'] != 10.0]\n",
    "\n",
    "feature1 = \"cosine_similarity\"\n",
    "feature2 = \"mean_similarity\"\n",
    "\n",
    "# create a sub-dataframe with the selected features, dropping missing values\n",
    "subdf = df_corr[[feature1, feature2]].dropna()\n",
    "\n",
    "# compute the correlation coefficient, with Bayes factor\n",
    "corr_with_bf = pingouin.pairwise_corr(subdf, columns=['cosine_similarity', 'mean_similarity'], method='pearson', alternative='two-sided')\n",
    "print(corr_with_bf)\n",
    "\n",
    "# create a joint plot with scatter and marginal histograms\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# scatter plot with histograms\n",
    "g = sns.jointplot(x=subdf[feature1], y=subdf[feature2], kind='reg', height=8,\n",
    "                  scatter_kws={'s': 50, 'alpha': 0.7}, marginal_kws=dict(bins=20, fill=True))\n",
    "\n",
    "g.fig.subplots_adjust(top=0.93)  # Adjust the title position\n",
    "\n",
    "# show plot\n",
    "plt.show()\n",
    "\n",
    "# save with high dpi\n",
    "plot_name = f\"{feature1}_vs_{feature2}_jointplot.png\"\n",
    "g.savefig(plot_name, dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERT",
   "language": "python",
   "name": "bert"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
