{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a13c435",
   "metadata": {},
   "source": [
    "# Processing I: from XDF to raw files\n",
    "\n",
    "As described in the preregistration of methods (@REF), the data has been collected using LabStreamLayer, allowing for recording of precisely synchronized streams. These streams include:\n",
    "- MicStream (16kHz)\n",
    "- WebcamFrameStream (ca. 60 Hz)\n",
    "- MarkerStream (sent from custom buttonbox)\n",
    "- BalanceBoardStream (500 Hz)\n",
    "\n",
    "LSL outputs single .xdf file that contains all the data streams. This script serves for extracting the streams and creating raw files for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf23534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kadava\\AppData\\Local\\anaconda3\\envs\\TSPROCESS\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_1', '0_2']\n",
      "['e:\\\\FLESH_ContinuousBodilyEffort\\\\01_XDF_processing\\\\data\\\\\\\\raw_data\\\\0_1\\\\session_S001.xdf', 'e:\\\\FLESH_ContinuousBodilyEffort\\\\01_XDF_processing\\\\data\\\\\\\\raw_data\\\\0_2\\\\session_S002.xdf']\n",
      "['e:\\\\FLESH_ContinuousBodilyEffort\\\\01_XDF_processing\\\\data\\\\\\\\raw_data\\\\0_1\\\\0_1_results.csv', 'e:\\\\FLESH_ContinuousBodilyEffort\\\\01_XDF_processing\\\\data\\\\\\\\raw_data\\\\0_2\\\\0_2_results.csv']\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "\n",
    "import os\n",
    "import pyxdf\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wave, struct, math, random\n",
    "from scipy.io import wavfile\n",
    "import noisereduce as nr\n",
    "import json\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "\n",
    "#from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip #this is the video clipping function\n",
    "#from moviepy.video.io.VideoFileClip import VideoFileClip #alternative for snipping video\n",
    "#from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip\n",
    "\n",
    "# set folders\n",
    "curfolder = os.getcwd()\n",
    "datafolder = curfolder+'\\\\data\\\\'\n",
    "errorlogs = datafolder+'\\\\error_logs\\\\'\n",
    "experiment_to_process = '\\\\raw_data\\\\'\n",
    "outputfolder = datafolder+'\\\\Data_processed\\\\CsvDataTS_raw\\\\' # outputfolder raw\n",
    "trialfolder = datafolder+'\\\\Data_processed\\\\Data_trials\\\\' # outputfolder trialbased\n",
    "targetfolder = datafolder+experiment_to_process # this is where raw data is stored\n",
    "\n",
    "# map all the folders in the target folder\n",
    "datafolders = glob.glob(targetfolder+'*\\\\')\n",
    "\n",
    "# extract the folder IDs\n",
    "datafolders_id = [x.split('\\\\')[-2] for x in datafolders]\n",
    "\n",
    "# print(curfolder)\n",
    "# print(targetfolder)\n",
    "print(datafolders_id)\n",
    "\n",
    "# identify all xdf files and all the associated triallist info\n",
    "xdffiles = []\n",
    "trialdatas = []\n",
    "\n",
    "for i in datafolders_id:\n",
    "    file = glob.glob(targetfolder+i+'\\\\*.xdf')\n",
    "    trialfile = targetfolder+i+'\\\\'+i+'_results'+'.csv'\n",
    "    trialdatas.append(trialfile)\n",
    "    xdffiles.extend(file)\n",
    "\n",
    "# these are the xdf files we need to process\n",
    "print(xdffiles)\n",
    "print(trialdatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7783689",
   "metadata": {},
   "source": [
    "# Extracting streams from XDF file\n",
    "\n",
    "Using `pyxdf` package, we can extract the streams from the XDF file.\n",
    "\n",
    "First, we extract streams for the whole session. Then, we cut these streams into trial-sized chunks, based on the marker stream that indicates the start of each trial. Moreover, we connect the trial with information from the PsychoPy log file, which includes metadata about the trial (i.e., concept, correction number, etc.)\n",
    "\n",
    "(Note that this code takes some time to execute.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32558e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio write function\n",
    "def to_audio(fileloc, timeseries, samplerate = 16000, channels = 1):\n",
    "    if timeseriestype == 'Mic': \n",
    "        obj = wave.open(fileloc,'w')\n",
    "        obj.setnchannels(channels) # mono\n",
    "        obj.setsampwidth(2)\n",
    "        obj.setframerate(float(samplerate))\n",
    "        for i in timeseries:\n",
    "            data = struct.pack('<h', int(i[0]))\n",
    "            obj.writeframesraw( data )\n",
    "        obj.close()\n",
    "\n",
    "# function to retrieve closest value\n",
    "def find_closest_value_and_retrieve(df, target_number, target_column, retrieve_column):\n",
    "    # get the absolute differences between a value in column and the target number\n",
    "    differences = abs(df[target_column] - target_number)\n",
    "    \n",
    "    # find the index of the minimum difference\n",
    "    min_difference_index = differences.idxmin()\n",
    "    \n",
    "    # retrieve the closest value in the target column\n",
    "    closest_value = df.loc[min_difference_index, target_column]\n",
    "    #print(closest_value)\n",
    "    # retrieve the corresponding value from the column\n",
    "    result_value = df.loc[min_difference_index, retrieve_column]\n",
    "\n",
    "    return result_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba00e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in data from participant: 0_1\n",
      "MyMarkerStream\n",
      "working on stream: MyMarkerStream  with a channel count of 1\n",
      " and a sampling rate of 0\n",
      "done with processing a complete time series and audio data\n",
      "we will now start making trial snipped data\n",
      "MyWebcamFrameStream\n",
      "working on stream: MyWebcamFrameStream  with a channel count of 1\n",
      " and a sampling rate of 500\n",
      "done with processing a complete time series and audio data\n",
      "we will now start making trial snipped data\n",
      "BalanceBoard_stream\n",
      "working on stream: BalanceBoard_stream  with a channel count of 4\n",
      " and a sampling rate of 500\n",
      "done with processing a complete time series and audio data\n",
      "we will now start making trial snipped data\n",
      "Mic\n",
      "working on stream: Mic  with a channel count of 1\n",
      " and a sampling rate of 16000\n",
      "done with processing a complete time series and audio data\n",
      "we will now start making trial snipped data\n"
     ]
    }
   ],
   "source": [
    "errorlist = []\n",
    "\n",
    "for dat in datafolders_id:\n",
    "    print('Loading in data from participant: ' + dat)\n",
    "    trialdata = pd.read_csv(targetfolder+dat+'\\\\'+dat+'_results.csv', sep=\",\")\n",
    "    #print(trialdata)\n",
    "    \n",
    "    # get the xdf file\n",
    "    files = glob.glob(targetfolder+dat+'\\\\*.xdf')\n",
    "    streams, header = pyxdf.load_xdf(files[0])   \n",
    "    # we go through each stream and save it as a csv, \n",
    "    # if it's Mic stream, also as a .wav file\n",
    "    for stream in streams:\n",
    "        timeseriestype = stream['info']['name'][0]\n",
    "        print(timeseriestype)\n",
    "        samplerate = round(float(stream['info']['nominal_srate'][0]))\n",
    "        # in the xdf loop over the streams and save it as csv if not yet exists\n",
    "        channelcount = stream['info']['channel_count'][0]\n",
    "        print('working on stream: ' + timeseriestype + '  with a channel count of ' + str(channelcount) +'\\n and a sampling rate of ' + str(samplerate))\n",
    "        timevec = stream['time_stamps']\n",
    "        timeseries = stream['time_series']\n",
    "        matrix_aux = np.vstack([np.transpose(timevec),np.transpose(timeseries)])\n",
    "        matrix = np.transpose(matrix_aux)\n",
    "        df_lab = pd.DataFrame(matrix)\n",
    "        df_lab.to_csv(outputfolder+dat+'_'+timeseriestype+'_nominal_srate'+str(samplerate)+'.csv',index=False)\n",
    "        #for audio data also create a wav file\n",
    "        if timeseriestype == 'Mic':\n",
    "            wavloc = outputfolder+'Audio/'+dat+'_'+timeseriestype+'_nominal_srate'+str(samplerate)+'.wav'\n",
    "            to_audio(wavloc, timeseries)\n",
    "            # load data\n",
    "            rate, data = wavfile.read(wavloc)\n",
    "            # perform noise reduction\n",
    "            reduced_noise = nr.reduce_noise(y=data, sr=rate, n_std_thresh_stationary=1.5,stationary=True)\n",
    "            wavloc2 = outputfolder+'Audio/'+dat+'_'+timeseriestype+'_nominal_srate'+str(samplerate)+'_denoised.wav'\n",
    "            wavfile.write(wavloc2, rate, reduced_noise)\n",
    "\n",
    "        print('done with processing a complete time series and audio data')\n",
    "        print('we will now start making trial snipped data') \n",
    "\n",
    "        # load the MyMarkerStream\n",
    "        markers = pd.read_csv(outputfolder+dat+'_MyMarkerStream_nominal_srate0.csv')\n",
    "        \n",
    "        # cut all timeseries to trial level based on the markers\n",
    "        if timeseriestype != 'MyMarkerStream':\n",
    "            \n",
    "            beginlist = []\n",
    "            endlist = []\n",
    "            timestamps = []\n",
    "            timestamps_2 = []\n",
    "            tpose_starts = []\n",
    "            tpose_ends = []\n",
    "\n",
    "            # iterate over markers and save times of trial starts and ends\n",
    "            for row in markers.iterrows():\n",
    "                # Accessing positional elements explicitly with .iloc\n",
    "                if 'Trial_start' in row[1].iloc[1] or 'Practice trial starts' in row[1].iloc[1]:\n",
    "                    beginlist.append(row[1].iloc[0])\n",
    "                if 'Trial_end' in row[1].iloc[1] or 'Practice trial ends' in row[1].iloc[1]:\n",
    "                    endlist.append(row[1].iloc[0])\n",
    "                if 'Experiment_start' in row[1].iloc[1]:\n",
    "                    timestamps.append(row[1].iloc[0])\n",
    "                if 'New block starts' in row[1].iloc[1]:\n",
    "                    timestamps_2.append(row[1].iloc[0])\n",
    "                if 'Tpose starts' in row[1].iloc[1]:\n",
    "                    tpose_starts.append(row[1].iloc[0])\n",
    "                if 'Tpose ends' in row[1].iloc[1]:\n",
    "                    tpose_ends.append(row[1].iloc[0])\n",
    "                    \n",
    "            # converting coefficient for lsl to psychopy time\n",
    "            exp_start_pp = float(trialdata['exp_start'][0])\n",
    "            block_start_pp = float(trialdata['block_start'][0])\n",
    "            # get to lsl_to_pp coefficient\n",
    "            if timestamps != []:\n",
    "                lsl_to_pp = timestamps[0] - exp_start_pp\n",
    "            else:\n",
    "                lsl_to_pp = timestamps_2[0] - block_start_pp\n",
    "        \n",
    "            # now we can proceed to cutting   \n",
    "            for i in range(len(beginlist)):\n",
    "                # prepare the range of the trial\n",
    "                begin = beginlist[i]\n",
    "                end = endlist[i]\n",
    "                indices = (df_lab.loc[:,0] > begin) & (df_lab.loc[:,0] < end)\n",
    "                beginst = min(df_lab.loc[:,0]) #start time of the timeseries\n",
    "                endst = max(df_lab.loc[:,0])  #end time of the timeseries\n",
    "                subset = df_lab.loc[indices, :]\n",
    "                # convert the beginst to psychopy time\n",
    "                beginst_pp = begin - lsl_to_pp\n",
    "                # now find in trialdata the closest time to the beginst_pp to gather info\n",
    "                # whether it is practice or trial\n",
    "                practice = find_closest_value_and_retrieve(trialdata, beginst_pp, 'trial_start', 'practice')\n",
    "                if practice == 'practice':\n",
    "                    trialtype = 'pr'\n",
    "                else:\n",
    "                    trialtype = 'trial'\n",
    "                \n",
    "                # which participant it is\n",
    "                cycle = find_closest_value_and_retrieve(trialdata, beginst_pp, 'trial_start', 'cycle')\n",
    "                if cycle == 0:\n",
    "                    participant = 'p0'\n",
    "                else:\n",
    "                    participant = 'p1'\n",
    "\n",
    "                # what concept it is\n",
    "                word = find_closest_value_and_retrieve(trialdata, beginst_pp, 'trial_start', 'word')\n",
    "                # modality\n",
    "                modality = find_closest_value_and_retrieve(trialdata, beginst_pp, 'trial_start', 'modality')\n",
    "                # correction, if applicable\n",
    "                correction_info = find_closest_value_and_retrieve(trialdata, beginst_pp, 'trial_start', 'correction')\n",
    "                if correction_info == 0:\n",
    "                    correction = '_c0'\n",
    "                elif correction_info == 1:\n",
    "                    correction = '_c1'\n",
    "                elif correction_info == 2:\n",
    "                    correction = '_c2'\n",
    "                else:\n",
    "                    correction = ''\n",
    "                \n",
    "                # continue saving\n",
    "                if(len(subset.axes[0])<2):\n",
    "                    errorlist.append(dat + \" for \"+ timeseriestype + \" for trial \" + str(i) + 'NO DATA WITHIN RANGE...')\n",
    "                if(len(subset.axes[0])>2):\n",
    "                     # save subset to csv\n",
    "                      subset.to_csv(trialfolder+dat+'_'+trialtype+'_'+ str(i) +'_'+timeseriestype+'_nominal_srate'+str(samplerate)+'_'+participant+'_'+word+'_'+modality+correction+'.csv', index=False)\n",
    "                      if timeseriestype == 'Mic':\n",
    "                            wavloc = trialfolder+'Audio/'+dat+'_'+trialtype+'_'+ str(i) +'_'+timeseriestype+'_nominal_srate'+str(samplerate)+'_'+participant+'_'+word+'_'+modality+correction+'.wav'\n",
    "                            to_audio(wavloc, timeseries[indices])\n",
    "                          # also apply denoising\n",
    "                            reduced_noiseclip = reduced_noise[indices]\n",
    "                            wavloc2 = trialfolder+'Audio/'+dat+'_'+trialtype+'_'+ str(i) +'_'+timeseriestype+'_nominal_srate'+str(samplerate)+'_'+participant+'_'+word+'_'+modality+correction+'_denoised.wav'\n",
    "                            wavfile.write(wavloc2, rate, reduced_noiseclip)\n",
    "            \n",
    "            # get information about the tpose for camera\n",
    "            if timeseriestype == 'MyWebcamFrameStream':\n",
    "                for i in range(len(tpose_starts)):\n",
    "                    begin = tpose_starts[i]\n",
    "                    end = tpose_ends[i]\n",
    "                    indices = (df_lab.loc[:,0] > begin) & (df_lab.loc[:,0] < end)\n",
    "                    beginst = min(df_lab.loc[:,0])\n",
    "                    endst = max(df_lab.loc[:,0])\n",
    "                    subset = df_lab.loc[indices, :]\n",
    "                    # save subset to csv\n",
    "                    subset.to_csv(trialfolder+dat+'_'+'tpose_'+ str(i) +'_'+timeseriestype+'_nominal_srate'+str(samplerate)+'.csv', index=False)\n",
    "        \n",
    "        # after every participants well save the error log\n",
    "        errors = pd.DataFrame(errorlist, columns=['file_error'])\n",
    "        file_path = errorlogs+'error_log_cuttingtrails.csv'\n",
    "        errors.to_csv(file_path, index=False) \n",
    "        \n",
    "print('Were done: proceed to snipping videos to triallevel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a2e035",
   "metadata": {},
   "source": [
    "Now we have raw data for each trial in csv and wav, but we still need to write videos for each trial. We will use the trial-cut files to access the range of frames in the original raw video file and cut it out from it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed535b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorlist = []\n",
    "\n",
    "# this is a folder with timeseries\n",
    "tsfolder = datafolder+'\\\\Data_processed\\\\Data_trials\\\\'\n",
    "# this is where the raw long video is\n",
    "videofolder = datafolder+'raw_data\\\\'\n",
    "#print(tsfolder)\n",
    "#print(videofolder)\n",
    "\n",
    "# loop through the csv's in tsfolder that has string 'MyWebcamStream' in name\n",
    "for file in os.listdir(tsfolder):\n",
    "    print(file)\n",
    "    if 'MyWebcamFrameStream' in file:\n",
    "        print('Now processing file '+ file)\n",
    "        # if it is a tpose file, we skip it for now\n",
    "        if 'tpose' in file:\n",
    "            continue\n",
    "\n",
    "        # the name looks like this 0_1_trial_0_MyWebcamFrameStream_nominal_srate500_p0_bitter_geluiden.csv\n",
    "\n",
    "        dyadIndex = file.split('_')[0]   # this is dyad number\n",
    "        partIndex = file.split('_')[1]   # this is part of the session\n",
    "        sessionIndex = dyadIndex + '_' + partIndex # this is the session index\n",
    "        trialIndex = file.split('_')[3] # this is trial number\n",
    "        participant = file.split('_')[7] # this is participant 0/1\n",
    "        word = file.split('_')[8] # this is the concept\n",
    "        modality = file.split('_')[9].split('.')[0] # this is the modality\n",
    "\n",
    "        # assess the correction\n",
    "        if 'c0' in file:\n",
    "            correction = '_c0'\n",
    "        elif 'c1' in file:\n",
    "            correction = '_c1'\n",
    "        elif 'c2' in file:\n",
    "            correction = '_c2'\n",
    "        else:\n",
    "            correction = ''\n",
    "\n",
    "\n",
    "        # assess the trial type\n",
    "        if 'pr' in file:\n",
    "            trialtype = 'pr'\n",
    "        else:\n",
    "            trialtype = 'trial'\n",
    "\n",
    "        trialdata = pd.read_csv(tsfolder+file)\n",
    "        #print(trialdata)\n",
    "        videolong = videofolder+sessionIndex+'\\\\'+sessionIndex+'-video.avi' # this is the long video \n",
    "        begin_time = trialdata['0'].min() # begin time of the trial\n",
    "        #print(begin_time)\n",
    "        end_time = trialdata['0'].max() # end time of the trial\n",
    "        #print(end_time)\n",
    "        # get the begin and end frame\n",
    "        begin_frame = trialdata['1'].min().astype(int)\n",
    "        #print(begin_frame)\n",
    "        end_frame = trialdata['1'].max().astype(int)\n",
    "        #print(end_frame)\n",
    "        totframes = end_frame-begin_frame # total number of frames in the trial\n",
    "        #print(totframes)\n",
    "        frames = range(begin_frame, end_frame) # get all the frames in trial\n",
    "        #print(frames)\n",
    "        # load in the long video\n",
    "        print('Loading the original video')\n",
    "        capture = cv2.VideoCapture(videolong) \n",
    "        \n",
    "        # some meta-info about the video\n",
    "        #frameWidth = capture.get(ffmpegcv.CAP_PROP_FRAME_WIDTH)\n",
    "        #frameHeight = capture.get(ffmpegcv.CAP_PROP_FRAME_HEIGHT)\n",
    "        #frate =  capture.get(ffmpegcv.CAP_PROP_FPS)\n",
    "        #print('frame rate: '+str(frate))\n",
    "        #fourcc = ffmpegcv.VideoWriter_fourcc(*'M','J','P','G') #for different video formats you could use e.g., *'XVID'\n",
    "\n",
    "        # what is the original fps of the video\n",
    "        originalfps = round((totframes/(end_time-begin_time)),3)\n",
    "        print('original fps: '+str(originalfps))\n",
    "        \n",
    "        # this is the location where the video will be saved\n",
    "        vidloc = trialfolder+sessionIndex+'_'+trialtype+'_'+ str(trialIndex) +'_'+participant+'_'+word+'_'+modality+correction+'_video_raw'+'.avi'\n",
    "        # codec for the video\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        # get the frame width\n",
    "        frameWidth = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        # get the frame height\n",
    "        frameHeight = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "        # start writing video\n",
    "        print('Starting to write the video')\n",
    "        #out = ffmpegcv.VideoWriter(vidloc, fourcc, fps = originalfps, frameSize = (int(frameWidth), int(frameHeight)))\n",
    "        out = cv2.VideoWriter(vidloc, fourcc, fps = originalfps, frameSize = (int(frameWidth), int(frameHeight)))\n",
    "\n",
    "        print('Looping over frames')\n",
    "\n",
    "        # index the frames of the current trial\n",
    "        for fra in frames:\n",
    "            capture.set(cv2.CAP_PROP_POS_FRAMES, fra)\n",
    "            ret, frame = capture.read()\n",
    "            if ret:\n",
    "                out.write(frame)\n",
    "            if not ret:\n",
    "                print('a frame was dropped: ' + str(fra))\n",
    "            \n",
    "        capture.release()\n",
    "        out.release()\n",
    "        \n",
    "        print('Video is done')\n",
    "\n",
    "print('All done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a918bac1",
   "metadata": {},
   "source": [
    "Now we also write the video of tpose, using the same code but looking only for csv files with tpose in the name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e5bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorlist = []\n",
    "\n",
    "# this is a folder with timeseries\n",
    "tsfolder = datafolder+'Data_processed\\Data_trials\\\\'\n",
    "# this is where the raw long video is\n",
    "videofolder = datafolder+'raw_data\\\\'\n",
    "#print(tsfolder)\n",
    "#print(videofolder)\n",
    "\n",
    "# loop through the csv's in tsfolder that has string 'MyWebcamStream' in name\n",
    "for file in os.listdir(tsfolder):\n",
    "    if 'MyWebcamFrameStream' in file and 'tpose' in file:\n",
    "        print('Now processing file '+file)\n",
    "        print(file)\n",
    "        # get the filename \n",
    "        filename = file.split('.')[0]\n",
    "        sessionIndex = filename.split('_')[0] + '_' + filename.split('_')[1]\n",
    "\n",
    "        videolong = videofolder+sessionIndex+'\\\\'+sessionIndex+'-video.avi' # this is the long video\n",
    "\n",
    "        begin_time = trialdata['0'].min() # begin time of the trial\n",
    "        #print(begin_time)\n",
    "        end_time = trialdata['0'].max() # end time of the trial\n",
    "        #print(end_time)\n",
    "        # get the begin and end frame\n",
    "        begin_frame = trialdata['1'].min().astype(int)\n",
    "        #print(begin_frame)\n",
    "        end_frame = trialdata['1'].max().astype(int)\n",
    "        #print(end_frame)\n",
    "        totframes = end_frame-begin_frame # total number of frames in the trial\n",
    "        #print(totframes)\n",
    "        frames = range(begin_frame, end_frame) #get all the frames in trial\n",
    "        #print(frames)\n",
    "        \n",
    "        #load in the long video\n",
    "        print('Loading the original video')\n",
    "        capture = cv2.VideoCapture(videolong) \n",
    "\n",
    "        originalfps = round((totframes/(end_time-begin_time)),3)\n",
    "        print('original fps: '+str(originalfps))\n",
    "        \n",
    "        # this is the location where the video will be saved\n",
    "        vidloc = trialfolder+filename+'_video_raw'+'.avi'\n",
    "        # codec for the video\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        # get the frame width\n",
    "        frameWidth = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        # get the frame height\n",
    "        frameHeight = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        # start writing video\n",
    "        print('Starting to write the video')\n",
    "        #out = ffmpegcv.VideoWriter(vidloc, fourcc, fps = originalfps, frameSize = (int(frameWidth), int(frameHeight)))\n",
    "        out = cv2.VideoWriter(vidloc, fourcc, fps = originalfps, frameSize = (int(frameWidth), int(frameHeight)))\n",
    "\n",
    "        print('Looping over frames')\n",
    "\n",
    "        # index the frames of the current trial\n",
    "        for fra in frames:\n",
    "            capture.set(cv2.CAP_PROP_POS_FRAMES, fra)\n",
    "            ret, frame = capture.read()\n",
    "            if ret:\n",
    "                out.write(frame)\n",
    "                \n",
    "            if not ret:\n",
    "                print('a frame was dropped: ' + str(fra))\n",
    "            \n",
    "        capture.release()\n",
    "        out.release()\n",
    "\n",
    "print('All done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adccb79",
   "metadata": {},
   "source": [
    "# Concatenating audio and video, using ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "wavloc = trialfolder+'Audio\\\\'\n",
    "audiovideo = datafolder+'Data_processed\\\\AudioVideo\\\\'\n",
    "\n",
    "if not os.path.exists(wavloc):\n",
    "    print(f\"Directory not found: {wavloc}\")\n",
    "\n",
    "# loop over Audio files\n",
    "for file in os.listdir(wavloc):\n",
    "    print(file)\n",
    "    if 'denoised' in file and '0_1' in file:\n",
    "        print('Now processing file '+file)\n",
    "        dyadIndex = file.split('_')[0]   # this is dyad number\n",
    "        partIndex = file.split('_')[1]   # this is part of the session\n",
    "        sessionIndex = dyadIndex + '_' + partIndex # this is the session index\n",
    "        trialIndex = file.split('_')[3] # this is trial number\n",
    "\n",
    "        participant = file.split('_')[7] # this is participant 0/1\n",
    "        word = file.split('_')[8] # this is the word\n",
    "        modality = file.split('_')[9] # this is the modality\n",
    "        # put the .csv away from the modality\n",
    "        modality = modality.split('.')[0]\n",
    "\n",
    "        if 'c0' in file:\n",
    "            correction = '_c0'\n",
    "        elif 'c1' in file:\n",
    "            correction = '_c1'\n",
    "        elif 'c2' in file:\n",
    "            correction = '_c2'\n",
    "        else:\n",
    "            correction = ''\n",
    "        \n",
    "        if 'pr' in file:\n",
    "            trialtype = 'pr'\n",
    "        else:\n",
    "            trialtype = 'trial'\n",
    "        #load in the audio\n",
    "        print('Loading the audio')\n",
    "        audio_path = os.path.join(wavloc, file)\n",
    "        if not os.path.exists(audio_path):\n",
    "            print(f\"Audio file not found: {audio_path}\")\n",
    "        # input the video with ffmpg\n",
    "        input_audio = ffmpeg.input(audio_path)\n",
    "        print(input_audio)\n",
    "        #load in the video with matchich trialIndex and SessionIndex\n",
    "        print('Loading the video')\n",
    "        video_path = os.path.join(trialfolder, f\"{sessionIndex}_{trialtype}_{trialIndex}_{participant}_{word}_{modality}{correction}_video_raw.avi\")\n",
    "\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Video file not found: {video_path}\")\n",
    "        input_video = ffmpeg.input(video_path)\n",
    "        print(input_video)\n",
    "        # get information about the vid_frate\n",
    "        #streamloc = trialfolder+sessionIndex+'_trial_'+ str(trialIndex) +'_'+'MyWebcamFrameStream_nominal_srate500'+'.csv'\n",
    "        #print(streamloc)\n",
    "        #streamdata = pd.read_csv(streamloc)\n",
    "        # get the begin and end frame\n",
    "        #begfr = streamdata['1'].min().astype(int)\n",
    "        #print(begfr)\n",
    "        #endfr = streamdata['1'].max().astype(int)\n",
    "        #print(endfr)\n",
    "        #totfr = endfr-begfr\n",
    "        #print(totfr)\n",
    "        #begin = streamdata['0'].min()\n",
    "        #print(begin)\n",
    "        #end = streamdata['0'].max()\n",
    "        #print(end)\n",
    "        # what is the original fps of the video\n",
    "        #origfps = round((totfr/(end-begin)),3)\n",
    "        # tranform it into real number\n",
    "        #origfps = float(origfps)\n",
    "        \n",
    "        #combine the audio and video\n",
    "        print('Combining audio and video')\n",
    "        output_path = os.path.abspath(os.path.join(audiovideo, f\"{sessionIndex}_{trialtype}_{trialIndex}_{participant}_{word}_{modality}{correction}_final.avi\"))\n",
    "        ffmpeg.concat(input_video, input_audio, v=1, a=1).output(output_path).run(overwrite_output=True)\n",
    "        \n",
    "        #save it\n",
    "        print('Saving the video')\n",
    "        #print(origfps)\n",
    "        #print(type(origfps))\n",
    "        #print(trialIndex)\n",
    "        #print(sessionIndex)\n",
    "        # save the final video with audio\n",
    "        #final.write_videofile(trialfolder+sessionIndex+'_trial_'+ str(trialIndex) +'_'+'video_audio'+'.mp4', fps=origfps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # open prompt and ask for id\n",
    "# id = input(\"Enter ID: \")\n",
    "# # create a folder with name of the id\n",
    "\n",
    "\n",
    "# # select an output path that will have a folderts from 1 to 1000, and if th folder does not exist, crate it\n",
    "# output_path = os.path.abspath(os.path.join(datafolder, f\"Data_processed\\\\{id}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TSPROCESS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
