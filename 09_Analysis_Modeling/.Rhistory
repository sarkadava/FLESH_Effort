family = gaussian,
Effort_Change_Ratio ~ 1 + s(PrevAn, bs = "bs", k = 19),
prior = c(prior(normal(100, 10), class = Intercept),
prior(normal(0, 10), class = b),
prior(student_t(3, 0, 5.9), class = sds),
prior(exponential(1), class = sigma)),
iter = 4000, warmup = 2000, chains = 4, cores = 4,
seed = 4,
control = list(adapt_delta = .99)
)
```
# Add criterions for later diagnostics
h2.s2 <- add_criterion(h2.s2, criterion = c("loo", "waic"))
# Add criterions for later diagnostics
h2.s2 <- add_criterion(h2.s2, criterion = c("loo", "waic"))
# Calculate also variance explained (R^2)
h2.s2_R2 <- bayes_R2(h2.s2)
# Save both as objects
saveRDS(h2.s2, here("09_Analysis_Modeling", "models", "h2.s2.rds"))
saveRDS(h2.s2_R2, here("09_Analysis_Modeling", "models", "h2.s2_R2.rds"))
f <- fitted(h2.s2)
f %>%
data.frame() %>%
bind_cols(d2) %>%
ggplot(aes(x = PrevAn, y = Effort_Change_Ratio, ymin = Q2.5, ymax = Q97.5)) +
geom_vline(xintercept = knot_list, color = "white", alpha = 1/2) +
geom_hline(yintercept = fixef(h2.s2)[1, 1], color = "white", linetype = 2) +
geom_point(color = "#ffb7c5", alpha = 1/2) +
geom_ribbon(fill = "white", alpha = 2/3) +
labs(x = "Previous Answer",
y = "Effort Change Ratio") +
theme_bw() +
theme(panel.background = element_rect(fill = "#4f455c"),
panel.grid = element_blank())
plot(h2.s2)
plot(conditional_effects(h2.s2), points = TRUE)
plot(conditional_effects(h2.s1), points = TRUE)
pp_check(h2.s2, type = "dens_overlay")
pp_check(h2.s2, type = "error_scatter_avg")
h2.s2_R2
pp_check(h2.s2, type = "dens_overlay")
h2.s2_R2
pp_check(h2.s2, type = "error_scatter_avg")
# Summary
summary(h2.s2)
fitted(h2.s2) %>%
data.frame() %>%
bind_cols(select(d2, PrevAn, Effort_Change_Ratio)) %>%
ggplot(aes(x = PrevAn, y = Effort_Change_Ratio, ymin = Q2.5, ymax = Q97.5)) +
geom_hline(yintercept = fixef(h2.s2)[1, 1], color = "white", linetype = 2) +
geom_point(color = "#ffb7c5", alpha = 1/2) +
geom_ribbon(fill = "white", alpha = 2/3) +
labs(subtitle = 'gam_s using s(PrevAn, bs = "bs")',
y = "Effort Chnage Ratio") +
theme_bw() +
theme(panel.background = element_rect(fill = "#4f455c"),
panel.grid = element_blank())
h2.s3 <-
brm(
data = d2,
family = gaussian,
Effort_Change_Ratio ~ 1 +
s(PrevAn_z, bs = "bs", k = 19) +  # Smooth for Previous Answer similarity
CommAtt + Modality + Big5 + Familiarity + Expressibility_z +  # Fixed effects
(1 | Participant) + (1 | Concept),  # Random effects
prior = c(
prior(normal(100, 10), class = Intercept),
prior(normal(0, 10), class = b),
prior(student_t(3, 0, 5.9), class = sds),
prior(exponential(1), class = sigma)
),
iter = 4000, warmup = 2000, chains = 4, cores = 4,
seed = 4,
control = list(adapt_delta = .99)
)
filtered_data$CommAtt <- as.factor(filtered_data$CommAtt)
filtered_data$Modality <- as.factor(filtered_data$Modality)
filtered_data$Participant <- as.factor(filtered_data$Participant)
filtered_data$Concept <- as.factor(filtered_data$Concept)
filtered_data$TrialNumber <- as.numeric(filtered_data$TrialNumber)  # Ensure TrialNumber is numeric
contrasts(filtered_data$CommAtt) <- MASS::contr.sdif(2) # but we don't need this one
contrasts(filtered_data$Modality) <- contr.sum(3)/2
filtered_data$TrialNumber_c <- filtered_data$TrialNumber - median(range(filtered_data$TrialNumber))
range(filtered_data$TrialNumber_c)
range(filtered_data$TrialNumber)
filtered_data$Familiarity <- filtered_data$Familiarity - median(range(filtered_data$Familiarity))
filtered_data$Big5 <- filtered_data$Big5 - median(range(filtered_data$Big5))
filtered_data <-
filtered_data |>
group_by(Modality) |>
mutate(Expressibility_z = (Expressibility - mean(Expressibility))/ sd(filtered_data$Expressibility, na.rm = T)) |>
ungroup()
filtered_data <-
filtered_data |>
#group_by(Modality) |>
mutate(PrevAn_z = (PrevAn - mean(PrevAn))/ sd(filtered_data$PrevAn, na.rm = T)) |>
ungroup()
filtered_data$PrevAn_c <- filtered_data$PrevAn - median(range(filtered_data$PrevAn))
filtered_data <-
filtered_data |>
group_by(Modality) |>
mutate(Expressibility_c = Expressibility - median(range(Expressibility))) |>
ungroup()
h2.s3 <-
brm(
data = filtered_data,
family = gaussian,
Effort_Change_Ratio ~ 1 +
s(PrevAn_z, bs = "bs", k = 19) +  # Smooth for Previous Answer similarity
CommAtt + Modality + Big5 + Familiarity + Expressibility_z +  # Fixed effects
(1 | Participant) + (1 | Concept),  # Random effects
prior = c(
prior(normal(100, 10), class = Intercept),
prior(normal(0, 10), class = b),
prior(student_t(3, 0, 5.9), class = sds),
prior(exponential(1), class = sigma)
),
iter = 4000, warmup = 2000, chains = 4, cores = 4,
seed = 4,
control = list(adapt_delta = .99)
)
h2.s4 <-
brm(
Effort_Change_Ratio ~ 1 +
s(PrevAn_z, bs = "bs", k = 19) +  # Nonlinear effect for Previous Answer similarity
CommAtt + Modality + Big5 + Familiarity + Expressibility_z +
(1 + CommAtt | Participant) +  # Random slopes and intercepts for Participant
(1 + CommAtt | Concept) +      # Random slopes and intercepts for Concept
(1 | TrialNumber_c),           # Random intercept for Trial Number
data = filtered_data,
family = lognormal(),
iter = 4000,
warmup = 2000,
chains = 4,
cores = 4,
seed = 4,
control = list(adapt_delta = .99)
)
h2.s3 <-
brm(
data = filtered_data,
family = gaussian,
Effort_Change_Ratio ~ 1 +
s(PrevAn_z, bs = "bs", k = 19) +  # Smooth for Previous Answer similarity
CommAtt + Modality + Big5 + Familiarity + Expressibility_z +  # Fixed effects
(1 | Participant) + (1 | Concept),  # Random effects
prior = c(
prior(normal(100, 10), class = Intercept),
prior(normal(0, 10), class = b),
prior(student_t(3, 0, 5.9), class = sds),
prior(exponential(1), class = sigma)
),
iter = 4000, warmup = 2000, chains = 4, cores = 4,
seed = 4,
control = list(adapt_delta = .99)
)
# Add criterions for later diagnostics
h2.s3 <- add_criterion(h2.s3, criterion = c("loo", "waic"))
# Calculate also variance explained (R^2)
h2.s3_R2 <- bayes_R2(h2.s3)
# Save both as objects
saveRDS(h2.s3, here("09_Analysis_Modeling", "models", "h2.s3.rds"))
saveRDS(h2.s3_R2, here("09_Analysis_Modeling", "models", "h2.s3_R2.rds"))
# Summary
summary(h2.s3)
h2.s3 <-
brm(
data = filtered_data,
family = gaussian,
Effort_Change_Ratio ~ 1 +
s(PrevAn_z, bs = "bs", k = 19) +  # Smooth for Previous Answer similarity
Modality + Big5 + Familiarity + Expressibility_z +  # Fixed effects
(1 | Participant) + (1 | Concept),  # Random effects
prior = c(
prior(normal(100, 10), class = Intercept),
prior(normal(0, 10), class = b),
prior(student_t(3, 0, 5.9), class = sds),
prior(exponential(1), class = sigma)
),
iter = 4000, warmup = 2000, chains = 4, cores = 4,
seed = 4,
control = list(adapt_delta = .99)
)
h2.s4 <-
brm(
Effort_Change_Ratio ~ 1 +
s(PrevAn_z, bs = "bs", k = 19) +  # Nonlinear effect for Previous Answer similarity
Modality + Big5 + Familiarity + Expressibility_z +
(1 + CommAtt | Participant) +  # Random slopes and intercepts for Participant
(1 + CommAtt | Concept) +      # Random slopes and intercepts for Concept
(1 | TrialNumber_c),           # Random intercept for Trial Number
data = filtered_data,
family = lognormal(),
iter = 4000,
warmup = 2000,
chains = 4,
cores = 4,
seed = 4,
control = list(adapt_delta = .99)
)
# Add criterions for later diagnostics
h2.s4 <- add_criterion(h2.s4, criterion = c("loo", "waic"))
# Calculate also variance explained (R^2)
h2.s4_R2 <- bayes_R2(h2.s4)
# Save both as objects
saveRDS(h2.s4, here("09_Analysis_Modeling", "models", "h2.s4.rds"))
saveRDS(h2.s4_R2, here("09_Analysis_Modeling", "models", "h2.s4_R2.rds"))
# Summary
summary(h2.s3)
plot(h2.s3)
plot(conditional_effects(h2.s3), points = TRUE)
pp_check(h2.s3, type = "dens_overlay")
pp_check(h2.s3, type = "error_scatter_avg")
h2.s3_R2
# Summary
summary(h2.s4)
pp_check(h2.s4, type = "dens_overlay")
h2.s4 <-
brm(
Effort_Change_Ratio ~ 1 +
s(PrevAn_z, bs = "bs", k = 19) +  # Nonlinear effect for Previous Answer similarity
Modality + Big5 + Familiarity + Expressibility_z +
(1 + CommAtt | Participant) +  # Random slopes and intercepts for Participant
(1 + CommAtt | Concept) +      # Random slopes and intercepts for Concept
(1 | TrialNumber_c),           # Random intercept for Trial Number
data = filtered_data,
family = lognormal(),
iter = 4000,
warmup = 2000,
chains = 4,
cores = 4,
seed = 4,
control = list(adapt_delta = .999,
max_treedepth = 12)
)
h2.s4 <-
brm(
Effort_Change_Ratio ~ 1 +
s(PrevAn_z, bs = "bs", k = 19) +  # Nonlinear effect for Previous Answer similarity
Modality + Big5 + Familiarity + Expressibility_z +
(1 + CommAtt || Participant) +  # Random slopes and intercepts for Participant
(1 + CommAtt || Concept) +      # Random slopes and intercepts for Concept
(1 | TrialNumber_c),           # Random intercept for Trial Number
data = filtered_data,
family = lognormal(),
iter = 4000,
warmup = 2000,
chains = 4,
cores = 4,
seed = 4,
control = list(adapt_delta = .999,
max_treedepth = 12)
)
filtered_data
View(filtered_data)
View(filtered_data)
h2.s4 <-
brm(
Effort_Change_Ratio ~ 1 +
s(PrevAn_z, bs = "bs", k = 19) +  # Nonlinear effect for Previous Answer similarity
Modality + Big5 + Familiarity + Expressibility_z +
(1 + CommAtt || Participant) +  # Random slopes and intercepts for Participant
(1 + CommAtt || Concept) +      # Random slopes and intercepts for Concept
(1 | TrialNumber_c),           # Random intercept for Trial Number
data = filtered_data,
family = lognormal(),
iter = 4000,
warmup = 2000,
chains = 4,
cores = 4,
seed = 4,
control = list(adapt_delta = .999,
max_treedepth = 12)
)
# Add criterions for later diagnostics
h2.s4 <- add_criterion(h2.s4, criterion = c("loo", "waic"))
# Calculate also variance explained (R^2)
h2.s4_R2 <- bayes_R2(h2.s4)
# Save both as objects
saveRDS(h2.s4, here("09_Analysis_Modeling", "models", "h2.s4.rds"))
saveRDS(h2.s4_R2, here("09_Analysis_Modeling", "models", "h2.s4_R2.rds"))
h2.m3 <- brm(
Effort_Change_Ratio ~ 1 + PrevAn_z + Modality + Big5 + Familiarity + Expressibility_z +
(1 + PrevAn || Participant) + (1 + PrevAn || Concept) + (1 | TrialNumber_c),
data = filtered_data,
family = mixture(normal(), normal()),  # Mixture of two normal distributions
iter = 4000,
cores = 4
)
h2.m3 <- brm(
Effort_Change_Ratio ~ 1 + PrevAn_z + Modality + Big5 + Familiarity + Expressibility_z +
(1 + PrevAn || Participant) + (1 + PrevAn || Concept) + (1 | TrialNumber_c),
data = filtered_data,
family = mixture(gaussian(), gaussian()),  # Mixture of two normal distributions
iter = 4000,
cores = 4
)
h2.m3 <- brm(
Effort_Change_Ratio ~ 1 + PrevAn_z + Modality + Big5 + Familiarity + Expressibility_z +
(1 + PrevAn || Participant) + (1 + PrevAn || Concept) + (1 | TrialNumber_c),
data = filtered_data,
family = mixture(gaussian(), gaussian()),  # Mixture of two normal distributions
iter = 4000,
cores = 4,
control = list(adapt_delta = .999,
max_treedepth = 12)
)
# Summary
summary(h2.s4)
plot(h2.s4)
plot(conditional_effects(h2.s4), points = TRUE)
pp_check(h2.s4, type = "dens_overlay")
pp_check(h2.s4, type = "error_scatter_avg")
h2.s4_R2
pp_check(h2.s4, type = "dens_overlay")
model_list <- list(h2.m1, h2.m2, h2.s1, h2.s2, h2.s3, h2.s4)
# Extract R-hat values for each model
rhat_list <- lapply(model_list, function(model) {
rhat_values <- rhat(model)
data.frame(model = deparse(substitute(model)),
max_rhat = max(rhat_values),
min_rhat = min(rhat_values))
})
# Combine and inspect
do.call(rbind, rhat_list)
# Extract n_eff values for each model
neff_ratio_list <- lapply(model_list, function(model) {
neff_values <- neff_ratio(model)              # Here we calculate ratio (not the raw number of effective samples)
data.frame(model = deparse(substitute(model)),
min_neff = min(neff_values),
max_neff = max(neff_values),
mean_neff = mean(neff_values))
})
# Combine and inspect
do.call(rbind, neff_ratio_list)
l <- loo_compare(h2.m1, h2.m2, h2.s1, h2.s2, h2.s3, h2.s4, criterion = "loo")
# Add criterions for later diagnostics
h2.s3 <- add_criterion(h2.s3, criterion = c("loo", "waic"))
l <- loo_compare(h2.m1, h2.m2, h2.s1, h2.s2, h2.s3, h2.s4, criterion = "loo")
print(l, simplify = F)
effective_sample(h2.s3)
effective_sample(h2.m1)
effective_sample(h2.m2)
w <- loo_compare(h2.m1, h2.m2, h2.s1, h2.s2, h2.s3, h2.s4, criterion = "waic")
print(w, simplify = F)
# see Solomon Kurz
cbind(waic_diff = w[,1] * -2,
se = w[,2] * 2)
library(tibble)
library(tidyverse)
library(rcartocolor)
w[, 7:8] %>%
data.frame() %>%
rownames_to_column("model_name") %>%
mutate(model_name = fct_reorder(model_name, waic, .desc = T)) %>%
ggplot(aes(x = waic, y = model_name,
xmin = waic - se_waic,
xmax = waic + se_waic)) +
geom_pointrange(color = carto_pal(7, "BurgYl")[7],
fill = carto_pal(7, "BurgYl")[5], shape = 21) +
labs(title = "WAIC plot",
x = NULL, y = NULL) +
theme(axis.ticks.y = element_blank())
model_weights(h2.m1, h2.m2, h2.s1, h2.s2, h2.s3, h2.s4, weights = "waic") %>%
round(digits = 2)
pp_check(h2.s1, type = "dens_overlay")
pp_check(h2.m1, type = "dens_overlay")
h2.m1 <- brm(Effort_Change_Ratio ~ 1 + PrevAn_z + CommAtt + Familiarity + Big5 + Expressibility_z + TrialNumber_c + Modality + (1 | Participant) + (1 | Concept),
data = filtered_data,
iter = 4000,
cores = 4)
pp_check(h2.m1, type = "dens_overlay")
plot(conditional_effects(h2.m1), points = TRUE)
# Add criterions for later diagnostics
h2.m1 <- add_criterion(h2.m1, criterion = c("loo", "waic"))
# Add criterions for later diagnostics
h2.m1 <- add_criterion(h2.m1, criterion = c("loo", "waic"))
# Calculate also variance explained (R^2)
h2.m1_R2 <- bayes_R2(h2.m1)
# Save both as objects
saveRDS(h2.m1, here("09_Analysis_Modeling", "models", "h2.m1.rds"))
saveRDS(h2.m1_R2, here("09_Analysis_Modeling", "models", "h2.m1_R2.rds"))
# Summary
summary(h2.m1)
pp_check(h2.m1, type = "error_scatter_avg")
pp_check(h2.m1, type = "dens_overlay")
pp_check(h2.m1, type = "error_scatter_avg")
# so there seems to be quite high residual error for some extreme values (esp for the second mode)
h2.m1_R2
h2.m2 <- brm(Effort_Change_Ratio ~ 1 + PrevAn_z + CommAtt + Modality + Big5 + Familiarity + Expressibility_z +  (1 + PrevAn || Participant) + (1 + PrevAn || Concept) + (1 | TrialNumber_c),
data = filtered_data,
family = lognormal(),
iter = 4000,
cores = 4)
# Add criterions for later diagnostics
h2.m2 <- add_criterion(h2.m2, criterion = c("loo", "waic"))
# Calculate also variance explained (R^2)
h2.m2_R2 <- bayes_R2(h2.m2)
# Save both as objects
saveRDS(h2.m2, here("09_Analysis_Modeling", "models", "h2.m2.rds"))
saveRDS(h2.m2_R2, here("09_Analysis_Modeling", "models", "h2.m2_R2.rds"))
beep(5)
# Summary
summary(h2.m2)
# Extract posterior samples
posterior_samples <- as_draws_df(h2.m2)
alpha_samples <- posterior_samples$b_Intercept
# Create a list to store effects for each fixed factor
effect_list <- list()
# Helper function to calculate summary statistics
get_effect_summary <- function(effect_samples) {
mean_effect <- mean(effect_samples)
se_effect <- sd(effect_samples)
ci_effect <- quantile(effect_samples, c(0.025, 0.975))
post_prob <- mean(effect_samples > 0)
c(mean = mean_effect,
se = se_effect,
lower_ci = ci_effect[1],
upper_ci = ci_effect[2],
post_prob = post_prob)
}
# Compute expected values on the log scale
mu_1 <- alpha_samples  # CommAtt 1
# Transform to original scale
effect_1 <- exp(mu_1)
# PrevAn (continuous)
if ("b_PrevAn_z" %in% colnames(posterior_samples)) {
beta_prevAn <- posterior_samples$b_PrevAn_z
effect_list$PrevAn_z <- get_effect_summary(exp(alpha_samples + beta_prevAn) - exp(alpha_samples))
}
effect_list$Intercept_mean <- mean(effect_1)
# Convert to a nicely formatted data frame
effect_df <- do.call(rbind, effect_list)
# View effects
effect_df
plot(conditional_effects(h2.m2), points = TRUE)
pp_check(h2.m2, type = "dens_overlay")
pp_check(h2.m2, type = "error_scatter_avg")
h2.m2_R2
h2.s3 <-
brm(
data = filtered_data,
family = gaussian,
Effort_Change_Ratio ~ 1 +
s(PrevAn_z, bs = "bs", k = 19) +  # Smooth for Previous Answer similarity
+ CommAtt + Modality + Big5 + Familiarity + Expressibility_z +  # Fixed effects
(1 | Participant) + (1 | Concept),  # Random effects
prior = c(
prior(normal(100, 10), class = Intercept),
prior(normal(0, 10), class = b),
prior(student_t(3, 0, 5.9), class = sds),
prior(exponential(1), class = sigma)
),
iter = 4000, warmup = 2000, chains = 4, cores = 4,
seed = 4,
control = list(adapt_delta = .99)
)
# Add criterions for later diagnostics
h2.s3 <- add_criterion(h2.s3, criterion = c("loo", "waic"))
# Calculate also variance explained (R^2)
h2.s3_R2 <- bayes_R2(h2.s3)
# Save both as objects
saveRDS(h2.s3, here("09_Analysis_Modeling", "models", "h2.s3.rds"))
saveRDS(h2.s3_R2, here("09_Analysis_Modeling", "models", "h2.s3_R2.rds"))
h2.s4 <-
brm(
Effort_Change_Ratio ~ 1 +
s(PrevAn_z, bs = "bs", k = 19) +  # Nonlinear effect for Previous Answer similarity
+ CommAtt + Modality + Big5 + Familiarity + Expressibility_z +
(1 + PrevAn_z || Participant) +  # Random slopes and intercepts for Participant
(1 + PrevAn_z || Concept) +      # Random slopes and intercepts for Concept
(1 | TrialNumber_c),           # Random intercept for Trial Number
data = filtered_data,
family = lognormal(),
iter = 4000,
warmup = 2000,
chains = 4,
cores = 4,
seed = 4,
control = list(adapt_delta = .999,
max_treedepth = 12)
)
# Add criterions for later diagnostics
h2.s4 <- add_criterion(h2.s4, criterion = c("loo", "waic"))
# Calculate also variance explained (R^2)
h2.s4_R2 <- bayes_R2(h2.s4)
# Save both as objects
saveRDS(h2.s4, here("09_Analysis_Modeling", "models", "h2.s4.rds"))
saveRDS(h2.s4_R2, here("09_Analysis_Modeling", "models", "h2.s4_R2.rds"))
pp_check(h2.s4, type = "dens_overlay")
h2.s4_R2
pp_check(h2.s4, type = "error_scatter_avg")
model_list <- list(h2.m1, h2.m2, h2.s1, h2.s2, h2.s3, h2.s4)
# Extract R-hat values for each model
rhat_list <- lapply(model_list, function(model) {
rhat_values <- rhat(model)
data.frame(model = deparse(substitute(model)),
max_rhat = max(rhat_values),
min_rhat = min(rhat_values))
})
# Combine and inspect
do.call(rbind, rhat_list)
# Extract n_eff values for each model
neff_ratio_list <- lapply(model_list, function(model) {
neff_values <- neff_ratio(model)              # Here we calculate ratio (not the raw number of effective samples)
data.frame(model = deparse(substitute(model)),
min_neff = min(neff_values),
max_neff = max(neff_values),
mean_neff = mean(neff_values))
})
# Combine and inspect
do.call(rbind, neff_ratio_list)
