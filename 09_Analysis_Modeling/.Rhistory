# Calculate Eff for the first attempt
if (attempt == 1) {
Eff <- 1.15 * Big5[participant_id] +
1.10 * Familiarity[participant_id] +
1.20 * expressibility_score +
rnorm(1, mean = 1, sd = 0.5)
# Adjust Eff based on modality
if (modality == "combined") {
Eff <- Eff * 0.7  # Slight moderation for combined modality
}
}
# Adjust Eff for subsequent attempts
if (attempt == 2) {
Eff <- 1.15 * Big5[participant_id] +
1.10 * Familiarity[participant_id] +
1.20 * expressibility_score +
rnorm(1, mean = 1, sd = 0.5)
Eff <- Eff * 1.50  # Multiply effort by 1.50 for the second attempt
} else if (attempt == 3) {
Eff <- 1.15 * Big5[participant_id] +
1.10 * Familiarity[participant_id] +
1.20 * expressibility_score +
rnorm(1, mean = 1, sd = 0.5)
Eff <- Eff * 0.70  # Multiply effort by 0.70 for the third attempt
}
# Create row for each attempt
participant_data <- rbind(participant_data, data.frame(
Participant = participant_id,
Concept = concept_id,
Modality = modality,
Big5 = Big5[participant_id],
Familiarity = Familiarity[participant_id],
Expressibility = expressibility_score,
CommAtt = attempt,  # Correctly set the attempt number
Eff = Eff,
TrialNumber = trial_number  # Set trial number for this attempt
))
# Increment the trial number after each attempt
trial_number <- trial_number + 1
}
}
return(participant_data)
}
# Simulate data for all participants
for (i in participants) {
final_data <- rbind(final_data, simulate_participant(i))
}
# Preview the first few rows of the final data
head(final_data)
# Create a boxplot comparing Effort across different Communicative Attempts
ggplot(final_data, aes(x = as.factor(CommAtt), y = Eff)) +
geom_boxplot(aes(fill = as.factor(CommAtt))) +
labs(title = "Comparison of Effort Across Communicative Attempts",
x = "Communicative Attempts",
y = "Effort",
fill = "CommAtt") +
theme_minimal() +
theme(legend.position = "none")
final_data$CommAtt <- as.factor(final_data$CommAtt)
final_data$Modality <- as.factor(final_data$Modality)
final_data$Participant <- as.factor(final_data$Participant)
final_data$Concept <- as.factor(final_data$Concept)
final_data$TrialNumber <- as.numeric(final_data$TrialNumber)  # Ensure TrialNumber is numeric
contrasts(final_data$CommAtt) <- MASS::contr.sdif(3)
contrasts(final_data$Modality) <- contr.sum(3)/2
# Set seed for reproducibility
set.seed(0209)
# Define participants, total unique concepts, and modalities
n_participants <- 120
n_total_concepts <- 21  # Total unique concepts
n_concepts_per_participant <- 21  # Each participant works with 21 concepts
n_modalities <- 3  # gesture, vocal, combined
# Generate participant IDs
participants <- 1:n_participants
# Simulate Big5 personality traits (standardized between 0 and 1) and Familiarity (between 0 and 1) for participants
Big5 <- runif(n_participants, min = 0, max = 1)  # Continuous values between 0 and 1
Familiarity <- runif(n_participants, min = 0, max = 1)  # Continuous values between 0 and 1
# Create a matrix to hold expressibility values for each concept in each modality
expressibility_matrix <- matrix(runif(n_total_concepts * n_modalities, min = 0, max = 1), nrow = n_total_concepts, ncol = n_modalities)
# Randomly sample 21 unique concepts for each participant
final_data <- data.frame()
# Define a function to assign CommAtt and Eff for a single participant
simulate_participant <- function(participant_id) {
# Randomly sample 21 unique concepts from the total pool of 84
selected_concepts <- sample(1:n_total_concepts, n_concepts_per_participant)
participant_data <- data.frame()
trial_number <- 1  # Initialize trial number
for (concept_id in selected_concepts) {
# Randomly determine the modality for the concept
modality <- sample(c("gesture", "vocal", "combined"), 1)
# Calculate expressibility based on modality
expressibility_score <- ifelse(modality == "vocal", expressibility_matrix[concept_id, 1] * 0.6,
ifelse(modality == "gesture", expressibility_matrix[concept_id, 2],
expressibility_matrix[concept_id, 3] * 1.5))
# Determine Communicative Attempts based solely on expressibility, familiarity, and Big5
base_prob <- c(0.33, 0.33, 0.33)  # Equal chance for 1, 2, or 3 attempts
# Modify probabilities based on familiarity, Big5, and expressibility
adjusted_prob <- base_prob * c(1 - Familiarity[participant_id], # 3 times for each
1 - Familiarity[participant_id],
1 - Familiarity[participant_id]) *
c(1 - Big5[participant_id],
1 - Big5[participant_id],
1 - Big5[participant_id]) *
c(1 - expressibility_score,
1 - expressibility_score,
1 - expressibility_score)
# Normalize the adjusted probabilities
adjusted_prob <- adjusted_prob / sum(adjusted_prob)
# Sample the number of communicative attempts based on adjusted probabilities
n_attempts <- sample(1:3, 1, prob = adjusted_prob)
# Loop through the number of attempts and increment CommAtt correctly
for (attempt in 1:n_attempts) {
# Calculate Eff for the first attempt
if (attempt == 1) {
Eff <- 1.15 * Big5[participant_id] +
1.10 * Familiarity[participant_id] +
1.20 * expressibility_score +
rnorm(1, mean = 1, sd = 0.5)
# Adjust Eff based on modality
if (modality == "combined") {
Eff <- Eff * 0.7  # Slight moderation for combined modality
}
}
# Adjust Eff for subsequent attempts
if (attempt == 2) {
Eff <- 1.15 * Big5[participant_id] +
1.10 * Familiarity[participant_id] +
1.20 * expressibility_score +
rnorm(1, mean = 1, sd = 0.5)
Eff <- Eff * 1.50  # Multiply effort by 1.50 for the second attempt
} else if (attempt == 3) {
Eff <- 1.15 * Big5[participant_id] +
1.10 * Familiarity[participant_id] +
1.20 * expressibility_score +
rnorm(1, mean = 1, sd = 0.5)
Eff <- Eff * 0.70  # Multiply effort by 0.70 for the third attempt
}
# Create row for each attempt
participant_data <- rbind(participant_data, data.frame(
Participant = participant_id,
Concept = concept_id,
Modality = modality,
Big5 = Big5[participant_id],
Familiarity = Familiarity[participant_id],
Expressibility = expressibility_score,
CommAtt = attempt,  # Correctly set the attempt number
Eff = Eff,
TrialNumber = trial_number  # Set trial number for this attempt
))
# Increment the trial number after each attempt
trial_number <- trial_number + 1
}
}
return(participant_data)
}
# Simulate data for all participants
for (i in participants) {
final_data <- rbind(final_data, simulate_participant(i))
}
# Preview the first few rows of the final data
head(final_data)
final_data$CommAtt <- as.factor(final_data$CommAtt)
final_data$Modality <- as.factor(final_data$Modality)
final_data$Participant <- as.factor(final_data$Participant)
final_data$Concept <- as.factor(final_data$Concept)
final_data$TrialNumber <- as.numeric(final_data$TrialNumber)  # Ensure TrialNumber is numeric
contrasts(final_data$CommAtt) <- MASS::contr.sdif(3)
contrasts(final_data$Modality) <- contr.sum(3)/2
final_data$TrialNumber_c <- final_data$TrialNumber - median(range(final_data$TrialNumber))
range(final_data$TrialNumber_c)
range(final_data$TrialNumber)
final_data$Familiarity <- final_data$Familiarity - median(range(final_data$Familiarity))
final_data$Big5 <- final_data$Big5 - median(range(final_data$Big5))
final_data <-
final_data |>
group_by(Modality) |>
mutate(Expressibility_z = (Expressibility - mean(Expressibility))/ sd(final_data$Expressibility, na.rm = T)) |>
ungroup()
library(ggplot2)
library(patchwork)
library(bayesplot)
library(brms)
library(beepr)
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())
fit_eff7 <- readRDS(here("09_Analysis_Modeling", "models", "fit_eff7.rds"))
pp_check(fit_eff7, type = "dens_overlay", ndraws = 500)
pp_check(fit_eff7, type = "error_scatter_avg")
fit_eff_dag <- readRDS(here("09_Analysis_Modeling", "models", "fit_eff_dag.rds"))
fit_eff_2 <- readRDS(here("09_Analysis_Modeling", "models", "fit_eff_2.rds"))
fit_eff3 <- readRDS(here("09_Analysis_Modeling", "models", "fit_eff3.rds"))
fit_eff3p <- readRDS(here("09_Analysis_Modeling", "models", "fit_eff3p.rds"))
fit_eff4 <- readRDS(here("09_Analysis_Modeling", "models", "fit_eff4.rds"))
fit_eff5 <- readRDS(here("09_Analysis_Modeling", "models", "fit_eff5.rds"))
fit_eff6 <- readRDS(here("09_Analysis_Modeling", "models", "fit_eff6.rds"))
model_list <- list(fit_eff_dag, fit_eff2, fit_eff3, fit_eff3p, fit_eff4, fit_eff5, fit_eff6, fit_eff7)
model_list <- list(fit_eff_dag, fit_eff_2, fit_eff3, fit_eff3p, fit_eff4, fit_eff5, fit_eff6, fit_eff7)
lapply(model_list, function(model) {
summary(model)$rhat  # Should be close to 1 (below 1.01 ideally)
})
# Extract R-hat values for each model
rhat_list <- lapply(model_list, function(model) {
rhat_values <- rhat(model)
data.frame(model = deparse(substitute(model)),
max_rhat = max(rhat_values),
min_rhat = min(rhat_values))
})
# Combine and inspect
do.call(rbind, rhat_list)
lapply(model_list, function(model) {
summary(model)$n_eff  # Should be reasonably large (>1000 per parameter ideally)
})
# Extract n_eff values for each model
neff_list <- lapply(model_list, function(model) {
neff_values <- neff_ratio(model)
data.frame(model = deparse(substitute(model)),
min_neff = min(neff_values),
max_neff = max(neff_values))
})
# Combine and inspect
do.call(rbind, neff_list)
# Create a data frame to store n_eff and n_eff ratio for each model
n_eff_summary <- lapply(list(fit_eff1, fit_eff2, fit_eff3, fit_eff4, fit_eff5, fit_eff6, fit_eff7), function(model) {
data.frame(
model = deparse(substitute(model)),
n_eff = summary(model)$n_eff,         # Extract effective sample size
n_eff_ratio = neff_ratio(model)      # Extract n_eff ratio
)
}) %>% bind_rows()
# Create a data frame to store n_eff and n_eff ratio for each model
n_eff_summary <- lapply(model_list), function(model) {
# Create a data frame to store n_eff and n_eff ratio for each model
n_eff_summary <- lapply(model_list, function(model) {
data.frame(
model = deparse(substitute(model)),
n_eff = summary(model)$n_eff,         # Extract effective sample size
n_eff_ratio = neff_ratio(model)      # Extract n_eff ratio
)
}) %>% bind_rows()
# Extract n_eff values for each model
neff_list <- lapply(model_list, function(model) {
neff_values <- neff_ratio(model)
data.frame(model = deparse(substitute(model)),
min_neff = min(neff_values),
max_neff = max(neff_values))
})
# Combine and inspect
do.call(rbind, neff_list)
# Extract n_eff values for each model
neff_ratio_list <- lapply(model_list, function(model) {
neff_values <- neff_ratio(model)              # Here we calculate ratio (not the raw number of effective samples)
data.frame(model = deparse(substitute(model)),
min_neff = min(neff_values),
max_neff = max(neff_values))
})
# Combine and inspect
do.call(rbind, neff_ratio_list)
# Extract n_eff values for each model
neff_list <- lapply(model_list, function(model) {
neff_values <- neff(model)              # Here we calculate ratio (not the raw number of effective samples)
data.frame(model = deparse(substitute(model)),
min_neff = min(neff_values),
max_neff = max(neff_values))
})
# Extract n_eff values for each model
neff_ratio_list <- lapply(model_list, function(model) {
neff_values <- neff_ratio(model)              # Here we calculate ratio (not the raw number of effective samples)
data.frame(model = deparse(substitute(model)),
min_neff = min(neff_values),
max_neff = max(neff_values),
mean_neff = mean(neff_values))
})
# Combine and inspect
do.call(rbind, neff_ratio_list)
neff(fit_eff_dag)
effective_sample(fit_eff_dag)
library(bayestestR)
effective_sample(fit_eff_dag)
effective_sample(fit_eff3)
effective_sample(fit_eff3p)
effective_sample(fit_eff3)
effective_sample(fit_eff3p) #
effective_sample(fit_eff7)
# Compare models using Leave-One-Out Cross-Validation (LOO)
loo_list <- lapply(model_list, loo)
# Print comparison
loo_compare(loo_list)
View(fit_eff_2)
# First we need to add the loo and waic to the model objects (recommended workflow)
fit_eff_dag <- add_criterion(fit_eff_dag, criterion = c("loo", "waic"))
# First we need to add the loo and waic to the model objects (recommended workflow)
fit_eff_dag <- add_criterion(fit_eff_dag, criterion = c("loo", "waic"))
fit_eff_2 <- add_criterion(fit_eff_2, criterion = c("loo", "waic"))
fit_eff3 <- add_criterion(fit_eff3, criterion = c("loo", "waic"))
fit_eff3p <- add_criterion(fit_eff3p, criterion = c("loo", "waic"))
fit_eff4 <- add_criterion(fit_eff4, criterion = c("loo", "waic"))
fit_eff5 <- add_criterion(fit_eff5, criterion = c("loo", "waic"))
fit_eff6 <- add_criterion(fit_eff6, criterion = c("loo", "waic"))
fit_eff7 <- add_criterion(fit_eff7, criterion = c("loo", "waic"))
waic(fit_eff_dag)
fit_eff_dag$waic
fit_eff_dag$waic
fit_eff_dag$loo
fit_eff_2$loo
fit_eff3$loo
fit_eff4$loo
fit_eff_dag
fit_eff_dag <- add_criterion(fit_eff_dag, criterion = c("loo", "waic"))
fit_eff_dag <- add_criterion(fit_eff_dag, criterion = c("loo", "waic"))
fit_eff_dag$waic
fit_eff_dag$loo
loo_compare(fit_eff_dag, fit_eff_2, criterion = "loo")
loo_compare(fit_eff_dag, fit_eff_2, fit_eff3, criterion = "loo")
loo_compare(model_list, criterion = "loo")
loo_compare(fit_eff_dag, fit_eff_2, fit_eff3, fit_eff3p, fit_eff4, fit_eff5, fit_eff6, fit_eff7, criterion = "loo")
(mw <- model_weights(fit_eff_dag, fit_eff_2, fit_eff3, fit_eff3p, fit_eff4, fit_eff5, fit_eff6, fit_eff7))
fit_eff_dag$criteria$waic
fit_eff_dag$criteria$loo
loo_compare(fit_eff_dag, fit_eff_2, fit_eff3, fit_eff3p, fit_eff4, fit_eff5, fit_eff6, fit_eff7, criterion = "loo")
loo_compare(fit_eff_dag, fit_eff_2, fit_eff3, fit_eff3p, fit_eff4, fit_eff5, fit_eff6, fit_eff7, criterion = "waic")
l <- loo_compare(fit_eff_dag, fit_eff_2, fit_eff3, fit_eff3p, fit_eff4, fit_eff5, fit_eff6, fit_eff7, criterion = "waic")
w <- loo_compare(fit_eff_dag, fit_eff_2, fit_eff3, fit_eff3p, fit_eff4, fit_eff5, fit_eff6, fit_eff7, criterion = "waic")
l <- loo_compare(fit_eff_dag, fit_eff_2, fit_eff3, fit_eff3p, fit_eff4, fit_eff5, fit_eff6, fit_eff7, criterion = "loo")
cbind(waic_diff = w[,1] * -2,
se = w[,2] * 2)
print(l, simplify = F)
print(w, simplify = F)
w[, 7:8] %>%
data.frame() %>%
rownames_to_column("model_name") %>%
mutate(model_name = fct_reorder(model_name, waic, .desc = T)) %>%
ggplot(aes(x = waic, y = model_name,
xmin = waic - se_waic,
xmax = waic + se_waic)) +
geom_pointrange(color = carto_pal(7, "BurgYl")[7],
fill = carto_pal(7, "BurgYl")[5], shape = 21) +
labs(title = "My custom WAIC plot",
x = NULL, y = NULL) +
theme(axis.ticks.y = element_blank())
library(tibble)
w[, 7:8] %>%
data.frame() %>%
rownames_to_column("model_name") %>%
mutate(model_name = fct_reorder(model_name, waic, .desc = T)) %>%
ggplot(aes(x = waic, y = model_name,
xmin = waic - se_waic,
xmax = waic + se_waic)) +
geom_pointrange(color = carto_pal(7, "BurgYl")[7],
fill = carto_pal(7, "BurgYl")[5], shape = 21) +
labs(title = "My custom WAIC plot",
x = NULL, y = NULL) +
theme(axis.ticks.y = element_blank())
library(fct_reorder)
install.packages('fct_reorder')
library(tibble)
library(fct_reorder)
library(tidyverse)
w[, 7:8] %>%
data.frame() %>%
rownames_to_column("model_name") %>%
mutate(model_name = fct_reorder(model_name, waic, .desc = T)) %>%
ggplot(aes(x = waic, y = model_name,
xmin = waic - se_waic,
xmax = waic + se_waic)) +
geom_pointrange(color = carto_pal(7, "BurgYl")[7],
fill = carto_pal(7, "BurgYl")[5], shape = 21) +
labs(title = "My custom WAIC plot",
x = NULL, y = NULL) +
theme(axis.ticks.y = element_blank())
install.packages("rcartocolor")
library(rcartocolor)
library(tibble)
library(tidyverse)
library(rcartocolor)
w[, 7:8] %>%
data.frame() %>%
rownames_to_column("model_name") %>%
mutate(model_name = fct_reorder(model_name, waic, .desc = T)) %>%
ggplot(aes(x = waic, y = model_name,
xmin = waic - se_waic,
xmax = waic + se_waic)) +
geom_pointrange(color = carto_pal(7, "BurgYl")[7],
fill = carto_pal(7, "BurgYl")[5], shape = 21) +
labs(title = "My custom WAIC plot",
x = NULL, y = NULL) +
theme(axis.ticks.y = element_blank())
library(tibble)
library(tidyverse)
library(rcartocolor)
w[, 7:8] %>%
data.frame() %>%
rownames_to_column("model_name") %>%
mutate(model_name = fct_reorder(model_name, waic, .desc = T)) %>%
ggplot(aes(x = waic, y = model_name,
xmin = waic - se_waic,
xmax = waic + se_waic)) +
geom_pointrange(color = carto_pal(7, "BurgYl")[7],
fill = carto_pal(7, "BurgYl")[5], shape = 21) +
labs(title = "WAIC plot",
x = NULL, y = NULL) +
theme(axis.ticks.y = element_blank())
model_weights(model_list, weights = "waic") %>%
round(digits = 2)
model_weights(fit_eff_dag, fit_eff_2, fit_eff3, fit_eff3p, fit_eff4, fit_eff5, fit_eff6, fit_eff7, weights = "waic") %>%
round(digits = 2)
pp_check(fit_eff_2, type = "dens_overlay")
View(final_data)
View(final_data)
pp_check(fit_eff7, type = "dens_overlay", ndraws = 300)
View(final_data)
hist(final_data$Eff)
fit_eff8 <- brm(Eff ~ 1 + CommAtt + Modality + Big5 + Familiarity + Expressibility_z +  (1 + CommAtt | Participant) + (1 + CommAtt | Concept) + (1 | TrialNumber_c),
data = final_data,
family = lognormal(),
iter = 4000,
cores = 4)
saveRDS(fit_eff8, here("09_Analysis_Modeling", "models", "fit_eff8.rds"))
# summary
summary(fit_eff8)
pp_check(fit_eff8, type = "dens_overlay")
pp_check(fit_eff8, type = "dens_overlay")
pp_check(fit_eff8, type = "error_scatter_avg")
pp_check(fit_eff8, type = "error_scatter_avg")
pp_check(fit_eff7, type = "error_scatter_avg")
model_list <- list(fit_eff_dag, fit_eff_2, fit_eff3, fit_eff3p, fit_eff4, fit_eff5, fit_eff6, fit_eff7, fit_eff8)
# Extract R-hat values for each model
rhat_list <- lapply(model_list, function(model) {
rhat_values <- rhat(model)
data.frame(model = deparse(substitute(model)),
max_rhat = max(rhat_values),
min_rhat = min(rhat_values))
})
# Combine and inspect
do.call(rbind, rhat_list)
plot(conditional_effects(fit_eff8), points = TRUE)
# Compute estimated marginal means on log-scale
em_mdl_fit_eff8 <- emmeans(fit_eff8, ~ Eff)
install.packages('emmeans')
library(emmeans)
# Compute estimated marginal means on log-scale
em_mdl_fit_eff8 <- emmeans(fit_eff8, ~ Eff)
library(emmeans)
# Compute estimated marginal means on log-scale
em_mdl_fit_eff8 <- emmeans(fit_eff8, ~ CommAtt)
#Backtransform the post.beta values
em_mdl_fit_eff8@post.beta <- exp(em_mdl_fit_eff8@post.beta)
print(em_mdl_fit_eff8)
library(emmeans)
# Compute estimated marginal means on log-scale
em_mdl_fit_eff8 <- emmeans(fit_eff8, ~ Modality)
#Backtransform the post.beta values
em_mdl_fit_eff8@post.beta <- exp(em_mdl_fit_eff8@post.beta)
print(em_mdl_fit_eff8)
library(emmeans)
# Compute estimated marginal means on log-scale
em_mdl_fit_eff8 <- emmeans(fit_eff8, ~ CommAtt)
#Backtransform the post.beta values
em_mdl_fit_eff8@post.beta <- exp(em_mdl_fit_eff8@post.beta)
print(em_mdl_fit_eff8)
# Compute estimated marginal means on log-scale
em_mdl_fit_eff8 <- emmeans(fit_eff8) #~ CommAtt
# Compute estimated marginal means on log-scale
em_mdl_fit_eff8 <- emmeans(fit_eff8, ~ CommAtt) #~ CommAtt
#Backtransform the post.beta values
em_mdl_fit_eff8@post.beta <- exp(em_mdl_fit_eff8@post.beta)
print(em_mdl_fit_eff8)
# summary
summary(fit_eff7)
#Extract posterior samples of the fixed effects coefficients
as_draws_df(fit_eff8) %>%
#Select fixed effects for percProm levels
select(starts_with("b_CommAtt")) %>%
#Rename columns to match percProm levels
rename_with(~ str_replace(.x, "b_CommAtt", "CommAtt"), starts_with("b_CommAtt")) %>%
#Compute differences between percProm levels
mutate(
diff_1_2 = exp(CommAtt2) - exp(CommAtt1),
diff_1_3 = exp(CommAtt3) - exp(CommAtt1),
diff_2_3 = exp(CommAtt3) - exp(CommAtt2)
) %>%
#Gather differences into long format
pivot_longer(
cols = starts_with("diff_"),
names_to = "Comparison",
values_to = "Difference"
) %>%
#Group by comparison to compute summary statistics
group_by(Comparison) %>%
summarise(
Estimate = mean(Difference),
Est.Error = sd(Difference),
CI.Lower = quantile(Difference, 0.025),
CI.Upper = quantile(Difference, 0.975),
Post.Prob = if_else(Estimate > 0,
mean(Difference > 0) * 100,
mean(Difference < 0) * 100)
) %>%
ungroup() %>%
#Add significance stars based on posterior probability
mutate(
Star = ifelse(Post.Prob > 95 | Post.Prob < 5, "*", ""),
Estimate = round(Estimate, 3),
Est.Error = round(Est.Error, 3),
CI.Lower = round(CI.Lower, 3),
CI.Upper = round(CI.Upper, 3),
Post.Prob = round(Post.Prob, 2)
) %>%
#Select and arrange the final columns
select(Comparison, Estimate, Est.Error, CI.Lower, CI.Upper, Post.Prob, Star) %>%
arrange(Comparison)
# summary
summary(fit_eff8)
