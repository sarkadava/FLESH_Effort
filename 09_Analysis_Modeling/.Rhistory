Eff <- Eff * b_comatt2
} else if (attempt == 3) {
Eff <- Eff * b_comatt3
}
# Adjust effort based on previous answer similarity
if (!is.na(prev_answer_similarity)) {
Eff <- Eff * (1 + (1 - prev_answer_similarity) * b_prevan)
}
# Store row
participant_data <- rbind(participant_data, data.frame(
Participant = participant_id,
Concept = concept_id,
Modality = modality,
Big5 = Big5[participant_id],
Familiarity = Familiarity[participant_id],
Expressibility = expressibility_score,
CommAtt = attempt,
Eff = Eff,
TrialNumber = trial_number,
PrevAn = prev_answer_similarity
))
# Update for next attempt
trial_number <- trial_number + 1
prev_answer_similarity <- runif(1, min = 0, max = 1)  # Simulate next similarity
}
}
return(participant_data)
}
# Simulate data for all participants
final_data_synt <- do.call(rbind, lapply(participants, simulate_participant))
# Preview results
head(final_data_synt, n=15)
hist(final_data_synt$Eff, breaks=100)
# Create a boxplot comparing Effort across different Communicative Attempts
ggplot(final_data_synt, aes(x = as.factor(CommAtt), y = Eff)) +
geom_boxplot(aes(fill = as.factor(CommAtt))) +
labs(title = "Comparison of Effort Across Communicative Attempts",
x = "Communicative Attempts",
y = "Effort",
fill = "CommAtt") +
theme_minimal() +
theme(legend.position = "none")
# Save the synthetic data for future purposes
write.csv(final_data_synt, file = here("09_Analysis_Modeling", "datasets", "synthetic_data.csv"), row.names = FALSE)
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())
final_data <- read_csv(paste0(datasets, "synthetic_data.csv"))
final_data$CommAtt <- as.factor(final_data$CommAtt)
final_data$Modality <- as.factor(final_data$Modality)
final_data$Participant <- as.factor(final_data$Participant)
final_data$Concept <- as.factor(final_data$Concept)
final_data$TrialNumber <- as.numeric(final_data$TrialNumber)  # Ensure TrialNumber is numeric
contrasts(final_data$CommAtt) <- MASS::contr.sdif(3)
contrasts(final_data$Modality) <- contr.sum(3)/2
final_data$TrialNumber_c <- final_data$TrialNumber - median(range(final_data$TrialNumber))
final_data$Familiarity <- final_data$Familiarity - median(range(final_data$Familiarity))
final_data$Big5 <- final_data$Big5 - median(range(final_data$Big5))
# For now, we will just center Familiarity and Big5 because we created them synthetically. But the real data have these two variables already z-scored
final_data <-
final_data |>
group_by(Modality) |>
mutate(Expressibility_z = (Expressibility - mean(Expressibility))/ sd(final_data$Expressibility, na.rm = T)) |>
ungroup()
# Calculate Effort Change (Difference)
final_data_2 <- final_data %>%
group_by(Participant, Concept) %>%
mutate(
Effort_1 = Eff[CommAtt == 1][1],  # Effort for attempt 1
Effort_2 = Eff[CommAtt == 2][1],  # Effort for attempt 2
Effort_3 = Eff[CommAtt == 3][1],  # Effort for attempt 3
Effort_Change_1_to_2 = case_when(
CommAtt == 2 & !is.na(Effort_1) ~ Eff - Effort_1,  # Change from 1st to 2nd attempt
TRUE ~ NA_real_
),
Effort_Change_2_to_3 = case_when(
CommAtt == 3 & !is.na(Effort_2) ~ Eff - Effort_2,  # Change from 2nd to 3rd attempt
TRUE ~ NA_real_
)
) %>%
ungroup()
# Collide changes into a single column
final_data_2 <- final_data_2 %>%
mutate(
Effort_Change = coalesce(Effort_Change_1_to_2, Effort_Change_2_to_3)
)
# Remove unnecessary columns
final_data_2 <- subset(final_data_2, select = -c(Effort_1, Effort_2, Effort_3, Effort_Change_1_to_2, Effort_Change_2_to_3))
# View the result
head(final_data_2, n=15)
# Filter out CommAtt == 1
filtered_data <- final_data_2[final_data_2$CommAtt != 1, ]
ggplot(filtered_data, aes(x = PrevAn, y = Eff)) +
geom_point(alpha = 0.6, color = "blue") +  # Scatter points
geom_smooth(method = "lm", color = "red", se = FALSE) +  # Regression line
labs(x = "Previous Answer Similarity (PrevAn)",
y = "Effort (Eff)",
title = "Relationship between Effort and Previous Answer Similarity") +
theme_minimal()
ggplot(filtered_data, aes(x = PrevAn, y = Effort_Change)) +
geom_point(alpha = 0.6, color = "blue") +  # Scatter points
geom_smooth(method = "lm", color = "red", se = FALSE) +  # Regression line
labs(x = "Previous Answer Similarity (PrevAn)",
y = "Effort (Eff)",
title = "Relationship between Effort Change and Previous Answer Similarity") +
theme_minimal()
hist(filtered_data$Effort_Change, breaks=100)
daggy_h2 <- dagitty('dag {
EffChange [outcome,pos="0,0"]
PrevAn [exposure,pos="-2,0"]
Big5 [pos="-1.5,1"]
CommAtt [pos="0,-1.5"]
Conc [pos="-2,-1.5"]
Expr [pos="-1.5,-1.5"]
Fam [pos="-0.5,1"]
Pcn [pos="-1,2"]
TrNum [pos="-2.5,-1.5"]
Mod [pos="-1,0.5"]
Big5 -> PrevAn
Big5 -> EffChange
CommAtt -> EffChange
Conc -> Expr
Expr -> PrevAn
Expr -> EffChange
Fam -> PrevAn
Fam -> EffChange
Mod -> EffChange
Mod -> PrevAn
Pcn -> Big5
Pcn -> PrevAn
Pcn -> EffChange
Pcn -> Fam
TrNum -> PrevAn
TrNum -> EffChange
Conc -> PrevAn
Conc -> EffChange
PrevAn -> EffChange
PrevAn -> CommAtt
}')
# Use ggdag for a cleaner visualization
d2 <- ggdag(daggy_h2, text = TRUE, use_labels = "name") +
theme_dag() +
ggtitle("Causal DAG for Effort Change") +
theme(plot.title = element_text(hjust = 0.5))
d2
dagitty::adjustmentSets(daggy_h2, exposure = "PrevAn", outcome = "EffChange")
filtered_data$CommAtt <- as.factor(filtered_data$CommAtt)
filtered_data$Modality <- as.factor(filtered_data$Modality)
filtered_data$Participant <- as.factor(filtered_data$Participant)
filtered_data$Concept <- as.factor(filtered_data$Concept)
filtered_data$TrialNumber <- as.numeric(filtered_data$TrialNumber)  # Ensure TrialNumber is numeric
contrasts(filtered_data$CommAtt) <- MASS::contr.sdif(2)
filtered_data$CommAtt
View(filtered_data)
View(filtered_data)
contrasts(filtered_data$CommAtt) <- contr.sum(2)/2
contrasts(filtered_data$Modality) <- contr.sum(3)/2
contrasts(filtered_data$CommAtt) <- contr.sum(2)/2
contrasts(filtered_data$CommAtt) <- contr.sum(2)/1
contrasts(filtered_data$CommAtt) <- contr.sum(2)/1
filtered_data$CommAtt <- as.factor(filtered_data$CommAtt)
contrasts(filtered_data$CommAtt) <- contr.sum(2)/1
filtered_data$CommAtt <- as.factor(filtered_data$CommAtt)
filtered_data$CommAtt <- droplevels(filtered_data$CommAtt)
filtered_data$CommAtt <- as.factor(filtered_data$CommAtt)
contrasts(filtered_data$CommAtt) <- contr.sum(2)/1
contrasts(filtered_data$Modality) <- contr.sum(3)/2
filtered_data$TrialNumber_c <- filtered_data$TrialNumber - median(range(filtered_data$TrialNumber))
filtered_data$Familiarity <- filtered_data$Familiarity - median(range(filtered_data$Familiarity))
filtered_data$Big5 <- filtered_data$Big5 - median(range(filtered_data$Big5))
filtered_data <-
filtered_data |>
group_by(Modality) |>
mutate(Expressibility_z = (Expressibility - mean(Expressibility))/ sd(filtered_data$Expressibility, na.rm = T)) |>
ungroup()
filtered_data <-
filtered_data |>
mutate(PrevAn_z = (PrevAn - mean(PrevAn))/ sd(filtered_data$PrevAn, na.rm = T)) |>
ungroup()
# To test, we will also center both expressibility and prevan to see what offers better interpretation
filtered_data$PrevAn_c <- filtered_data$PrevAn - median(range(filtered_data$PrevAn))
filtered_data <-
filtered_data |>
group_by(Modality) |>
mutate(Expressibility_c = Expressibility - median(range(Expressibility))) |>
ungroup()
h2.m1 <- brm(Effort_Change ~ 1 + PrevAn_z + CommAtt + Familiarity + Big5 + Expressibility_z + TrialNumber_c + Modality + (1 | Participant) + (1 | Concept),
data = filtered_data,
iter = 4000,
cores = 4)
h2.m1 <- brm(Effort_Change ~ 1 + PrevAn_z + CommAtt + Familiarity + Big5 + Expressibility_z + TrialNumber_c + Modality + (1 | Participant) + (1 | Concept),
data = filtered_data,
iter = 4000,
cores = 4)
# Add criterions for later diagnostics
h2.m1 <- add_criterion(h2.m1, criterion = c("loo", "waic"))
# Calculate also variance explained (R^2)
h2.m1_R2 <- bayes_R2(h2.m1)
# Save both as objects
saveRDS(h2.m1, here("09_Analysis_Modeling", "models", "h2.m1.rds"))
saveRDS(h2.m1_R2, here("09_Analysis_Modeling", "models", "h2.m1_R2.rds"))
beep(5)
# Summary
summary(h2.m1)
plot(h2.m1)
plot(conditional_effects(h2.m1), points = TRUE)
pp_check(h2.m1, type = "dens_overlay")
pp_check(h2.m1, type = "error_scatter_avg")
h2.m1_R2
h2.m2 <- brm(Effort_Change ~ 1 + PrevAn_z + CommAtt + Modality + Big5 + Familiarity + Expressibility_z +  (1 + PrevAn || Participant) + (1 + PrevAn || Concept) + (1 | TrialNumber_c),
data = filtered_data,
family = lognormal(),
iter = 4000,
cores = 4)
h2.m2 <- brm(Effort_Change ~ 1 + PrevAn_z + CommAtt + Modality + Big5 + Familiarity + Expressibility_z +  (1 + PrevAn || Participant) + (1 + PrevAn || Concept) + (1 | TrialNumber_c),
data = filtered_data,
family = mixture(gaussian, gaussian),
iter = 4000,
cores = 4)
# Add criterions for later diagnostics
h2.m2 <- add_criterion(h2.m2, criterion = c("loo", "waic"))
# Calculate also variance explained (R^2)
h2.m2_R2 <- bayes_R2(h2.m2)
# Save both as objects
saveRDS(h2.m2, here("09_Analysis_Modeling", "models", "h2.m2.rds"))
saveRDS(h2.m2_R2, here("09_Analysis_Modeling", "models", "h2.m2_R2.rds"))
beep(5)
# Summary
summary(h2.m2)
plot(h2.m2)
pp_check(h2.m2, type = "dens_overlay")
pp_check(h2.m2, type = "dens_overlay")
pp_check(h2.m2, type = "error_scatter_avg")
pp_check(h2.m2, type = "error_scatter_avg")
pp_check(h2.m2, type = "error_scatter_avg")
h2.m2_R2
plot(conditional_effects(h2.m2), points = TRUE)
ggplot(filtered_data, aes(x = PrevAn, y = Eff)) +
geom_point(alpha = 0.6, color = "blue") +  # Scatter points
geom_smooth(method = "loess", color = "red", se = FALSE) +  # loess for potential nonlinearity
labs(x = "Previous Answer Similarity (PrevAn)",
y = "Effort (Eff)",
title = "Relationship between Effort and Previous Answer Similarity") +
theme_minimal()
# Get rid of NAs in the predictor
d <-
final_data_2 %>%
drop_na(PrevAn)
# And convert all that is necessary to factor/numerical
d$CommAtt <- as.factor(d$CommAtt)
d$Modality <- as.factor(d$Modality)
d$Participant <- as.factor(d$Participant)
d$Concept <- as.factor(d$Concept)
d$TrialNumber <- as.numeric(d$TrialNumber)
d %>%
select_if(is.numeric) %>%  # Select only numeric columns
pivot_longer(cols = everything(), names_to = "key", values_to = "value") %>%
group_by(key) %>%
summarise(
mean = mean(value, na.rm = TRUE),
sd   = sd(value, na.rm = TRUE),
ll   = quantile(value, probs = 0.055, na.rm = TRUE),
ul   = quantile(value, probs = 0.945, na.rm = TRUE)
) %>%
mutate(across(where(is.double), round, digits = 2))
print(d)
num_knots <- 7
knot_list <- quantile(d$PrevAn, probs = seq(from = 0, to = 1, length.out = num_knots))
knot_list
d %>%
ggplot(aes(x = PrevAn, y = Effort_Change_Ratio)) +
geom_vline(xintercept = knot_list, color = "white", alpha = 1/2) +
geom_point(color = "#ffb7c5", alpha = 1/2) +
theme_bw() +
theme(panel.background = element_rect(fill = "#4f455c"),
panel.grid = element_blank())
d %>%
ggplot(aes(x = PrevAn, y = Effort_Change)) +
geom_vline(xintercept = knot_list, color = "white", alpha = 1/2) +
geom_point(color = "#ffb7c5", alpha = 1/2) +
theme_bw() +
theme(panel.background = element_rect(fill = "#4f455c"),
panel.grid = element_blank())
d %>%
ggplot(aes(x = PrevAn, y = Effort_Change)) +
geom_vline(xintercept = knot_list, color = "white", alpha = 1/2) +
geom_point(color = "#ffb7c5", alpha = 1/2) +
theme_bw() +
theme(panel.background = element_rect(fill = "#4f455c"),
panel.grid = element_blank())
library(splines)
B <- bs(d$PrevAn,
knots = knot_list[-c(1, num_knots)],
degree = 3, # cubic spline
intercept = TRUE)
B <- bs(d$PrevAn,
knots = knot_list[-c(1, num_knots)],
degree = 3, # cubic spline
intercept = TRUE)
# wrangle a bit
b <-
B %>%
data.frame() %>%
set_names(str_c(0, 1:4), 5:9) %>%
bind_cols(select(d, PrevAn)) %>%
pivot_longer(-PrevAn,
names_to = "bias_function",
values_to = "bias")
# plot
b %>%
ggplot(aes(x = PrevAn, y = bias, group = bias_function)) +
geom_vline(xintercept = knot_list, color = "white", alpha = 1/2) +
geom_line(color = "#ffb7c5", alpha = 1/2, linewidth = 1.5) +
ylab("bias value") +
theme_bw() +
theme(panel.background = element_rect(fill = "#4f455c"),
panel.grid = element_blank())
d2 <-
d %>%
mutate(B = B)
# take a look at the structure of `d3
d2 %>% glimpse()
h2.s1 <-
brm(data = d2,
family = gaussian,
Effort_Change ~ 1 + B,
prior = c(prior(normal(100, 10), class = Intercept),
prior(normal(0, 10), class = b),
prior(exponential(1), class = sigma)),
iter = 4000, warmup = 2000, chains = 4, cores = 4,
seed = 4)
# Add criterions for later diagnostics
h2.s1 <- add_criterion(h2.s1, criterion = c("loo", "waic"))
# Calculate also variance explained (R^2)
h2.s1_R2 <- bayes_R2(h2.s1)
# Save both as objects
saveRDS(h2.s1, here("09_Analysis_Modeling", "models", "h2.s1.rds"))
saveRDS(h2.s1_R2, here("09_Analysis_Modeling", "models", "h2.s1_R2.rds"))
# Summary
print(h2.s1)
post <- as_draws_df(h2.s1)
post %>%
select(b_B1:b_B9) %>%
set_names(c(str_c(0, 1:4), 5:9)) %>%
pivot_longer(everything(), names_to = "bias_function") %>%
group_by(bias_function) %>%
summarise(weight = mean(value)) %>%
full_join(b, by = "bias_function") %>%
# plot
ggplot(aes(x = PrevAn, y = bias * weight, group = bias_function)) +
geom_vline(xintercept = knot_list, color = "white", alpha = 1/2) +
geom_line(color = "#ffb7c5", alpha = 1/2, linewidth = 1.5) +
theme_bw() +
theme(panel.background = element_rect(fill = "#4f455c"),
panel.grid = element_blank())
f <- fitted(h2.s1)
f %>%
data.frame() %>%
bind_cols(d2) %>%
ggplot(aes(x = PrevAn, y = Effort_Change_Ratio, ymin = Q2.5, ymax = Q97.5)) +
geom_vline(xintercept = knot_list, color = "white", alpha = 1/2) +
geom_hline(yintercept = fixef(h2.s1)[1, 1], color = "white", linetype = 2) +
geom_point(color = "#ffb7c5", alpha = 1/2) +
geom_ribbon(fill = "white", alpha = 2/3) +
labs(x = "Previous Answer",
y = "Effort Change Ratio") +
theme_bw() +
theme(panel.background = element_rect(fill = "#4f455c"),
panel.grid = element_blank())
f <- fitted(h2.s1)
f %>%
data.frame() %>%
bind_cols(d2) %>%
ggplot(aes(x = PrevAn, y = Effort_Change, ymin = Q2.5, ymax = Q97.5)) +
geom_vline(xintercept = knot_list, color = "white", alpha = 1/2) +
geom_hline(yintercept = fixef(h2.s1)[1, 1], color = "white", linetype = 2) +
geom_point(color = "#ffb7c5", alpha = 1/2) +
geom_ribbon(fill = "white", alpha = 2/3) +
labs(x = "Previous Answer",
y = "Effort Change Ratio") +
theme_bw() +
theme(panel.background = element_rect(fill = "#4f455c"),
panel.grid = element_blank())
f <- fitted(h2.s1)
f %>%
data.frame() %>%
bind_cols(d2) %>%
ggplot(aes(x = PrevAn, y = Effort_Change, ymin = Q2.5, ymax = Q97.5)) +
geom_vline(xintercept = knot_list, color = "white", alpha = 1/2) +
geom_hline(yintercept = fixef(h2.s1)[1, 1], color = "white", linetype = 2) +
geom_point(color = "#ffb7c5", alpha = 1/2) +
geom_ribbon(fill = "white", alpha = 2/3) +
labs(x = "Previous Answer",
y = "Effort Change") +
theme_bw() +
theme(panel.background = element_rect(fill = "#4f455c"),
panel.grid = element_blank())
plot(h2.s1)
pp_check(h2.s1, type = "dens_overlay")
pp_check(h2.s1, type = "error_scatter_avg")
h2.s1_R2
get_prior(data = d2,
family = gaussian,
Effort_Change ~ 1 + s(PrevAn))
h2.s2 <-
brm(data = d2,
family = gaussian,
Effort_Change ~ 1 + s(PrevAn, bs = "bs", k = 19),
iter = 4000,
warmup = 2000,
chains = 4,
cores = 4,
seed = 4,
control = list(adapt_delta = .99)
)
# Add criterions for later diagnostics
h2.s2 <- add_criterion(h2.s2, criterion = c("loo", "waic"))
# Calculate also variance explained (R^2)
h2.s2_R2 <- bayes_R2(h2.s2)
# Save both as objects
saveRDS(h2.s2, here("09_Analysis_Modeling", "models", "h2.s2.rds"))
saveRDS(h2.s2_R2, here("09_Analysis_Modeling", "models", "h2.s2_R2.rds"))
beep(5)
# Summary
summary(h2.s2)
plot(h2.s2)
plot(conditional_effects(h2.s2), points = TRUE)
pp_check(h2.s2, type = "dens_overlay")
pp_check(h2.s2, type = "error_scatter_avg")
h2.s2_R2
h2.s3 <-
brm(
data = filtered_data,
family = gaussian,
Effort_Change ~ 1 +
s(PrevAn_z, bs = "bs", k = 19) +  # Smooth for Previous Answer similarity
+ CommAtt + Modality + Big5 + Familiarity + Expressibility_z +  # Fixed effects
(1 | Participant) + (1 | Concept),  # Random effects
iter = 4000,
warmup = 2000,
chains = 4,
cores = 4,
seed = 4,
control = list(adapt_delta = .99)
)
# Add criterions for later diagnostics
h2.s3 <- add_criterion(h2.s3, criterion = c("loo", "waic"))
# Calculate also variance explained (R^2)
h2.s3_R2 <- bayes_R2(h2.s3)
# Save both as objects
saveRDS(h2.s3, here("09_Analysis_Modeling", "models", "h2.s3.rds"))
saveRDS(h2.s3_R2, here("09_Analysis_Modeling", "models", "h2.s3_R2.rds"))
beep(5)
# Summary
summary(h2.s3)
plot(h2.s3)
pp_check(h2.s3, type = "dens_overlay")
pp_check(h2.s3, type = "error_scatter_avg")
h2.s3_R2
model_list <- list(h2.m1, h2.s1, h2.s2, h2.s3)
# Extract R-hat values for each model
rhat_list <- lapply(model_list, function(model) {
rhat_values <- rhat(model)
data.frame(model = deparse(substitute(model)),
max_rhat = max(rhat_values),
min_rhat = min(rhat_values))
})
# Combine and inspect
do.call(rbind, rhat_list)
# Extract n_eff values for each model
neff_ratio_list <- lapply(model_list, function(model) {
neff_values <- neff_ratio(model)              # Here we calculate ratio (not the raw number of effective samples)
data.frame(model = deparse(substitute(model)),
min_neff = min(neff_values),
max_neff = max(neff_values),
mean_neff = mean(neff_values))
})
# Combine and inspect
do.call(rbind, neff_ratio_list)
effective_sample(h2.m1)
effective_sample(h2.s3)
l <- loo_compare(h2.m1, h2.s1, h2.s2, h2.s3, criterion = "loo")
print(l, simplify = F)
w <- loo_compare(h2.m1, h2.s1, h2.s2, h2.s3, criterion = "waic")
print(w, simplify = F)
# see Solomon Kurz
cbind(waic_diff = w[,1] * -2,
se = w[,2] * 2)
w[, 7:8] %>%
data.frame() %>%
rownames_to_column("model_name") %>%
mutate(model_name = fct_reorder(model_name, waic, .desc = T)) %>%
ggplot(aes(x = waic, y = model_name,
xmin = waic - se_waic,
xmax = waic + se_waic)) +
geom_pointrange(color = carto_pal(7, "BurgYl")[7],
fill = carto_pal(7, "BurgYl")[5], shape = 21) +
labs(title = "WAIC plot",
x = NULL, y = NULL) +
theme(axis.ticks.y = element_blank())
model_weights(h2.m1, h2.s1, h2.s2, h2.s3, weights = "waic") %>%
round(digits = 2)
# Print priors
prior_summary(h2.s3)
priors_h2s4 <- c(
set_prior("normal(0,0.50)", class = "b", coef = "sPrevAn_z_1"),
set_prior("normal(0,0.50)", class = "b", coef = "CommAtt2M1"),
set_prior("normal(0,0.25)", class = "b", coef = "Modality1"),
set_prior("normal(0,0.25)", class = "b", coef = "Modality2"),
set_prior("normal(0,0.25)", class = "b", coef = "Big5"),
set_prior("normal(0,0.25)", class = "b", coef = "Familiarity"),
set_prior("normal(0,0.25)", class = "b", coef = "Expressibility_z")
)
