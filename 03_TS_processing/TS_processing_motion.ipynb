{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8daa0249",
   "metadata": {},
   "source": [
    "# Processing III: motion tracking and balance\n",
    "\n",
    "In this notebook, we work further with motion tracking data extracted in XXX. Additionally, we process the balance board stream that we extracted in XX. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6780ef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\FLESH_ContinuousBodilyEffort\\01_TS_processing\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "\n",
    "curfolder = os.getcwd()\n",
    "print(curfolder)\n",
    "\n",
    "# files to work with\n",
    "MTfolder = 'C:\\\\Users\\\\kadava\\\\Documents\\\\Github\\\\FLESH_3Dtracking_new\\\\projectdata\\\\' ## FLAGGED CHANGE\n",
    "ACfolder = 'E:\\\\charade_experiment_WORKSPACE\\\\xdf_procedure\\\\data\\\\Data_processed\\\\Data_trials\\\\Audio_48\\\\' ## FLAGGED CHANGE\n",
    "BBfolder = 'E:\\\\charade_experiment_WORKSPACE\\\\xdf_procedure\\\\data\\\\Data_processed\\\\Data_trials\\\\'\n",
    "\n",
    "# folders to save the processed data\n",
    "MTfolder_processed = curfolder + '\\\\TS_motiontracking\\\\'\n",
    "ACfolder_processed = curfolder + '\\\\TS_acoustics\\\\'\n",
    "TSmerged = curfolder + '\\\\TS_merged\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267097d3",
   "metadata": {},
   "source": [
    "# Motion tracking \n",
    "\n",
    "FLAGGED. Note that y and z dimensions are swapped (such that z is vertical)\n",
    "\n",
    "In the previous notebook, we have ran pose estimation on the trial videos (OpenPose), and triangulated the coordinates to get 3D coordinates for each trial (pose2sim). Furthermore, we have performed inverse kinematics and dynamics to extract joint angles and moments.\n",
    "\n",
    "In this section, we will clean the data, and extract further information (such as speed, acceleration, etc.). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f4c24",
   "metadata": {},
   "source": [
    "## Motion tracking - kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90528ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "MTtotrack = glob.glob(MTfolder + '*/P*/*', recursive=True)\n",
    "\n",
    "# get rid of all the folders that are not the ones we want to track, like .sto files\n",
    "MTtotrack = [x for x in MTtotrack if 'sto' not in x]\n",
    "MTtotrack = [x for x in MTtotrack if 'txt' not in x]\n",
    "MTtotrack = [x for x in MTtotrack if 'xml' not in x]\n",
    "MTtotrack = [x for x in MTtotrack if 'opensim' not in x]\n",
    "MTtotrack = [x for x in MTtotrack if 'Results' not in x]\n",
    "MTtotrack = [x for x in MTtotrack if 'toml' not in x]\n",
    "\n",
    "print(MTtotrack)\n",
    "\n",
    "MTfiles_all = []\n",
    "\n",
    "for folder in MTtotrack:\n",
    "    print('working on:' + folder)\n",
    "    # last element is trialid\n",
    "    trialid = folder.split('\\\\')[-1]\n",
    "    \n",
    "    # get all csv files in the folder\n",
    "    csvfiles = glob.glob(folder + '\\\\**\\\\*.csv', recursive=True)\n",
    "    # keep only the ones that have butterworth in the name\n",
    "    csvfiles = [x for x in csvfiles if 'butterworth' in x]\n",
    "    butterfile = csvfiles[0]\n",
    "    # append to list with trialid\n",
    "    MTfiles_all.append([trialid, butterfile])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c805f92",
   "metadata": {},
   "source": [
    "The data can still be noisy, as the OpenPose in-built filter is not particularly strong. We don't want to smooth all the keypoints with the same strength, as some keypoints are more prone to noise than others. We can therefore use the function `check_smooth_strength` to check the effect of different smoothing strengths on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6314a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check different smoothing windows and orders\n",
    "def check_smooth_strength(df, keycols, windows, orders):\n",
    "\n",
    "    # prepare new df\n",
    "    df_smooth = pd.DataFrame()\n",
    "\n",
    "    for col in keycols:\n",
    "        for win in windows:\n",
    "            for ord in orders:\n",
    "                df_smooth[col + '_savgol' + str(win) + '_' + str(ord)] = scipy.signal.savgol_filter(df[col], win, ord)\n",
    "\n",
    "    # make R_Hand_x from df_sample a list\n",
    "    keycol_x = df[keycols[0]].tolist()\n",
    "    keycol_y = df[keycols[1]].tolist()\n",
    "    keycol_z = df[keycols[2]].tolist()\n",
    "\n",
    "    # load these values into df_smooth as a new column\n",
    "    df_smooth[keycols[0]] = keycol_x\n",
    "    df_smooth[keycols[1]] = keycol_y\n",
    "    df_smooth[keycols[2]] = keycol_z\n",
    "\n",
    "    # plot all dimensions in one plot\n",
    "    colstoplot = keycols\n",
    "\n",
    "    for col in colstoplot:\n",
    "        plt.plot(df_smooth[col], label=col, alpha=0.65)\n",
    "    plt.legend()\n",
    "    # make only timewindow 50 to 250\n",
    "    #plt.xlim(50, 222)\n",
    "    plt.show()\n",
    "\n",
    "### 15, 1 seems quite solid\n",
    "\n",
    "# but for lower body let's try 20,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a8078bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MTfiles_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mMTfiles_all\u001b[49m[\u001b[38;5;241m20\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      2\u001b[0m sample \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(MTfiles_all[\u001b[38;5;241m20\u001b[39m][\u001b[38;5;241m1\u001b[39m], sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m windows \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m70\u001b[39m,\u001b[38;5;241m100\u001b[39m] \u001b[38;5;66;03m# list possible window\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MTfiles_all' is not defined"
     ]
    }
   ],
   "source": [
    "print(MTfiles_all[20][1])\n",
    "sample = pd.read_csv(MTfiles_all[20][1], sep=',')\n",
    "\n",
    "windows = [50,70,100] # list possible window\n",
    "orders = [1,3] # list possible orders\n",
    "\n",
    "# col of interest\n",
    "samplecol = ['LKnee_x', 'LKnee_y', 'LKnee_z']\n",
    "\n",
    "check_smooth_strength(sample, samplecol, windows, orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7fbe3d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c38565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get euclidian sum of associated keypoints\n",
    "\n",
    "def aggregate_keypoints(df, measurement, finalcolname):\n",
    "\n",
    "    # group keypoints that belong together\n",
    "    lowerbodycols = ['RHip', 'LHip']\n",
    "    legcols = ['RKnee', 'RAnkle', 'LAnkle', 'LKnee', 'RHeel', 'LHeel']\n",
    "    headcols = ['Head', 'Neck', 'Nose']\n",
    "    armcols = ['RShoulder', 'RElbow', 'RWrist', 'LShoulder', 'LElbow', 'LWrist', 'RIndex', 'LIndex']\n",
    "\n",
    "    groups = [lowerbodycols, legcols, headcols, armcols]\n",
    "\n",
    "    # make subdf only with speed\n",
    "    subdf = df[[x for x in df.columns if measurement in x]]\n",
    "\n",
    "    # loop through each joint group\n",
    "    for group in groups:\n",
    "        # get cols\n",
    "        cols = [x for x in subdf.columns if any(y in x for y in group)]\n",
    "        subdf_temp = subdf[cols]\n",
    "\n",
    "        for index, row in subdf_temp.iterrows():\n",
    "            # get all values of that row\n",
    "            values = row.values\n",
    "            # calculate euclidian sum\n",
    "            euclidian_sum = np.sqrt(np.sum(np.square(values))) ## FLAGGED: possibly normalize\n",
    "            # get a name for new col\n",
    "            if group == lowerbodycols:\n",
    "                colname = 'lowerbody'\n",
    "            elif group == legcols:\n",
    "                colname = 'leg'\n",
    "            elif group == headcols:\n",
    "                colname = 'head'\n",
    "            elif group == armcols:\n",
    "                colname = 'arm'\n",
    "\n",
    "            df.loc[index, colname + finalcolname] = euclidian_sum\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# get kinematic derivatives\n",
    "def get_derivatives(df, sr, upperbodycols, lowerbodycols):\n",
    "\n",
    "    mtcols = df.columns\n",
    "\n",
    "    # prepare cols for speed\n",
    "    cols = [x.split('_')[0] for x in mtcols]\n",
    "    colsforspeed = list(set(cols))\n",
    "\n",
    "    # for each unique colname (cols), calculate speed \n",
    "    for col in colsforspeed:\n",
    "        # get x and y columns\n",
    "        x = df[col + '_x']\n",
    "        y = df[col + '_y']\n",
    "        z = df[col + '_z'] # note that y and z are flipped\n",
    "        # calculate speed\n",
    "        df[col + '_speed'] = np.insert(np.sqrt(np.diff(x)**2 + np.diff(y)**2 + np.diff(z)**2), 0, 0)\n",
    "        # multiply the values by sr, because now we have values in m/(s/sr)\n",
    "        df[col + '_speed'] = df[col + '_speed']*sr\n",
    "        \n",
    "        # smooth\n",
    "        if any(x in col for x in upperbodycols):\n",
    "            df[col + '_speed'] = scipy.signal.savgol_filter(df[col + '_speed'], 15, 1)\n",
    "        elif any(x in col for x in lowerbodycols):\n",
    "            df[col + '_speed'] = scipy.signal.savgol_filter(df[col + '_speed'], 20, 1)\n",
    "        else:\n",
    "            df[col + '_speed'] = scipy.signal.savgol_filter(df[col + '_speed'], 15, 1)\n",
    "\n",
    "        # if the col contains wrist, we will alco calculate the vertical velocity (z dimension)\n",
    "        if 'Wrist' in col:\n",
    "            # calculate speed\n",
    "            df[col + '_vert_vel'] = np.insert(np.diff(z), 0, 0)\n",
    "            # multiply the values by sr, because now we have values in m/(s/sr)\n",
    "            df[col + '_vert_vel'] = df[col + '_vert_vel']*sr\n",
    "            # smooth with savgol \n",
    "            df[col + '_vert_vel'] = scipy.signal.savgol_filter(df[col + '_vert_vel'], 15, 1)\n",
    "\n",
    "        # derive acceleration\t\n",
    "        df[col + '_acc'] = np.insert(np.diff(df[col + '_speed']), 0, 0)\n",
    "        # smooth\n",
    "        df[col + '_acc'] = scipy.signal.savgol_filter(df[col + '_acc'], 15, 1)\n",
    "\n",
    "        # derive jerk\n",
    "        df[col + '_jerk'] = np.insert(np.diff(df[col + '_acc']), 0, 0)\n",
    "        # smooth\n",
    "        df[col + '_jerk'] = scipy.signal.savgol_filter(df[col + '_jerk'], 15, 1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in MTtotrack:\n",
    "    print('working on:' + folder)\n",
    "    # last element is trialid\n",
    "    trialid = folder.split('\\\\')[-1]\n",
    "    \n",
    "    # get all csv files in the folder\n",
    "    csvfiles = glob.glob(folder + '/**/*.csv', recursive=True)\n",
    "    # keep only the ones that have butterworth in the name\n",
    "    csvfiles = [x for x in csvfiles if 'butterworth' in x]\n",
    "    butterfile = csvfiles[0]\n",
    "\n",
    "    # load it\n",
    "    mt = pd.read_csv(butterfile)\n",
    "\n",
    "    # the mt is missing 0 ms timepoint, so we need to create a row that copies the first row of mt and time = 0\n",
    "    padrow = mt.iloc[0].copy()\n",
    "    padrow['Time'] = 0\n",
    "\n",
    "    # concatenate it to the beginning of mt \n",
    "    mt = pd.concat([pd.DataFrame(padrow).T, mt], ignore_index=True)\n",
    "\n",
    "    # keep only cols of interest\n",
    "    colstokeep = [\"Time\", \"RHip\", \"RKnee\", \"RAnkle\", \"RHeel\", \"LHip\", \"LKnee\", \"LAnkle\", \"LHeel\", \"Neck\", \"Head\", \"Nose\", \"RShoulder\", \"RElbow\", \"RWrist\", \"RIndex\", \"LShoulder\", \"LElbow\", \"LWrist\",\n",
    "    \"LIndex\",\n",
    "]\n",
    "    mt = mt[[col for col in mt.columns if any(x in col for x in colstokeep)]]\n",
    "\n",
    "    # show columns\n",
    "    mtcols = mt.columns\n",
    "\n",
    "    # smooth all columns except time with savgol\n",
    "    colstosmooth = mtcols[:-1]\n",
    "\n",
    "    mt_smooth = pd.DataFrame()\n",
    "\n",
    "    # upper body cols\n",
    "    upperbodycols = ['Head', 'Neck', 'RShoulder', 'RElbow', 'RWrist', 'LShoulder', 'LElbow', 'LWrist', 'Nose', 'RIndex', 'LIndex']\n",
    "    # lower body cols\n",
    "    lowerbodycols = ['RHip', 'RKnee', 'RAnkle', 'RHeel' 'LHip', 'LKnee', 'LAnkle', 'LHeel']\n",
    "\n",
    "    for col in colstosmooth:\n",
    "        # if the col + x/y/z is in upperbodycols, smooth with 15,1\n",
    "        if any(x in col for x in upperbodycols):\n",
    "            mt_smooth[col] = scipy.signal.savgol_filter(mt[col], 15, 1)\n",
    "        # as the lowerbody keypoints are not moving that much, they are much more prone to noise (e.g., from the measurement error of OpenPose, therefore we will smooth them with a little higher window)\n",
    "        elif any(x in col for x in lowerbodycols):\n",
    "            mt_smooth[col] = scipy.signal.savgol_filter(mt[col], 20, 1)\n",
    "        else:\n",
    "            mt_smooth[col] = scipy.signal.savgol_filter(mt[col], 15, 1)\n",
    "\n",
    "        # and put them all to cms\n",
    "        mt_smooth[col] = mt_smooth[col]*100\n",
    "\n",
    "    # add back time column\n",
    "    mt_smooth['Time'] = mt['Time']\n",
    "\n",
    "    # get sampling rate\n",
    "    sr = 1/np.mean(np.diff(mt['Time']))\n",
    "\n",
    "    mt_smooth = get_derivatives(mt_smooth, sr, upperbodycols, lowerbodycols)\n",
    "    # prepare cols for speed\n",
    "    # cols = [x.split('_')[0] for x in mtcols]\n",
    "    # colsforspeed = list(set(cols))\n",
    "\n",
    "    # # for each unique colname (cols), calculate speed \n",
    "    # for col in colsforspeed:\n",
    "    #     # get x and y columns\n",
    "    #     x = mt_smooth[col + '_x']\n",
    "    #     y = mt_smooth[col + '_y']\n",
    "    #     z = mt_smooth[col + '_z'] # note that y and z are flipped\n",
    "    #     # calculate speed\n",
    "    #     mt_smooth[col + '_speed'] = np.insert(np.sqrt(np.diff(x)**2 + np.diff(y)**2 + np.diff(z)**2), 0, 0)\n",
    "    #     # multiply the values by sr, because now we have values in m/(s/sr)\n",
    "    #     mt_smooth[col + '_speed'] = mt_smooth[col + '_speed']*sr\n",
    "        \n",
    "    #     # smooth\n",
    "    #     if any(x in col for x in upperbodycols):\n",
    "    #         mt_smooth[col + '_speed'] = scipy.signal.savgol_filter(mt_smooth[col + '_speed'], 15, 1)\n",
    "    #     elif any(x in col for x in lowerbodycols):\n",
    "    #         mt_smooth[col + '_speed'] = scipy.signal.savgol_filter(mt_smooth[col + '_speed'], 20, 1)\n",
    "    #     else:\n",
    "    #         mt_smooth[col + '_speed'] = scipy.signal.savgol_filter(mt_smooth[col + '_speed'], 15, 1)\n",
    "\n",
    "    #     # if the col contains wrist, we will alco calculate the vertical velocity (z dimension)\n",
    "    #     if 'Wrist' in col:\n",
    "    #         # calculate speed\n",
    "    #         mt_smooth[col + '_vert_vel'] = np.insert(np.diff(z), 0, 0)\n",
    "    #         # multiply the values by sr, because now we have values in m/(s/sr)\n",
    "    #         mt_smooth[col + '_vert_vel'] = mt_smooth[col + '_vert_vel']*sr\n",
    "    #         # smooth with savgol \n",
    "    #         mt_smooth[col + '_vert_vel'] = scipy.signal.savgol_filter(mt_smooth[col + '_vert_vel'], 15, 1)\n",
    "\n",
    "    #     # derive acceleration\t\n",
    "    #     mt_smooth[col + '_acc'] = np.insert(np.diff(mt_smooth[col + '_speed']), 0, 0)\n",
    "    #     # smooth\n",
    "    #     mt_smooth[col + '_acc'] = scipy.signal.savgol_filter(mt_smooth[col + '_acc'], 15, 1)\n",
    "\n",
    "    #     # derive jerk\n",
    "    #     mt_smooth[col + '_jerk'] = np.insert(np.diff(mt_smooth[col + '_acc']), 0, 0)\n",
    "    #     # smooth\n",
    "    #     mt_smooth[col + '_jerk'] = scipy.signal.savgol_filter(mt_smooth[col + '_jerk'], 15, 1)\n",
    "\n",
    "    # getting aggreagated sums for groups of cols\n",
    "    mt_smooth = aggregate_keypoints(mt_smooth, 'speed', 'speedKin_sum')\n",
    "    mt_smooth = aggregate_keypoints(mt_smooth, 'acc', 'accKin_sum')\n",
    "    mt_smooth = aggregate_keypoints(mt_smooth, 'jerk', 'jerkKin_sum')\n",
    "\n",
    "    # lowerbodycols = ['RHip', 'LHip']\n",
    "    # legcols = ['RKnee', 'RAnkle', 'LAnkle', 'LKnee', 'RHeel', 'LHeel']\n",
    "    # headcols = ['Head', 'Neck', 'Nose']\n",
    "    # armcols = ['RShoulder', 'RElbow', 'RWrist', 'LShoulder', 'LElbow', 'LWrist', 'RIndex', 'LIndex']\n",
    "\n",
    "    # groups = [lowerbodycols, legcols, headcols, armcols]\n",
    "\n",
    "    # # make subdf only with speed\n",
    "    # subdf = mt_smooth[[x for x in mt_smooth.columns if 'speed' in x]]\n",
    "\n",
    "    # # loop through each joint group\n",
    "    # for group in groups:\n",
    "    #     # get cols\n",
    "    #     cols = [x for x in subdf.columns if any(y in x for y in group)]\n",
    "    #     subdf_temp = subdf[cols]\n",
    "\n",
    "    #     for index, row in subdf_temp.iterrows():\n",
    "    #         # get all values of that row\n",
    "    #         values = row.values\n",
    "    #         # calculate euclidian sum\n",
    "    #         euclidian_sum = np.sqrt(np.sum(np.square(values))) ## FLAGGED: possibly normalize\n",
    "    #         # get a name for new col\n",
    "    #         if group == lowerbodycols:\n",
    "    #             colname = 'lowerbody'\n",
    "    #         elif group == legcols:\n",
    "    #             colname = 'leg'\n",
    "    #         elif group == headcols:\n",
    "    #             colname = 'head'\n",
    "    #         elif group == armcols:\n",
    "    #             colname = 'arm'\n",
    "\n",
    "    #         mt_smooth.loc[index, colname + '_speedKin_sum'] = euclidian_sum\n",
    "\n",
    "    # # now for acc\n",
    "    # subdf = mt_smooth[[x for x in mt_smooth.columns if 'acc' in x]]\n",
    "\n",
    "    # # loop through each joint group\n",
    "    # for group in groups:\n",
    "\n",
    "    #     # get cols\n",
    "    #     cols = [x for x in subdf.columns if any(y in x for y in group)]\n",
    "\n",
    "    #     subdf_temp = subdf[cols]\n",
    "\n",
    "    #     for index, row in subdf_temp.iterrows():\n",
    "    #         # get all values of that row\n",
    "    #         values = row.values\n",
    "\n",
    "    #         # calculate euclidian sum\n",
    "    #         euclidian_sum = np.sqrt(np.sum(np.square(values))) ## FLAGGED: possibly normalize\n",
    "\n",
    "    #         # get a name for new col\n",
    "    #         if group == lowerbodycols:\n",
    "    #             colname = 'lowerbody'\n",
    "    #         elif group == legcols:\n",
    "    #             colname = 'leg'\n",
    "    #         elif group == headcols:\n",
    "    #             colname = 'head'\n",
    "    #         elif group == armcols:\n",
    "    #             colname = 'arm'\n",
    "\n",
    "\n",
    "    #         mt_smooth.loc[index, colname + '_accKin_sum'] = euclidian_sum\n",
    "\n",
    "    # # now for jerk\n",
    "    # subdf = mt_smooth[[x for x in mt_smooth.columns if 'jerk' in x]]\n",
    "\n",
    "    # # loop through each joint group\n",
    "    # for group in groups:\n",
    "\n",
    "    #     # get cols\n",
    "    #     cols = [x for x in subdf.columns if any(y in x for y in group)]\n",
    "\n",
    "    #     subdf_temp = subdf[cols]\n",
    "\n",
    "    #     for index, row in subdf_temp.iterrows():\n",
    "    #         # get all values of that row\n",
    "    #         values = row.values\n",
    "\n",
    "    #         # calculate euclidian sum\n",
    "    #         euclidian_sum = np.sqrt(np.sum(np.square(values))) ## FLAGGED: possibly normalize\n",
    "\n",
    "    #         # get a name for new col\n",
    "    #         if group == lowerbodycols:\n",
    "    #             colname = 'lowerbody'\n",
    "    #         elif group == legcols:\n",
    "    #             colname = 'leg'\n",
    "    #         elif group == headcols:\n",
    "    #             colname = 'head'\n",
    "    #         elif group == armcols:\n",
    "    #             colname = 'arm'\n",
    "\n",
    "\n",
    "    #         mt_smooth.loc[index, colname + '_jerkKin_sum'] = euclidian_sum\n",
    "\n",
    "    # add trialid\n",
    "    mt_smooth['TrialID'] = trialid\n",
    "    # convert time to ms\n",
    "    mt_smooth['Time'] = mt_smooth['Time']*1000\n",
    "    # write to csv\n",
    "    mt_smooth.to_csv(MTfolder_processed + '/mt_' + trialid + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d907a6df",
   "metadata": {},
   "source": [
    "Let's check one file to see how the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341c84fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one in to check\n",
    "\n",
    "MTfiles = glob.glob(MTfolder_processed + '/*.csv')\n",
    "print(MTfiles)\n",
    "\n",
    "sample = pd.read_csv(MTfiles[0])\n",
    "print(sample)\n",
    "\n",
    "# FLAGGED - plot here coordinates-speed-acc-jerk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc97ab2",
   "metadata": {},
   "source": [
    "## Motion tracking - inverse kinematics\n",
    "\n",
    "Using OpenSim, we have extracted joint angles in the previous notebook. Now again, we clean the data and extract further information before saving it into csv file per trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc88ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all mot files in the folder\n",
    "mot_files = glob.glob(MTfolder + '*/P*/*/*.mot', recursive=True)\n",
    "\n",
    "for mot in mot_files:\n",
    "    print('working on ' + mot)\n",
    "    # get trialid\n",
    "    trialid = mot.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "    # get rid of the first element before _\n",
    "    trialid = '_'.join(trialid.split('_')[1:])\n",
    "\n",
    "    # load it\n",
    "    mot_df = pd.read_csv(mot, sep='\\t', skiprows=10)\n",
    "    \n",
    "    # pad 0 ms row\n",
    "    padrow = mot_df.iloc[0].copy()\n",
    "    padrow['time'] = 0\n",
    "\n",
    "    # concatenate it to the beginning of mot_df\n",
    "    mot_df = pd.concat([pd.DataFrame(padrow).T, mot_df], ignore_index=True)\n",
    "    \n",
    "    # get the sr\n",
    "    sr = 1/np.mean(np.diff(mot_df['time']))\n",
    "\n",
    "    # smooth all columns except the firts time (time) and last (trialid)\n",
    "    colstosmooth = [x for x in mot_df.columns if 'time' not in x]\n",
    "\n",
    "    # smooth\n",
    "    for col in colstosmooth:\n",
    "        mot_df[col] = scipy.signal.savgol_filter(mot_df[col], 15, 3)\n",
    "        # convert to radians\n",
    "        mot_df[col] = np.deg2rad(mot_df[col])\n",
    "\n",
    "    # convert time to ms\n",
    "    mot_df['time'] = mot_df['time']*1000\n",
    "\n",
    "    # keep only columns you might use\n",
    "    keypoints = ['wrist', 'pro', 'elbow', 'arm', 'neck', 'ankle', 'knee', 'hip', 'pelvis']\n",
    "    coi = [x for x in mot_df.columns if any(y in x for y in keypoints) or 'time' in x or 'TrialID' in x]\n",
    "    mot_df2 = mot_df[coi]\n",
    "\n",
    "    # get derivatives\n",
    "    mot_df2 = get_derivatives(mot_df2, sr, [], [])\n",
    "    \n",
    "    # calculate angular speed\n",
    "    speedcols = [x for x in mot_df2.columns if 'time' not in x]\n",
    "    speedcols = [x for x in speedcols if 'TrialID' not in x]\n",
    "    print(speedcols)\n",
    "\n",
    "    for col in speedcols:\n",
    "        mot_df2[col + '_speed'] = np.insert(np.diff(mot_df2[col]), 0, 0)\n",
    "        mot_df2[col + '_speed'] = mot_df2[col + '_speed']*sr\n",
    "        mot_df2[col + '_speed'] = scipy.signal.savgol_filter(mot_df2[col + '_speed'], 15, 1)\n",
    "\n",
    "    # calculate angular acceleration\n",
    "    acccols = [x for x in mot_df2.columns if 'speed' in x]\n",
    "\n",
    "    for col in acccols:\n",
    "        # replace speed with ''\n",
    "        col_name = col.replace('_speed', '')\n",
    "        mot_df2[col_name + '_acc'] = np.insert(np.diff(mot_df2[col]), 0, 0)\n",
    "        mot_df2[col_name + '_acc'] = scipy.signal.savgol_filter(mot_df2[col_name + '_acc'], 15, 1)\n",
    "\n",
    "    # calculate jerk\n",
    "    jerkcols = [x for x in mot_df2.columns if 'acc' in x]\n",
    "\n",
    "    for col in jerkcols:\n",
    "        # replace acc with ''\n",
    "        col_name = col.replace('_acc', '')\n",
    "        mot_df2[col_name + '_jerk'] = np.insert(np.diff(mot_df2[col]), 0, 0)\n",
    "        mot_df2[col_name + '_jerk'] = scipy.signal.savgol_filter(mot_df2[col_name + '_jerk'], 15, 1)\n",
    "\n",
    "\n",
    "    # add time and trialid\n",
    "    mot_df2['time'] = mot_df['time']\n",
    "    mot_df2['TrialID'] = trialid\n",
    "\n",
    "    # let's get aggregated euclidian sum for each joint group\n",
    "    # upper body\n",
    "    pelviscols = ['pelvis']\n",
    "    spinecols = ['L5_S1', 'L4_L5', 'L3_L4', 'L2_L3', 'L1_L2', 'L1_T12']\n",
    "    lowerbodycols = ['pelvis', 'hip']\n",
    "    legcols = ['knee', 'ankle', 'subtalar']\n",
    "    headcols = ['neck']\n",
    "    armcols = ['arm', 'elbow', 'wrist', 'pro_sup']\n",
    "\n",
    "    groups = [lowerbodycols, legcols, headcols, armcols, pelviscols, spinecols]\n",
    "\n",
    "    # make subdf only with moments\n",
    "    subdf = mot_df2[[x for x in mot_df2.columns if 'speed' in x]]\n",
    "\n",
    "    # loop through each joint group\n",
    "    for group in groups:\n",
    "\n",
    "        # get cols\n",
    "        cols = [x for x in subdf.columns if any(y in x for y in group)]\n",
    "\n",
    "        subdf_temp = subdf[cols]\n",
    "\n",
    "        for index, row in subdf_temp.iterrows():\n",
    "            # get all values of that row\n",
    "            values = row.values\n",
    "\n",
    "            # calculate euclidian sum\n",
    "            euclidian_sum = np.sqrt(np.sum(np.square(values))) \n",
    "\n",
    "            # get a name for new col\n",
    "            if group == lowerbodycols:\n",
    "                colname = 'lowerbody'\n",
    "            elif group == legcols:\n",
    "                colname = 'leg'\n",
    "            elif group == headcols:\n",
    "                colname = 'head'\n",
    "            elif group == armcols:\n",
    "                colname = 'arm'\n",
    "            elif group == pelviscols:\n",
    "                colname = 'pelvis'\n",
    "            elif group == spinecols:\n",
    "                colname = 'spine'\n",
    "\n",
    "\n",
    "            mot_df2.loc[index, colname + '_angSpeed_sum'] = euclidian_sum\n",
    "\n",
    "    # and the same for acceleration\n",
    "    # make subdf only with acc\n",
    "    subdf = mot_df2[[x for x in mot_df2.columns if 'acc' in x]]\n",
    "\n",
    "    # loop through each joint group\n",
    "    for group in groups:\n",
    "\n",
    "        # get cols\n",
    "        cols = [x for x in subdf.columns if any(y in x for y in group)]\n",
    "\n",
    "        subdf_temp = subdf[cols]\n",
    "\n",
    "        for index, row in subdf_temp.iterrows():\n",
    "            # get all values of that row\n",
    "            values = row.values\n",
    "\n",
    "            # calculate euclidian sum\n",
    "            euclidian_sum = np.sqrt(np.sum(np.square(values))) ## FLAGGED: possibly normalize\n",
    "\n",
    "            # get a name for new col\n",
    "            if group == lowerbodycols:\n",
    "                colname = 'lowerbody'\n",
    "            elif group == legcols:\n",
    "                colname = 'leg'\n",
    "            elif group == headcols:\n",
    "                colname = 'head'\n",
    "            elif group == armcols:\n",
    "                colname = 'arm'\n",
    "            elif group == pelviscols:\n",
    "                colname = 'pelvis'\n",
    "            elif group == spinecols:\n",
    "                colname = 'spine'\n",
    "\n",
    "\n",
    "            mot_df2.loc[index, colname + '_angAcc_sum'] = euclidian_sum\n",
    "\n",
    "    # and the same for jerk\n",
    "    # make subdf only with jerk\n",
    "    subdf = mot_df2[[x for x in mot_df2.columns if 'jerk' in x]]\n",
    "\n",
    "    # loop through each joint group\n",
    "    for group in groups:\n",
    "\n",
    "        # get cols\n",
    "        cols = [x for x in subdf.columns if any(y in x for y in group)]\n",
    "\n",
    "        subdf_temp = subdf[cols]\n",
    "\n",
    "        for index, row in subdf_temp.iterrows():\n",
    "            # get all values of that row\n",
    "            values = row.values\n",
    "\n",
    "            # calculate euclidian sum\n",
    "            euclidian_sum = np.sqrt(np.sum(np.square(values))) ## FLAGGED: possibly normalize\n",
    "\n",
    "            # get a name for new col\n",
    "            if group == lowerbodycols:\n",
    "                colname = 'lowerbody'\n",
    "            elif group == legcols:\n",
    "                colname = 'leg'\n",
    "            elif group == headcols:\n",
    "                colname = 'head'\n",
    "            elif group == armcols:\n",
    "                colname = 'arm'\n",
    "            elif group == pelviscols:\n",
    "                colname = 'pelvis'\n",
    "            elif group == spinecols:\n",
    "                colname = 'spine'\n",
    "\n",
    "            mot_df2.loc[index, colname + '_angJerk_sum'] = euclidian_sum\n",
    "\n",
    "    # write to csv\n",
    "    mot_df2.to_csv(MTfolder_processed + '/ik_' + trialid + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf3145a",
   "metadata": {},
   "source": [
    "## Motion tracking - inverse dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e70531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in MTfolders, find all sto files\n",
    "sto_files = glob.glob(MTfolder + '*/P*/*/*.sto', recursive=True)\n",
    "sto_files = [x for x in sto_files if 'ID' in x]\n",
    "\n",
    "for sto in sto_files:\n",
    "    print('working on ' + sto)\n",
    "\n",
    "    # load it\n",
    "    id_df = pd.read_csv(sto, sep='\\t', skiprows=6)\n",
    "\n",
    "    # from the filename, get the trialid\n",
    "    trialid = sto.split('\\\\')[-1].split('.')[0]\n",
    "    trialid = '_'.join(trialid.split('_')[:-1])\n",
    "    trialid = '_'.join(trialid.split('_')[1:])\n",
    "\n",
    "    # pad 0 ms row\n",
    "    padrow = id_df.iloc[0].copy()\n",
    "    padrow['time'] = 0\n",
    "\n",
    "    # concatenate it to the beginning of id_df\n",
    "    id_df = pd.concat([pd.DataFrame(padrow).T, id_df], ignore_index=True)\n",
    "\n",
    "    # add trialid\n",
    "    id_df['TrialID'] = trialid\n",
    "\n",
    "    # smooth all columns except the firts time (time) and last (trialid)\n",
    "    colstosmooth = [x for x in id_df.columns if 'time' not in x]\n",
    "    colstosmooth = [x for x in colstosmooth if 'TrialID' not in x]\n",
    "\n",
    "    # smooth\n",
    "    for col in colstosmooth:\n",
    "        id_df[col] = scipy.signal.savgol_filter(id_df[col], 15, 3)\n",
    "    \n",
    "    # convert time to ms\n",
    "    id_df['time'] = id_df['time']*1000\n",
    "\n",
    "    # let's get aggregated euclidian sum for each joint group\n",
    "    # upper body\n",
    "    pelviscols = ['pelvis']\n",
    "    spinecols = ['L5_S1', 'L4_L5', 'L3_L4', 'L2_L3', 'L1_L2', 'L1_T12']\n",
    "    lowerbodycols = ['pelvis', 'hip']\n",
    "    legcols = ['knee', 'ankle', 'subtalar']\n",
    "    headcols = ['neck']\n",
    "    armcols = ['arm', 'elbow', 'wrist', 'pro_sup']\n",
    "\n",
    "    groups = [lowerbodycols, legcols, headcols, armcols, pelviscols, spinecols]\n",
    "\n",
    "    # make subdf only with moments\n",
    "    subdf = id_df[[x for x in id_df.columns if 'moment' in x]]\n",
    "\n",
    "    # loop through each joint group\n",
    "    for group in groups:\n",
    "\n",
    "        # get cols\n",
    "        cols = [x for x in subdf.columns if any(y in x for y in group)]\n",
    "\n",
    "        subdf_temp = subdf[cols]\n",
    "\n",
    "        for index, row in subdf_temp.iterrows():\n",
    "            # get all values of that row\n",
    "            values = row.values\n",
    "\n",
    "            # calculate euclidian sum\n",
    "            euclidian_sum = np.sqrt(np.sum(np.square(values))) \n",
    "\n",
    "            # get a name for new col\n",
    "            if group == lowerbodycols:\n",
    "                colname = 'lowerbody'\n",
    "            elif group == legcols:\n",
    "                colname = 'leg'\n",
    "            elif group == headcols:\n",
    "                colname = 'head'\n",
    "            elif group == armcols:\n",
    "                colname = 'arm'\n",
    "            elif group == pelviscols:\n",
    "                colname = 'pelvis'\n",
    "            elif group == spinecols:\n",
    "                colname = 'spine'\n",
    "\n",
    "            id_df.loc[index, colname + '_torque_sum'] = euclidian_sum\n",
    "\n",
    "    # for each torque_sum, we will also calculate the change in torque_sum\n",
    "    torquestodiff = [x for x in id_df.columns if 'torque_sum' in x]\n",
    "\n",
    "    for col in torquestodiff:\n",
    "        id_df[col + '_change'] = np.insert(np.diff(id_df[col]), 0, 0)\n",
    "        # absolutize\n",
    "        id_df[col + '_change'] = np.abs(id_df[col + '_change'])\n",
    "        # smooth\n",
    "        id_df[col + '_change'] = scipy.signal.savgol_filter(id_df[col + '_change'], 20, 4)\n",
    "    \n",
    "\n",
    "    # write to csv\n",
    "    id_df.to_csv(MTfolder_processed + '/id_' + trialid + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78117d84",
   "metadata": {},
   "source": [
    "### ID&MT check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550fe39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load in one id and mt file with the same trialid\n",
    "\n",
    "idfiles = glob.glob(MTfolder_processed + '/id*.csv')\n",
    "mtfiles = glob.glob(MTfolder_processed + '/mt*.csv')\n",
    "\n",
    "id = pd.read_csv(idfiles[0])\n",
    "mt = pd.read_csv(mtfiles[0])\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "ax[0].plot(mt['Time'], mt['LWrist_speed'], label='LWrist_speed')\n",
    "# add LElbow_speed\n",
    "ax[0].plot(mt['Time'], mt['LElbow_speed'], label='LElbow_speed')\n",
    "ax[0].set_title('LWrist_speed')\n",
    "ax[0].set_ylabel('speed (cm/s)')\n",
    "ax[0].set_xlabel('time (ms)')\n",
    "ax[0].legend()\n",
    "\n",
    "# elbow flexion\n",
    "ax[1].plot(id['time'], id['elbow_flex_r_moment'], label='elbow_flex_r_moment')\n",
    "ax[1].plot(id['time'], id['elbow_flex_l_moment'], label='elbow_flex_l_moment')\n",
    "ax[1].set_title('wrist_flex_l_moment')\n",
    "ax[1].set_ylabel('moment (Nm)')\n",
    "ax[1].set_xlabel('time (ms)')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1f7dd1",
   "metadata": {},
   "source": [
    "# Balance Board\n",
    "\n",
    "\n",
    "We do XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89dfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in BBfolder, find all files containing BalanceBoard\n",
    "\n",
    "BB_files = glob.glob(BBfolder + '*BalanceBoard*.csv', recursive=True)\n",
    "print(BB_files)\n",
    "\n",
    "for bb in BB_files:\n",
    "    print('working on ' + bb)\n",
    "    # get trialid\n",
    "    trialid = bb.split('\\\\')[-1].split('.')[0]\n",
    "    # get the first, second, fourth, nineth elements\n",
    "    trialid = '_'.join(trialid.split('_')[:2] + trialid.split('_')[3:4] + trialid.split('_')[8:9])\n",
    "\n",
    "    # because we are going to merge on bb, we will store also more information\n",
    "    fileinfo = bb.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "    # if second element is 1, we will store last three elements\n",
    "    if fileinfo.split('_')[1] == '1':\n",
    "        # if there is not 'corrected' in the name, we will store last three elements\n",
    "        if 'corrected' not in fileinfo:\n",
    "            info = '_'.join(fileinfo.split('_')[-3:])\n",
    "        else:\n",
    "            info = '_'.join(fileinfo.split('_')[-4:])\n",
    "    elif fileinfo.split('_')[1] == '2':\n",
    "        # otherwise we store last four elements (5 when corrected)\n",
    "        if 'corrected' not in fileinfo:\n",
    "            info = '_'.join(fileinfo.split('_')[-4:])\n",
    "        else:\n",
    "            info = '_'.join(fileinfo.split('_')[-5:])\n",
    "\n",
    "    # Load the balanceboard data\n",
    "    df_bb = pd.read_csv(bb)\n",
    "\n",
    "    # Rename columns\n",
    "    df_bb.columns = ['time_s', 'left_back', 'right_forward', 'right_back', 'left_forward']\n",
    "\n",
    "    # Calculate sampling rate\n",
    "    bbsamp = 1 / np.mean(np.diff(df_bb['time_s'] - min(df_bb['time_s'])))\n",
    "\n",
    "    # Apply Savitzky-Golay filter to smooth the data\n",
    "    for col in df_bb.columns[1:]:\n",
    "        df_bb[col] = scipy.signal.savgol_filter(df_bb[col], 51, 5)\n",
    "\n",
    "    # Calculate COPX and COPY\n",
    "    COPX = (df_bb['right_forward'] + df_bb['right_back']) - (df_bb['left_forward'] + df_bb['left_back'])\n",
    "    COPY = (df_bb['right_forward'] + df_bb['left_forward']) - (df_bb['left_back'] + df_bb['right_back'])\n",
    "\n",
    "    # Calculate COPXc and COPYc\n",
    "    df_bb['COPXc'] = scipy.signal.savgol_filter(np.insert(np.diff(COPX), 0, 0), 51, 5)\n",
    "    df_bb['COPYc'] = scipy.signal.savgol_filter(np.insert(np.diff(COPY), 0, 0), 51, 5)\n",
    "\n",
    "    # Calculate COPc\n",
    "    df_bb['COPc'] = np.sqrt(df_bb['COPXc']**2 + df_bb['COPYc']**2)\n",
    "\n",
    "    # restart the time so that starts from 0\n",
    "    df_bb['time_s'] = df_bb['time_s'] - min(df_bb['time_s'])\n",
    "    # convert to ms\n",
    "    df_bb['time_s'] = df_bb['time_s']*1000\n",
    "\n",
    "    # rename time_s to time\n",
    "    df_bb.rename(columns={'time_s': 'time'}, inplace=True)\n",
    "\n",
    "    # Add trialid\n",
    "    df_bb['TrialID'] = trialid\n",
    "    # Add info\n",
    "    df_bb['FileInfo'] = info\n",
    "\n",
    "    # Write as csv to MTfolder_processed\n",
    "    df_bb.to_csv(MTfolder_processed + '/bb_' + trialid + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dde499",
   "metadata": {},
   "source": [
    "## Plot to check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ee37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bbfiles = glob.glob(MTfolder_processed + '/bb*.csv')\n",
    "\n",
    "samplebb = pd.read_csv(bbfiles[20])\n",
    "\n",
    "# plot COPc the sample\n",
    "plt.plot(samplebb['time'], samplebb['COPc'])\n",
    "plt.xlim(1000,2000)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EffortProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
