{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Processing III: motion tracking and balance'\n",
        "---"
      ],
      "id": "ed3c3ba8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the previous notebook, we have ran pose estimation on the trial videos (OpenPose), and triangulated the coordinates to get 3D coordinates for each trial (pose2sim). Furthermore, we have performed inverse kinematics and dynamics to extract joint angles and moments.\n",
        "\n",
        "In this script, we will clean the data, and extract further information (such as speed, acceleration, etc.). \n"
      ],
      "id": "413ed168"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: Code to load packages and prepare the environment\n",
        "\n",
        "\n",
        "# packages\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "\n",
        "\n",
        "curfolder = os.getcwd()\n",
        "print(curfolder)\n",
        "\n",
        "# files to work with\n",
        "MTfolder = 'C:\\\\Users\\\\kadava\\\\Documents\\\\Github\\\\FLESH_3Dtracking_new\\\\projectdata\\\\' ## FLAGGED CHANGE\n",
        "BBfolder = curfolder + '\\\\..\\\\01_XDF_processing\\\\data\\\\Data_processed\\\\Data_trials\\\\'\n",
        "\n",
        "# folders to save the processed data\n",
        "MTfolder_processed = curfolder + '\\\\TS_motiontracking\\\\'"
      ],
      "id": "5b577280",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Motion tracking - kinematics\n"
      ],
      "id": "3fe67557"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: Code to prepare files to process\n",
        "\n",
        "MTtotrack = glob.glob(MTfolder + '*/P*/*', recursive=True)\n",
        "\n",
        "# get rid of all the folders that are not the ones we want to track, like .sto files\n",
        "MTtotrack = [x for x in MTtotrack if 'sto' not in x]\n",
        "MTtotrack = [x for x in MTtotrack if 'txt' not in x]\n",
        "MTtotrack = [x for x in MTtotrack if 'xml' not in x]\n",
        "MTtotrack = [x for x in MTtotrack if 'opensim' not in x]\n",
        "MTtotrack = [x for x in MTtotrack if 'Results' not in x]\n",
        "MTtotrack = [x for x in MTtotrack if 'toml' not in x]\n",
        "\n",
        "print(MTtotrack)\n",
        "\n",
        "MTfiles_all = []\n",
        "\n",
        "for folder in MTtotrack:\n",
        "    print('working on:' + folder)\n",
        "    # last element is trialid\n",
        "    trialid = folder.split('\\\\')[-1]\n",
        "    \n",
        "    # get all csv files in the folder\n",
        "    csvfiles = glob.glob(folder + '\\\\**\\\\*.csv', recursive=True)\n",
        "    # keep only the ones that have butterworth in the name\n",
        "    csvfiles = [x for x in csvfiles if 'butterworth' in x]\n",
        "    butterfile = csvfiles[0]\n",
        "    # append to list with trialid\n",
        "    MTfiles_all.append([trialid, butterfile])"
      ],
      "id": "4c853311",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data can still be noisy, as the OpenPose in-built filter is not particularly strong. We don't want to smooth all the keypoints with the same strength, as some keypoints are more prone to noise than others. We can therefore use the function `check_smooth_strength` to check the effect of different smoothing strengths on the data. \n"
      ],
      "id": "ead05a7c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: Code with function to check smoothing strength\n",
        "\n",
        "# function to check different smoothing windows and orders\n",
        "def check_smooth_strength(df, keycols, windows, orders, keytoplot):\n",
        "\n",
        "    # prepare new df\n",
        "    df_smooth = pd.DataFrame()\n",
        "\n",
        "    for col in keycols:\n",
        "        for win in windows:\n",
        "            for ord in orders:\n",
        "                df_smooth[col + '_savgol' + str(win) + '_' + str(ord)] = scipy.signal.savgol_filter(df[col], win, ord)\n",
        "\n",
        "    # make R_Hand_x from df_sample a list\n",
        "    keycol_x = df[keycols[0]].tolist()\n",
        "    keycol_y = df[keycols[1]].tolist()\n",
        "    keycol_z = df[keycols[2]].tolist()\n",
        "\n",
        "    # load these values into df_smooth as a new column\n",
        "    df_smooth[keycols[0]] = keycol_x\n",
        "    df_smooth[keycols[1]] = keycol_y\n",
        "    df_smooth[keycols[2]] = keycol_z\n",
        "\n",
        "    # plot keytoplot in all strngths\n",
        "    colstoplot = [x for x in df_smooth.columns if keytoplot in x]\n",
        "    plt.figure()\n",
        "    for col in colstoplot:\n",
        "        plt.plot(df_smooth[col], label=col)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "id": "e5e990b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: Code to plot\n",
        "\n",
        "print(MTfiles_all[20][1])\n",
        "sample = pd.read_csv(MTfiles_all[20][1], sep=',')\n",
        "\n",
        "windows = [50,70,100] # list possible window\n",
        "orders = [1,3] # list possible orders\n",
        "\n",
        "# col of interest\n",
        "samplecol = ['LKnee_x', 'LKnee_y', 'LKnee_z']\n",
        "\n",
        "check_smooth_strength(sample, samplecol, windows, orders, 'LKnee_y')"
      ],
      "id": "e1e2bb9a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We used OpenPose (XX) for pose estimation, and pose2sim (XX) for triangulation.\n",
        "\n",
        "Here we clean the data, and smooth coordinates and derivatives with a Savitzky-Golay filter. We vary the strength (i.e., window and order) according to which keypoint we are smoothing (e.g., lower versus upper body)\n",
        "\n",
        "To get aggregated kinematic measures for each body group (i.e., head, upperbody, arms, lowerbody), we compute euclidian sum on each derivative belonging to the group.\n"
      ],
      "id": "5b793516"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: Code with functions for processing kinematic data\n",
        "\n",
        "# function to get euclidian sum of associated keypoints\n",
        "\n",
        "def aggregate_keypoints(df, measurement, finalcolname, use):\n",
        "\n",
        "    if use == 'kinematics':\n",
        "        # group keypoints that belong together\n",
        "        lowerbodycols = ['RHip', 'LHip']\n",
        "        legcols = ['RKnee', 'RAnkle', 'LAnkle', 'LKnee', 'RHeel', 'LHeel']\n",
        "        headcols = ['Head', 'Neck', 'Nose']\n",
        "        armcols = ['RShoulder', 'RElbow', 'RWrist', 'LShoulder', 'LElbow', 'LWrist', 'RIndex', 'LIndex']\n",
        "\n",
        "        groups = [lowerbodycols, legcols, headcols, armcols]\n",
        "\n",
        "    elif use == 'angles':\n",
        "        pelviscols = ['pelvis']\n",
        "        spinecols = ['L5_S1', 'L4_L5', 'L3_L4', 'L2_L3', 'L1_L2', 'L1_T12']\n",
        "        lowerbodycols = ['pelvis', 'hip']\n",
        "        legcols = ['knee', 'ankle', 'subtalar']\n",
        "        headcols = ['neck']\n",
        "        armcols = ['arm', 'elbow', 'wrist', 'pro_sup']\n",
        "\n",
        "        groups = [lowerbodycols, legcols, headcols, armcols, pelviscols, spinecols]\n",
        "\n",
        "    # make subdf only with speed\n",
        "    subdf = df[[x for x in df.columns if measurement in x]]\n",
        "\n",
        "    # loop through each joint group\n",
        "    for group in groups:\n",
        "        # get cols\n",
        "        cols = [x for x in subdf.columns if any(y in x for y in group)]\n",
        "        subdf_temp = subdf[cols]\n",
        "\n",
        "        for index, row in subdf_temp.iterrows():\n",
        "            # get all values of that row\n",
        "            values = row.values\n",
        "            # calculate euclidian sum\n",
        "            euclidian_sum = np.sqrt(np.sum(np.square(values))) ## FLAGGED: possibly normalize\n",
        "            # get a name for new col\n",
        "            if group == lowerbodycols:\n",
        "                colname = 'lowerbody'\n",
        "            elif group == legcols:\n",
        "                colname = 'leg'\n",
        "            elif group == headcols:\n",
        "                colname = 'head'\n",
        "            elif group == armcols:\n",
        "                colname = 'arm'\n",
        "            elif group == pelviscols:\n",
        "                colname = 'pelvis'\n",
        "            elif group == spinecols:\n",
        "                colname = 'spine'\n",
        "                \n",
        "\n",
        "            df.loc[index, colname + finalcolname] = euclidian_sum\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# get kinematic derivatives\n",
        "def get_derivatives(df, sr, upperbodycols, lowerbodycols, use):\n",
        "\n",
        "    mtcols = df.columns\n",
        "    if use == 'kinematics':\n",
        "        # get rid of cols that are not x, y or z\n",
        "        mtcols = [x for x in mtcols if '_x' in x or '_y' in x or '_z' in x]\n",
        "    \n",
        "\n",
        "        # prepare cols for speed\n",
        "        cols = [x.split('_')[0] for x in mtcols]\n",
        "        colsforspeed = list(set(cols))\n",
        "\n",
        "        # for each unique colname (cols), calculate speed \n",
        "        for col in colsforspeed:\n",
        "            # get x and y columns\n",
        "            x = df[col + '_x']\n",
        "            y = df[col + '_y']\n",
        "            z = df[col + '_z'] # note that y and z are flipped\n",
        "            # calculate speed\n",
        "            speed = np.insert(np.sqrt(np.diff(x)**2 + np.diff(y)**2 + np.diff(z)**2),0,0)\n",
        "            # multiply the values by sr, because now we have values in m/(s/sr)\n",
        "            speed = speed*sr\n",
        "\n",
        "            # smooth\n",
        "            if any(x in col for x in upperbodycols):\n",
        "                speed = scipy.signal.savgol_filter(speed, 15, 1)\n",
        "            elif any(x in col for x in lowerbodycols):\n",
        "                speed = scipy.signal.savgol_filter(speed, 20, 1)\n",
        "            else:\n",
        "                speed = scipy.signal.savgol_filter(speed, 15, 1)\n",
        "\n",
        "            # if the col contains wrist, we will alco calculate the vertical velocity (z dimension)\n",
        "            if 'Wrist' in col:\n",
        "                verticvel = np.insert(np.diff(z), 0, 0)\n",
        "                verticvel = verticvel*sr\n",
        "                verticvel = scipy.signal.savgol_filter(verticvel, 15, 1)\n",
        "\n",
        "            # derive acceleration\t\n",
        "            acceleration = np.insert(np.diff(speed), 0, 0)\n",
        "            acceleration = scipy.signal.savgol_filter(acceleration, 15, 1)\n",
        "\n",
        "            # derive jerk\n",
        "            jerk = np.insert(np.diff(acceleration), 0, 0)\n",
        "            jerk = scipy.signal.savgol_filter(jerk, 15, 1)\n",
        "\n",
        "            # new_data\n",
        "            new_data = pd.DataFrame({col + '_speed': speed, col + '_acc': acceleration, col + '_jerk': jerk})\n",
        "            df = pd.concat([df, new_data], axis=1)\n",
        "\n",
        "    elif use == 'angles':\n",
        "        # get rid of cols that are not angles (so skip time)\n",
        "        mtcols = mtcols[1:]\n",
        "\n",
        "        # derive speed\n",
        "        for col in mtcols:\n",
        "            speed = np.insert(np.diff(df[col]), 0, 0)\n",
        "            speed = speed*sr\n",
        "            speed = scipy.signal.savgol_filter(speed, 15, 1)\n",
        "\n",
        "            # derive acceleration\n",
        "            acceleration = np.insert(np.diff(speed), 0, 0)\n",
        "            acceleration = scipy.signal.savgol_filter(acceleration, 15, 1)\n",
        "            \n",
        "            # derive jerk\n",
        "            jerk = np.insert(np.diff(acceleration), 0, 0)\n",
        "            jerk = scipy.signal.savgol_filter(jerk, 15, 1)\n",
        "\n",
        "            # new_data\n",
        "            new_data = pd.DataFrame({col + '_speed': speed, col + '_acc': acceleration, col + '_jerk': jerk})\n",
        "            df = pd.concat([df, new_data], axis=1)\n",
        "\n",
        "    return df"
      ],
      "id": "058d4b5c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: false\n",
        "#| code-summary: Code to process kinematics\n",
        "\n",
        "# upper body cols\n",
        "upperbodycols = ['Head', 'Neck', 'RShoulder', 'RElbow', 'RWrist', 'LShoulder', 'LElbow', 'LWrist', 'Nose', 'RIndex', 'LIndex']\n",
        "# lower body cols\n",
        "lowerbodycols = ['RHip', 'RKnee', 'RAnkle', 'RHeel' 'LHip', 'LKnee', 'LAnkle', 'LHeel']\n",
        "\n",
        "for folder in MTtotrack:\n",
        "    print('working on:' + folder)\n",
        "    # last element is trialid\n",
        "    trialid = folder.split('\\\\')[-1]\n",
        "    \n",
        "    # get all csv files in the folder\n",
        "    csvfiles = glob.glob(folder + '/**/*.csv', recursive=True)\n",
        "    # keep only the ones that have butterworth in the name\n",
        "    csvfiles = [x for x in csvfiles if 'butterworth' in x]\n",
        "    butterfile = csvfiles[0]\n",
        "\n",
        "    # load it\n",
        "    mt = pd.read_csv(butterfile)\n",
        "\n",
        "    # the mt is missing 0 ms timepoint, so we need to create a row that copies the first row of mt and time = 0\n",
        "    padrow = mt.iloc[0].copy()\n",
        "    padrow['Time'] = 0\n",
        "\n",
        "    # concatenate it to the beginning of mt \n",
        "    mt = pd.concat([pd.DataFrame(padrow).T, mt], ignore_index=True)\n",
        "\n",
        "    # keep only cols of interest\n",
        "    colstokeep = [\"Time\", \"RHip\", \"RKnee\", \"RAnkle\", \"RHeel\", \"LHip\", \"LKnee\", \"LAnkle\", \"LHeel\", \"Neck\", \"Head\", \"Nose\", \"RShoulder\", \"RElbow\", \"RWrist\", \"RIndex\", \"LShoulder\", \"LElbow\", \"LWrist\",\n",
        "    \"LIndex\",\n",
        "]\n",
        "    mt = mt[[col for col in mt.columns if any(x in col for x in colstokeep)]]\n",
        "\n",
        "        # if col has _y in it, replace it by _temp\n",
        "    mt.columns = [x.replace('_y', '_temp') for x in mt.columns]\n",
        "    # replace _z by _y\n",
        "    mt.columns = [x.replace('_z', '_y') for x in mt.columns]\n",
        "    # replace _temp by _z\n",
        "    mt.columns = [x.replace('_temp', '_z') for x in mt.columns]\n",
        "\n",
        "    # smooth all columns except time with savgol\n",
        "    mtcols = mt.columns\n",
        "    colstosmooth = mtcols[:-1]\n",
        "\n",
        "    mt_smooth = pd.DataFrame()\n",
        "\n",
        "    for col in colstosmooth:\n",
        "        # if the col + x/y/z is in upperbodycols, smooth with 15,1\n",
        "        if any(x in col for x in upperbodycols):\n",
        "            mt_smooth[col] = scipy.signal.savgol_filter(mt[col], 15, 1)\n",
        "        # as the lowerbody keypoints are not moving that much, they are much more prone to noise (e.g., from the measurement error of OpenPose, therefore we will smooth them with a little higher window)\n",
        "        elif any(x in col for x in lowerbodycols):\n",
        "            mt_smooth[col] = scipy.signal.savgol_filter(mt[col], 20, 1)\n",
        "        else:\n",
        "            mt_smooth[col] = scipy.signal.savgol_filter(mt[col], 15, 1)\n",
        "\n",
        "        # and put them all to cms\n",
        "        mt_smooth[col] = mt_smooth[col]*100\n",
        "\n",
        "    # add back time column\n",
        "    mt_smooth['Time'] = mt['Time']\n",
        "\n",
        "    # get sampling rate\n",
        "    sr = 1/np.mean(np.diff(mt['Time']))\n",
        "\n",
        "    # get kinematic derivatives\n",
        "    mt_smooth = get_derivatives(mt_smooth, sr, upperbodycols, lowerbodycols, 'kinematics')\n",
        "\n",
        "    # getting aggreagated sums for groups of cols\n",
        "    mt_smooth = aggregate_keypoints(mt_smooth, 'speed', '_speedKin_sum', 'kinematics')\n",
        "    mt_smooth = aggregate_keypoints(mt_smooth, 'acc', '_accKin_sum', 'kinematics')\n",
        "    mt_smooth = aggregate_keypoints(mt_smooth, 'jerk', '_jerkKin_sum', 'kinematics')\n",
        "\n",
        "    # add trialid\n",
        "    mt_smooth['TrialID'] = trialid\n",
        "    # convert time to ms\n",
        "    mt_smooth['Time'] = mt_smooth['Time']*1000\n",
        "    # write to csv\n",
        "    mt_smooth.to_csv(MTfolder_processed + '/mt_' + trialid + '.csv', index=False)"
      ],
      "id": "62d1e028",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check one file to see how the data looks like by plotting RWrist and its kinematics, and also the euclidian sum for the whole arm along with it\n"
      ],
      "id": "6b7710ef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: Show code for this plot\n",
        "\n",
        "# Load one file to check\n",
        "MTfiles = glob.glob(MTfolder_processed + '/*.csv')\n",
        "print(MTfiles)\n",
        "sample = pd.read_csv(MTfiles[4])\n",
        "\n",
        "# Define colors and styles\n",
        "colors = ['blue', 'orange', 'green', 'red']\n",
        "titles = ['RWrist_y', 'RWrist_speed', 'RWrist_acc', 'RWrist_jerk']\n",
        "\n",
        "# Create a 2x2 grid of plots\n",
        "fig, axs = plt.subplots(2, 2, figsize=(20, 12), constrained_layout=True)\n",
        "fig.suptitle('Kinematics of RWrist', fontsize=20, fontweight='bold', color='darkblue')\n",
        "\n",
        "# Plot RWrist_y\n",
        "axs[0, 0].plot(sample['RWrist_y'], color=colors[0], linewidth=2)\n",
        "axs[0, 0].set_title('RWrist Position (y)', fontsize=14)\n",
        "axs[0, 0].set_xlabel('Frame')\n",
        "axs[0, 0].set_ylabel('Position')\n",
        "axs[0, 0].grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "# Plot RWrist_speed\n",
        "axs[0, 1].plot(sample['RWrist_speed'], color=colors[1], linewidth=2)\n",
        "# add arm sum\n",
        "axs[0, 1].plot(sample['arm_speedKin_sum'], color='black', linewidth=2, linestyle='--')\n",
        "axs[0, 1].set_title('RWrist Speed', fontsize=14)\n",
        "axs[0, 1].set_xlabel('Frame')\n",
        "axs[0, 1].set_ylabel('Speed')\n",
        "axs[0, 1].grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "# Plot RWrist_acc\n",
        "axs[1, 0].plot(sample['RWrist_acc'], color=colors[2], linewidth=2)\n",
        "# add arm sum\n",
        "axs[1, 0].plot(sample['arm_accKin_sum'], color='black', linewidth=2, linestyle='--')\n",
        "axs[1, 0].set_title('RWrist Acceleration', fontsize=14)\n",
        "axs[1, 0].set_xlabel('Frame')\n",
        "axs[1, 0].set_ylabel('Acceleration')\n",
        "axs[1, 0].grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "# Plot RWrist_jerk\n",
        "axs[1, 1].plot(sample['RWrist_jerk'], color=colors[3], linewidth=2)\n",
        "# add arm sum\n",
        "axs[1, 1].plot(sample['arm_jerkKin_sum'], color='black', linewidth=2, linestyle='--')\n",
        "axs[1, 1].set_title('RWrist Jerk', fontsize=14)\n",
        "axs[1, 1].set_xlabel('Frame')\n",
        "axs[1, 1].set_ylabel('Jerk')\n",
        "axs[1, 1].grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "# Adjust spacing\n",
        "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "id": "b0809c81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Motion tracking - inverse kinematics\n",
        "\n",
        "Using OpenSim (XX), we have extracted joint angles in the previous notebook. Now again, we clean the data and extract further information before saving it into csv file per trial\n"
      ],
      "id": "68c46c68"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: Code to process joint angles\n",
        "\n",
        "# get all mot files in the folder\n",
        "mot_files = glob.glob(MTfolder + '*/P*/*/*.mot', recursive=True)\n",
        "keypoints = ['wrist', 'pro_sup', 'elbow', 'arm', 'neck', 'subtalar', 'ankle', 'knee', 'hip', 'pelvis', 'L5_S1', 'L4_L5', 'L3_L4', 'L2_L3', 'L1_L2', 'L1_T12']\n",
        "\n",
        "for mot in mot_files:\n",
        "    print('working on ' + mot)\n",
        "    # get trialid\n",
        "    trialid = mot.split('\\\\')[-1].split('.')[0]\n",
        "\n",
        "    # get rid of the first element before _\n",
        "    trialid = '_'.join(trialid.split('_')[1:])\n",
        "\n",
        "    # load it\n",
        "    mot_df = pd.read_csv(mot, sep='\\t', skiprows=10)\n",
        "    \n",
        "    # pad 0 ms row\n",
        "    padrow = mot_df.iloc[0].copy()\n",
        "    padrow['time'] = 0\n",
        "\n",
        "    # concatenate it to the beginning of mot_df\n",
        "    mot_df = pd.concat([pd.DataFrame(padrow).T, mot_df], ignore_index=True)\n",
        "    \n",
        "    # get the sr\n",
        "    sr = 1/np.mean(np.diff(mot_df['time']))\n",
        "\n",
        "    # smooth all columns except the firts time (time) and last (trialid)\n",
        "    colstosmooth = [x for x in mot_df.columns if 'time' not in x]\n",
        "\n",
        "    # smooth\n",
        "    for col in colstosmooth:\n",
        "        mot_df[col] = scipy.signal.savgol_filter(mot_df[col], 15, 3)\n",
        "        # convert to radians\n",
        "        mot_df[col] = np.deg2rad(mot_df[col])\n",
        "\n",
        "    # keep only columns you might use\n",
        "    coi = [x for x in mot_df.columns if any(y in x for y in keypoints) or 'time' in x or 'TrialID' in x]\n",
        "    mot_df2 = mot_df[coi]\n",
        "\n",
        "    # get derivatives\n",
        "    mot_df2 = get_derivatives(mot_df2, sr, [], [], 'angles')\n",
        "\n",
        "    # aggregate data\n",
        "    mot_df2 = aggregate_keypoints(mot_df2, 'speed', '_angSpeed_sum', 'angles')\n",
        "    mot_df2 = aggregate_keypoints(mot_df2, 'acc', '_angAcc_sum', 'angles')\n",
        "    mot_df2 = aggregate_keypoints(mot_df2, 'jerk', '_angJerk_sum', 'angles')\n",
        "\n",
        "    # add time and trialid\n",
        "    mot_df2['time'] = mot_df['time']\n",
        "    # convert time to ms\n",
        "    mot_df2['time'] = mot_df2['time']*1000\n",
        "    mot_df2['TrialID'] = trialid\n",
        "\n",
        "    # write to csv\n",
        "    mot_df2.to_csv(MTfolder_processed + '/ik_' + trialid + '.csv', index=False)\n",
        "    \n",
        "    \n",
        "mot_df2.head(15)"
      ],
      "id": "6d669aec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Motion tracking - inverse dynamics\n"
      ],
      "id": "60cb6f6b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: Code to process joint moments\n",
        "\n",
        "# in MTfolders, find all sto files\n",
        "sto_files = glob.glob(MTfolder + '*/P*/*/*.sto', recursive=True)\n",
        "sto_files = [x for x in sto_files if 'ID' in x]\n",
        "\n",
        "for sto in sto_files:\n",
        "    print('working on ' + sto)\n",
        "\n",
        "    # load it\n",
        "    id_df = pd.read_csv(sto, sep='\\t', skiprows=6)\n",
        "\n",
        "    # from the filename, get the trialid\n",
        "    trialid = sto.split('\\\\')[-1].split('.')[0]\n",
        "    trialid = '_'.join(trialid.split('_')[:-1])\n",
        "    trialid = '_'.join(trialid.split('_')[1:])\n",
        "\n",
        "    # pad 0 ms row\n",
        "    padrow = id_df.iloc[0].copy()\n",
        "    padrow['time'] = 0\n",
        "\n",
        "    # concatenate it to the beginning of id_df\n",
        "    id_df = pd.concat([pd.DataFrame(padrow).T, id_df], ignore_index=True)\n",
        "\n",
        "    # smooth all columns except the firts time (time) and last (trialid)\n",
        "    colstosmooth = [x for x in id_df.columns if 'time' not in x]\n",
        "    colstosmooth = [x for x in colstosmooth if 'TrialID' not in x]\n",
        "\n",
        "    # smooth\n",
        "    for col in colstosmooth:\n",
        "        id_df[col] = scipy.signal.savgol_filter(id_df[col], 15, 3)\n",
        "\n",
        "    # make subdf only with moments\n",
        "    subdf = id_df[[x for x in id_df.columns if 'moment' in x]]\n",
        "\n",
        "    # get aggregated euclidian sum for each joint group\n",
        "    id_df = aggregate_keypoints(id_df, 'moment', '_moment_sum', 'angles')\n",
        "\n",
        "    # for each moment col, we will also calculate the change \n",
        "    torquestodiff = [x for x in id_df.columns if 'moment' in x]\n",
        "\n",
        "    for col in torquestodiff:\n",
        "        torquechange = np.insert(np.diff(id_df[col]), 0, 0)\n",
        "        id_df[col + '_change'] = np.abs(torquechange)\n",
        "        id_df[col + '_change'] = scipy.signal.savgol_filter(id_df[col + '_change'], 20, 4)\n",
        "        # new data\n",
        "        new_data = pd.DataFrame({col + '_change': torquechange})\n",
        "        id_df = pd.concat([id_df, new_data], axis=1)\n",
        "    \n",
        "    # convert time to ms\n",
        "    id_df['time'] = id_df['time']*1000\n",
        "        # add trialid\n",
        "    id_df['TrialID'] = trialid\n",
        "\n",
        "    # write to csv\n",
        "    id_df.to_csv(MTfolder_processed + '/id_' + trialid + '.csv', index=False)\n",
        "\n",
        "\n",
        "id_df.head(15)"
      ],
      "id": "0e79718e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can check by ploting the joint moments along the kinematic data\n"
      ],
      "id": "cfcfadf0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: Show code for the plot\n",
        "\n",
        "# load in one id and mt file with the same trialid\n",
        "idfiles = glob.glob(MTfolder_processed + '/id*.csv')\n",
        "mtfiles = glob.glob(MTfolder_processed + '/mt*.csv')\n",
        "\n",
        "id = pd.read_csv(idfiles[0])\n",
        "print(idfiles[0])\n",
        "mt = pd.read_csv(mtfiles[0])\n",
        "print(mtfiles[0])\n",
        "\n",
        "# plot\n",
        "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "ax[0].plot(mt['Time'], mt['LWrist_speed'], label='LWrist_speed')\n",
        "# add LElbow_speed\n",
        "ax[0].plot(mt['Time'], mt['LElbow_speed'], label='LElbow_speed')\n",
        "ax[0].set_title('LWrist_speed')\n",
        "ax[0].set_ylabel('speed (cm/s)')\n",
        "ax[0].set_xlabel('time (ms)')\n",
        "ax[0].legend()\n",
        "\n",
        "# elbow flexion\n",
        "ax[1].plot(id['time'], id['elbow_flex_r_moment'], label='elbow_flex_r_moment')\n",
        "ax[1].plot(id['time'], id['elbow_flex_l_moment'], label='elbow_flex_l_moment')\n",
        "ax[1].set_title('wrist_flex_l_moment')\n",
        "ax[1].set_ylabel('moment (Nm)')\n",
        "ax[1].set_xlabel('time (ms)')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.show()"
      ],
      "id": "eafa2947",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Balance Board\n",
        "\n",
        "\n",
        "We do XXX\n"
      ],
      "id": "2c12d724"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: Code to process balance board data\n",
        "\n",
        "BB_files = glob.glob(BBfolder + '*BalanceBoard*.csv', recursive=True)\n",
        "\n",
        "for bb in BB_files:\n",
        "    print('working on ' + bb)\n",
        "    # get trialid\n",
        "    trialid = bb.split('\\\\')[-1].split('.')[0]\n",
        "    # get the first, second, fourth, nineth elements\n",
        "    trialid = '_'.join(trialid.split('_')[:2] + trialid.split('_')[3:4] + trialid.split('_')[8:9])\n",
        "\n",
        "    # because we are going to merge on bb, we will store also more information\n",
        "    fileinfo = bb.split('\\\\')[-1].split('.')[0]\n",
        "\n",
        "    # if second element is 1, we will store last three elements\n",
        "    if fileinfo.split('_')[1] == '1':\n",
        "        # if there is not 'corrected' in the name, we will store last three elements\n",
        "        if 'corrected' not in fileinfo:\n",
        "            info = '_'.join(fileinfo.split('_')[-3:])\n",
        "        else:\n",
        "            info = '_'.join(fileinfo.split('_')[-4:])\n",
        "    elif fileinfo.split('_')[1] == '2':\n",
        "        # otherwise we store last four elements (5 when corrected)\n",
        "        if 'corrected' not in fileinfo:\n",
        "            info = '_'.join(fileinfo.split('_')[-4:])\n",
        "        else:\n",
        "            info = '_'.join(fileinfo.split('_')[-5:])\n",
        "\n",
        "    # Load the balanceboard data\n",
        "    df_bb = pd.read_csv(bb)\n",
        "\n",
        "    # Rename columns\n",
        "    df_bb.columns = ['time_s', 'left_back', 'right_forward', 'right_back', 'left_forward']\n",
        "\n",
        "    # Calculate sampling rate\n",
        "    bbsamp = 1 / np.mean(np.diff(df_bb['time_s'] - min(df_bb['time_s'])))\n",
        "\n",
        "    # Apply Savitzky-Golay filter to smooth the data\n",
        "    for col in df_bb.columns[1:]:\n",
        "        df_bb[col] = scipy.signal.savgol_filter(df_bb[col], 51, 5)\n",
        "\n",
        "    # Calculate COPX and COPY\n",
        "    COPX = (df_bb['right_forward'] + df_bb['right_back']) - (df_bb['left_forward'] + df_bb['left_back'])\n",
        "    COPY = (df_bb['right_forward'] + df_bb['left_forward']) - (df_bb['left_back'] + df_bb['right_back'])\n",
        "\n",
        "    # Calculate COPXc and COPYc\n",
        "    df_bb['COPXc'] = scipy.signal.savgol_filter(np.insert(np.diff(COPX), 0, 0), 51, 5)\n",
        "    df_bb['COPYc'] = scipy.signal.savgol_filter(np.insert(np.diff(COPY), 0, 0), 51, 5)\n",
        "\n",
        "    # Calculate COPc\n",
        "    df_bb['COPc'] = np.sqrt(df_bb['COPXc']**2 + df_bb['COPYc']**2)\n",
        "\n",
        "    # restart the time so that starts from 0\n",
        "    df_bb['time_s'] = df_bb['time_s'] - min(df_bb['time_s'])\n",
        "    # convert to ms\n",
        "    df_bb['time_s'] = df_bb['time_s']*1000\n",
        "\n",
        "    # rename time_s to time\n",
        "    df_bb.rename(columns={'time_s': 'time'}, inplace=True)\n",
        "\n",
        "    # Add trialid\n",
        "    df_bb['TrialID'] = trialid\n",
        "    # Add info\n",
        "    df_bb['FileInfo'] = info\n",
        "\n",
        "    # Write as csv to MTfolder_processed\n",
        "    df_bb.to_csv(MTfolder_processed + '/bb_' + trialid + '.csv', index=False)\n",
        "\n",
        "df_bb.head(15)"
      ],
      "id": "3064166f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: Show code for the plot\n",
        "\n",
        "bbfiles = glob.glob(MTfolder_processed + '/bb*.csv')\n",
        "samplebb = pd.read_csv(bbfiles[20])\n",
        "\n",
        "# plot COPc the sample\n",
        "plt.plot(samplebb['time'], samplebb['COPc'])\n",
        "#plt.xlim(1000,2000)\n",
        "plt.show()"
      ],
      "id": "6cf7a364",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "tsprocess",
      "language": "python",
      "display_name": "TSprocess"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}