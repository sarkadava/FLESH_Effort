)
saveRDS(vocModel1, file = paste0(models, "vocModel1.rds"), compress = TRUE)
vocModel2 <- caret::train(
correction_info ~ .,
data = vocData1235,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(vocModel2, file = paste0(models, "vocModel2.rds"), compress = TRUE)
vocModel3 <- caret::train(
correction_info ~ .,
data = vocData1245,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(vocModel3, file = paste0(models, "vocModel3.rds"), compress = TRUE)
vocModel4 <- caret::train(
correction_info ~ .,
data = vocData1345,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(vocModel4, file = paste0(models, "vocModel4.rds"), compress = TRUE)
vocModel5 <- caret::train(
correction_info ~ .,
data = vocData2345,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(vocModel5, file = paste0(models, "vocModel5.rds"), compress = TRUE)
vocModel1 <- readRDS(paste0(models, "vocModel1.rds"))
vocModel2 <- readRDS(paste0(models, "vocModel2.rds"))
vocModel3 <- readRDS(paste0(models, "vocModel3.rds"))
vocModel4 <- readRDS(paste0(models, "vocModel4.rds"))
vocModel5 <- readRDS(paste0(models, "vocModel5.rds"))
# Generate predictions
vocPredictions1 <- predict(vocModel1, newdata = vocData5)
vocPredictions2 <- predict(vocModel2, newdata = vocData4)
vocPredictions3 <- predict(vocModel3, newdata = vocData3)
vocPredictions4 <- predict(vocModel4, newdata = vocData2)
vocPredictions5 <- predict(vocModel5, newdata = vocData1)
# Compute confusion matrices
vocCm1 <- confusionMatrix(vocPredictions1, vocData5$correction_info)
vocCm2 <- confusionMatrix(vocPredictions2, vocData4$correction_info)
vocCm3 <- confusionMatrix(vocPredictions3, vocData3$correction_info)
vocCm4 <- confusionMatrix(vocPredictions4, vocData2$correction_info)
vocCm5 <- confusionMatrix(vocPredictions5, vocData1$correction_info)
# Extract p-values (you need to define how to extract these based on your metric, here assumed to be some metric from confusion matrix)
vocPValues <- c(vocCm1$overall['AccuracyPValue'],
vocCm2$overall['AccuracyPValue'],
vocCm3$overall['AccuracyPValue'],
vocCm4$overall['AccuracyPValue'],
vocCm5$overall['AccuracyPValue'])
# Fisher's method
vocFisher_combined <- -2 * sum(log(vocPValues))
df <- 2 * length(vocPValues)
vocPCcombined_fisher <- 1 - pchisq(vocFisher_combined, df)
print(vocPCcombined_fisher)
# Stouffer's method
vocZ_scores <- qnorm(1 - vocPValues/2)
vocCombined_z <- sum(vocZ_scores) / sqrt(length(vocPValues))
vocP_combined_stouffer <- 2 * (1 - pnorm(abs(vocCombined_z)))
print(vocP_combined_stouffer)
XGBvocModel1 <- vocModel1$finalModel
importanceXGBvocModel1 <- xgb.importance(model = XGBvocModel1)
print(importanceXGBvocModel1)
xgb.plot.importance(importanceXGBvocModel1)
XGBvocModel2 <- vocModel2$finalModel
importanceXGBvocModel2 <- xgb.importance(model = XGBvocModel2)
print(importanceXGBvocModel2)
xgb.plot.importance(importanceXGBvocModel2)
XGBvocModel3 <- vocModel3$finalModel
importanceXGBvocModel3 <- xgb.importance(model = XGBvocModel3)
print(importanceXGBvocModel3)
xgb.plot.importance(importanceXGBvocModel3)
XGBvocModel4 <- vocModel4$finalModel
importanceXGBvocModel4 <- xgb.importance(model = XGBvocModel4)
print(importanceXGBvocModel4)
xgb.plot.importance(importanceXGBvocModel4)
XGBvocModel5 <- vocModel5$finalModel
importanceXGBvocModel5 <- xgb.importance(model = XGBvocModel5)
print(importanceXGBvocModel5)
xgb.plot.importance(importanceXGBvocModel5)
# Function to extract and normalize importance
get_normalized_importance <- function(model) {
importance <- xgb.importance(model = model)
importance$Gain <- importance$Gain / sum(importance$Gain)
return(importance)
}
# Extract normalized importance for each model
vocImportance1 <- get_normalized_importance(vocModel1$finalModel)
vocImportance2 <- get_normalized_importance(vocModel2$finalModel)
vocImportance3 <- get_normalized_importance(vocModel3$finalModel)
vocImportance4 <- get_normalized_importance(vocModel4$finalModel)
vocImportance5 <- get_normalized_importance(vocModel5$finalModel)
# Combine importances
vocAllImportances <- list(vocImportance1, vocImportance2, vocImportance3, vocImportance4, vocImportance5)
# Function to merge importances
merge_importances <- function(importances) {
for (i in 2:length(importances)) {
names(importances[[i]])[2:4] <- paste0(names(importances[[i]])[2:4], "_", i)
}
merged <- Reduce(function(x, y) merge(x, y, by = "Feature", all = TRUE), importances)
merged[is.na(merged)] <- 0  # Replace NAs with 0
gain_cols <- grep("Gain", colnames(merged), value = TRUE)
merged$Cumulative <- rowSums(merged[, ..gain_cols])
return(merged[, .(Feature, Cumulative)])
}
# Merge and sort importances
vocCumulativeImportance <- merge_importances(vocAllImportances)
vocCumulativeImportance <- vocCumulativeImportance[order(-vocCumulativeImportance$Cumulative), ]
# Print cumulative feature importance
print(vocCumulativeImportance)
voc_pca <- read_csv(paste0(datasets, "PCA_top_contributors_voc.csv"))
# Combined function to extract top n features, rank by importance, and save as CSV
extract_and_save_top_features <- function(df_pca, CumulativeImportance, n = 3, file_name = "top_features_per_pc.csv") {
# Initialize an empty list to store the results
top_features_per_pc <- list()
# Loop through each row in ges_pca (corresponding to each principal component)
for (pc_index in 1:nrow(df_pca)) {
# Get the feature list for the current principal component (the row)
pc_features_str <- df_pca[pc_index, ]
# Remove the square brackets, single quotes, and extra spaces
pc_features <- gsub("\\[|\\]", "", pc_features_str)  # Remove square brackets
pc_features <- gsub("'", "", pc_features)           # Remove single quotes
pc_features <- gsub("\\s+", " ", pc_features)       # Replace multiple spaces with a single space
# Split the string by commas to get individual feature names
pc_features <- unlist(strsplit(pc_features, ","))
# Clean up any leading/trailing spaces from each feature name
pc_features <- trimws(pc_features)
# Filter XGBoost importance data for features present in the current PC
important_features <- CumulativeImportance[CumulativeImportance$Feature %in% pc_features, ]
# Sort features by importance in descending order
important_features <- important_features[order(-important_features$Cumulative), ]
# Get the top n features for the current PC
top_features <- head(important_features, n)
# Add a column for the PC number
top_features$PC <- paste("PC", pc_index)
# Store the sorted features in the results list
top_features_per_pc[[paste("PC", pc_index)]] <- top_features
}
# Combine all results into a single dataframe
result_df <- do.call(rbind, top_features_per_pc)
# Save the dataframe to a CSV file
write.csv(result_df, file_name, row.names = FALSE)
# Return the dataframe
return(result_df)
}
# Call the function to extract top features, rank by importance, and save as CSV
top_features_voc <- extract_and_save_top_features(voc_pca, vocCumulativeImportance, n = 3, file_name = "top_features_voc_final.csv")
# Print the resulting dataframe
print(top_features_voc)
data_mult <- read_csv(paste0(datasets, "multi_clean_df.csv"))
# Make predictor a factor variable
data_mult$correction_info <- as.factor(data_mult$correction_info)
# prepare predictors
predictors <- setdiff(names(data_mult), "correction_info")
formula_str <- paste("correction_info ~", paste(predictors, collapse = " + "))
# Convert the formula string to a formula object
multTree_formula <- as.formula(formula_str)
# Now use the formula in rpart
multTree <- rpart(formula = multTree_formula, data = data_mult,
method='class', # Specify that it's a classification tree
control = rpart.control(maxdepth = 5)  # Control parameters for the 'rpart' function
)
prp(
multTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
set.seed(989) # Set a seed for reproducibility
# # Split the data into training and testing subsets
# sample_indices <- sample(1:nrow(data_voc), 0.8*nrow(data_voc)) # 80% training, 20% testing
# train_data <- data_voc[sample_indices, ]
# test_data <- data_voc[-sample_indices, ]
# This method should ensure that all levels of our dependent variable are present in both sets
# Ensure each level is present in both sets
train_data <- data_mult %>%
group_by(correction_info) %>%
sample_frac(0.8, replace = FALSE) %>%
ungroup()
# Assign the remaining samples to the test set
test_data <- anti_join(data_mult, train_data)
# Untuned Model with importance (permutation) option set
multUntuned <- ranger(
y = train_data$correction_info,
x = train_data[,0:510], # FLAGGED: adapt
num.trees = 500,
importance = "permutation"
)
predictions <- predict(multUntuned, data = test_data)$predictions
# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$correction_info)
# Print the confusion matrix
print(confusion_matrix)
# Calculate feature importance
feature_importance <- importance(multUntuned, num.threads = 1, type = 1)
# Convert to data frame
feature_importance <- as.data.frame(feature_importance, stringsAsFactors = FALSE)
feature_importance$Feature <- rownames(feature_importance)
colnames(feature_importance) <- c("Importance", "Feature")
# Sort by importance
sorted_feature_importance <- feature_importance[order(-feature_importance$Importance), ]
# Print sorted feature importance
print(sorted_feature_importance)
# Define the number of CPU cores to use
num_cores <- detectCores()
# Create a cluster with specified number of cores
cl <- makeCluster(num_cores)
tuneMult <- makeClassifTask(data = data_mult[,0:511], # FLAGGED: adapt
target = "correction_info")
tuneMult <- tuneRanger(tuneMult,
measure = list(multiclass.brier),
num.trees = 500)
tuneMult
multTuned <- ranger(
y = train_data$correction_info,
x = train_data[,0:510],  # FLAGGED: adapt
num.trees = 5000,
mtry = 142, # Set the recommended mtry value (number of features).
min.node.size = 3, # Set the recommended min.node.size value (number of samples before a node terminates).
sample.fraction = 0.3627617, # Set the recommended sample fraction value.(% of data for bagging).
importance = "permutation" # Permutation is a computationally intensive test.
)
predictions <- predict(multTuned, data = test_data)$predictions
# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$correction_info)
# Print the confusion matrix
print(confusion_matrix)
# Calculate feature importance
feature_importance <- importance(multTuned, num.threads = 1, type = 1)
# Convert to data frame
feature_importance <- as.data.frame(feature_importance, stringsAsFactors = FALSE)
feature_importance$Feature <- rownames(feature_importance)
colnames(feature_importance) <- c("Importance", "Feature")
# Sort by importance
sorted_feature_importance <- feature_importance[order(-feature_importance$Importance), ]
# Print sorted feature importance
print(sorted_feature_importance)
# Create a classification task for tuning
tuneMult <- makeClassifTask(data = train_data[, 0:511], target = "correction_info") # FLAGGED: adapt
# Tune the model
tuneMult <- tuneRanger(tuneMult, measure = list(multiclass.brier), num.trees = 500)
tuneMult
# Fit the tuned model on the training data
multTuned <- ranger(
y = train_data$correction_info,
x = train_data[, 0:511],  # FLAGGED: adapt
num.trees = 5000,
mtry = 32,
min.node.size = 2,
sample.fraction = 0.2087997,
importance = "permutation"
)
# Predict on the test data
predictions <- predict(multTuned, data = test_data)$predictions
# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$correction_info)
# Print the confusion matrix
print(confusion_matrix)
# Calculate feature importance
feature_importance <- importance(multTuned, num.threads = 1, type = 1)
# Convert to data frame
feature_importance_df <- as.data.frame(feature_importance, stringsAsFactors = FALSE)
feature_importance_df$Feature <- rownames(feature_importance_df)
colnames(feature_importance_df) <- c("Importance", "Feature")
# Sort by importance
sorted_feature_importance <- feature_importance_df[order(-feature_importance_df$Importance), ]
# Print sorted feature importance
print(sorted_feature_importance)
write.csv(data_mult, file = paste0(datasets, "multDataXGB.csv"), row.names = FALSE)
# Detect the number of available cores
cores <- detectCores() #- 1  # Leave one core free
# Create a cluster with the detected number of cores
cl <- makeCluster(cores)
# Register the parallel backend
registerDoParallel(cl)
grid_tune <- expand.grid(
nrounds = c(5000, 10000),
max_depth = c(3, 6),
eta = c(0.05, 0.1),
gamma = c(0.1),
colsample_bytree = c(0.6, 0.8),
min_child_weight = c(1),
subsample = c(0.75, 1.0)
)
# Calculate total combinations
total_combinations <- nrow(grid_tune)
# Estimate single model run time (assume 1 minute per run)
single_model_time <- 10 # minute
# Total runs for cross-validation
folds <- 5
total_runs <- total_combinations * folds
# Total time estimation without parallel processing
total_time <- total_runs * single_model_time # in minutes
# Convert to hours
total_time_hours <- total_time / 60
# Output estimated time without parallel processing
print(paste("Estimated time for grid search without parallel processing:", total_time_hours, "hours"))
# Parallel processing with 4 cores
cores <- 24
total_time_parallel <- total_time / cores # in minutes
# Convert to hours
total_time_parallel_hours <- total_time_parallel / 60
# Output estimated time with parallel processing
print(paste("Estimated time for grid search with", cores, "cores:", total_time_parallel_hours, "hours"))
rm(total_combinations,single_model_time,folds,total_runs,total_time,total_time_hours,total_time_parallel,total_time_parallel_hours,cores)
# Set seed for reproducibility
set.seed(998)
# Set up train control
train_control <- trainControl(
method = "cv",        # Cross-validation
number = 5,           # 5-fold cross-validation
allowParallel = TRUE  # Enable parallel processing
)
# Define the number of subsets
numSubsets <- 5
# Load MICE-imputed data (using placeholder 'data_ges' as the input dataset)
multDataXGB <- data_mult
# Ensure 'correction_info' is a factor
multDataXGB$correction_info <- as.factor(multDataXGB$correction_info)
# Remove rows with only NA values
multDataXGB <- multDataXGB[rowSums(is.na(multDataXGB)) < ncol(multDataXGB), ]
# Split data by levels of 'correction_info'
correction_levels <- levels(multDataXGB$correction_info)
split_data <- split(multDataXGB, multDataXGB$correction_info)
# Initialize a list to store subsets
multSubsets <- vector("list", length = numSubsets)
# Distribute rows for each level equally across subsets
for (level in correction_levels) {
level_data <- split_data[[level]]
subset_sizes <- rep(floor(nrow(level_data) / numSubsets), numSubsets)
remainder <- nrow(level_data) %% numSubsets
# Distribute remainder rows randomly
if (remainder > 0) {
subset_sizes[seq_len(remainder)] <- subset_sizes[seq_len(remainder)] + 1
}
# Shuffle rows of the level and assign to subsets
shuffled_data <- level_data[sample(nrow(level_data)), ]
indices <- cumsum(c(0, subset_sizes))
for (i in 1:numSubsets) {
if (is.null(gesSubsets[[i]])) {
multSubsets[[i]] <- shuffled_data[(indices[i] + 1):indices[i + 1], ]
} else {
multSubsets[[i]] <- rbind(multSubsets[[i]], shuffled_data[(indices[i] + 1):indices[i + 1], ])
}
}
}
# Naming the subsets
names(multSubsets) <- paste0("multData", 1:numSubsets)
# Verify balance in subsets
for (i in 1:numSubsets) {
cat("Subset", i, "contains rows:", nrow(multSubsets[[i]]), "and levels:\n")
print(table(multSubsets[[i]]$correction_info))
}
# Remove any rows with only NAs from subsets just to ensure cleanliness
multSubsets <- lapply(multSubsets, function(subset) {
subset[rowSums(is.na(subset)) < ncol(subset), ]
})
# Access the subsets
multData1 <- multSubsets$multData1
multData2 <- multSubsets$multData2
multData3 <- multSubsets$multData3
multData4 <- multSubsets$multData4
multData5 <- multSubsets$multData5
# Combine subsets into 80% groups
multData1234 <- rbind(multData1, multData2, multData3, multData4)
multData1235 <- rbind(multData1, multData2, multData3, multData5)
multData1245 <- rbind(multData1, multData2, multData4, multData5)
multData1345 <- rbind(multData1, multData3, multData4, multData5)
multData2345 <- rbind(multData2, multData3, multData4, multData5)
# Final verification of all levels in the combined datasets
combined_sets <- list(multData1234, multData1235, multData1245, multData1345, multData2345)
names(combined_sets) <- c("multData1234", "multData1235", "multData1245", "multData1345", "multData2345")
for (set_name in names(combined_sets)) {
cat("Dataset", set_name, "contains rows:", nrow(combined_sets[[set_name]]), "and levels:\n")
print(table(combined_sets[[set_name]]$correction_info))
}
multModel1 <- caret::train(
correction_info ~ .,
data = multData1234,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(multModel1, file = paste0(models, "multModel1.rds"), compress = TRUE)
multModel2 <- caret::train(
correction_info ~ .,
data = multData1235,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(multModel2, file = paste0(models, "multModel2.rds"), compress = TRUE)
multModel3 <- caret::train(
correction_info ~ .,
data = multData1245,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(multModel3, file = paste0(models, "multModel3.rds"), compress = TRUE)
multModel4 <- caret::train(
correction_info ~ .,
data = multData1345,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(multModel4, file = paste0(models, "multModel4.rds"), compress = TRUE)
multModel5 <- caret::train(
correction_info ~ .,
data = multData2345,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(multModel5, file = paste0(models, "multModel5.rds"), compress = TRUE)
multModel1 <- readRDS(paste0(models, "multModel1.rds"))
multModel2 <- readRDS(paste0(models, "multModel2.rds"))
multModel3 <- readRDS(paste0(models, "multModel3.rds"))
multModel4 <- readRDS(paste0(models, "multModel4.rds"))
multModel5 <- readRDS(paste0(models, "multModel5.rds"))
# Generate predictions
multPredictions1 <- predict(multModel1, newdata = multData5)
multPredictions2 <- predict(multModel2, newdata = multData4)
multPredictions3 <- predict(multModel3, newdata = multData3)
multPredictions4 <- predict(multModel4, newdata = multData2)
multPredictions5 <- predict(multModel5, newdata = multData1)
# Compute confusion matrices
multCm1 <- confusionMatrix(multPredictions1, multData5$correction_info)
multCm2 <- confusionMatrix(multPredictions2, multData4$correction_info)
multCm3 <- confusionMatrix(multPredictions3, multData3$correction_info)
multCm4 <- confusionMatrix(multPredictions4, multData2$correction_info)
multCm5 <- confusionMatrix(multPredictions5, multData1$correction_info)
# Extract p-values (you need to define how to extract these based on your metric, here assumed to be some metric from confusion matrix)
multPValues <- c(multCm1$overall['AccuracyPValue'],
multCm2$overall['AccuracyPValue'],
multCm3$overall['AccuracyPValue'],
multCm4$overall['AccuracyPValue'],
multCm5$overall['AccuracyPValue'])
# Fisher's method
multFisher_combined <- -2 * sum(log(multPValues))
df <- 2 * length(multPValues)
multPCcombined_fisher <- 1 - pchisq(multFisher_combined, df)
print(multPCcombined_fisher)
# Stouffer's method
multZ_scores <- qnorm(1 - multPValues/2)
multCombined_z <- sum(multZ_scores) / sqrt(length(multPValues))
multP_combined_stouffer <- 2 * (1 - pnorm(abs(multCombined_z)))
print(multP_combined_stouffer)
XGBmultModel1 <- multModel1$finalModel
importanceXGBmultModel1 <- xgb.importance(model = XGBmultModel1)
print(importanceXGBmultModel1)
xgb.plot.importance(importanceXGBmultModel1)
XGBmultModel2 <- multModel2$finalModel
importanceXGBmultModel2 <- xgb.importance(model = XGBmultModel2)
print(importanceXGBmultModel2)
xgb.plot.importance(importanceXGBmultModel2)
XGBmultModel3 <- multModel3$finalModel
importanceXGBmultModel3 <- xgb.importance(model = XGBmultModel3)
print(importanceXGBmultModel3)
xgb.plot.importance(importanceXGBmultModel3)
XGBmultModel4 <- multModel4$finalModel
importanceXGBmultModel4 <- xgb.importance(model = XGBmultModel4)
print(importanceXGBmultModel4)
xgb.plot.importance(importanceXGBmultModel4)
XGBmultModel5 <- multModel5$finalModel
importanceXGBmultModel5 <- xgb.importance(model = XGBmultModel5)
print(importanceXGBmultModel5)
xgb.plot.importance(importanceXGBmultModel5)
# Function to extract and normalize importance
get_normalized_importance <- function(model) {
importance <- xgb.importance(model = model)
importance$Gain <- importance$Gain / sum(importance$Gain)
return(importance)
}
# Extract normalized importance for each model
multImportance1 <- get_normalized_importance(multModel1$finalModel)
multImportance2 <- get_normalized_importance(multModel2$finalModel)
multImportance3 <- get_normalized_importance(multModel3$finalModel)
multImportance4 <- get_normalized_importance(multModel4$finalModel)
multImportance5 <- get_normalized_importance(multModel5$finalModel)
# Combine importances
multAllImportances <- list(multImportance1, multImportance2, multImportance3, multImportance4, multImportance5)
# Function to merge importances
merge_importances <- function(importances) {
for (i in 2:length(importances)) {
names(importances[[i]])[2:4] <- paste0(names(importances[[i]])[2:4], "_", i)
}
merged <- Reduce(function(x, y) merge(x, y, by = "Feature", all = TRUE), importances)
merged[is.na(merged)] <- 0  # Replace NAs with 0
gain_cols <- grep("Gain", colnames(merged), value = TRUE)
merged$Cumulative <- rowSums(merged[, ..gain_cols])
return(merged[, .(Feature, Cumulative)])
}
# Merge and sort importances
multCumulativeImportance <- merge_importances(multAllImportances)
multCumulativeImportance <- multCumulativeImportance[order(-multCumulativeImportance$Cumulative), ]
# Print cumulative feature importance
print(multCumulativeImportance)
# Load in the df
mult_pca <- read_csv(paste0(datasets, "PCA_top_contributors_multi.csv"))
# Call the function to extract top features, rank by importance, and save as CSV
top_features_mult <- extract_and_save_top_features(mult_pca, multCumulativeImportance, n = 3, file_name = "top_features_mult_final.csv")
# Print the resulting dataframe
print(top_features_mult)
