{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion tracking IV: Modeling inverse kinematics and dynamics\n",
    "\n",
    "In this script, we will use the `opensim` library to model the inverse kinematics (i.e., joint angles) and dynamics (i.e., joint forces) of the motion tracking data. \n",
    "\n",
    "The documentation of OpenSim project is available [here](https://opensimconfluence.atlassian.net/wiki/spaces/OpenSim/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e:\\\\FLESH_ContinuousBodilyEffort\\\\02_MotionTracking\\\\projectdata_test\\\\Session_0_1', 'e:\\\\FLESH_ContinuousBodilyEffort\\\\02_MotionTracking\\\\projectdata_test\\\\Session_0_2']\n",
      "['0']\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "import opensim\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "curfolder = os.getcwd()\n",
    "\n",
    "# This is where we store the data\n",
    "projectdata = os.path.join(curfolder, 'projectdata_test')\n",
    "# These are the sessions we want to track\n",
    "sessionstotrack = glob.glob(os.path.join(projectdata, 'Session*'))\n",
    "print(sessionstotrack)\n",
    "\n",
    "# Here we store the metadata about weight, height\n",
    "META = pd.read_csv('META.txt', sep='\\t')\n",
    "\n",
    "# Here are the config files for the OpenSim pipeline\n",
    "scalefile = curfolder + '/Pose2Sim/OpenSim_Setup/Scaling_Setup_Pose2Sim_Body135_FLESH.xml'\n",
    "ikfile = curfolder + '/Pose2Sim/OpenSim_Setup/IK_Setup_Pose2Sim_Body135_FLESH.xml'\n",
    "idfile = curfolder + '/Pose2Sim/OpenSim_Setup/ID_Setup_Pose2Sim_Body135_FLESH.xml'\n",
    "\n",
    "# Get sessionIDs\n",
    "sessionIDs = []\n",
    "for session in sessionstotrack:\n",
    "    sessionIDs.append(session.split('\\\\')[-1])\n",
    "    sessionIDs[-1] = sessionIDs[-1].split('_')[1]\n",
    "    # Keep only unique values\n",
    "    sessionIDs = list(set(sessionIDs))\n",
    "\n",
    "print(sessionIDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "# Function to update XML file\n",
    "def update_xml_file(dir, input_file, output_file, new_mass=None, new_model_file=None, new_marker_file=None, new_timerange=None, new_output_model_file=None, new_coord_file=None):\n",
    "\n",
    "    # Load the XML document\n",
    "    tree = ET.parse(input_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # If the file has Scaling in the name, we need to update the marker file\n",
    "    if 'Scaling' in input_file:\n",
    "        \n",
    "        # Update the <mass> element if a new value is provided\n",
    "        if new_mass is not None:\n",
    "            mass_element = root.find('.//mass')\n",
    "            if mass_element is not None:\n",
    "                mass_element.text = new_mass\n",
    "\n",
    "        # Update the <model_file> element within <GenericModelMaker> if a new value is provided\n",
    "        if new_model_file is not None:\n",
    "            model_file_element = root.find('.//GenericModelMaker/model_file')\n",
    "            if model_file_element is not None:\n",
    "                model_file_element.text = new_model_file\n",
    "\n",
    "        # Update the <marker_file> element within <ModelScaler> and <MarkerPlacer> if a new value is provided\n",
    "        if new_marker_file is not None:\n",
    "            marker_file_elements = root.findall('.//marker_file')\n",
    "            for marker_file_element in marker_file_elements:\n",
    "                marker_file_element.text = new_marker_file\n",
    "\n",
    "        # Update all time ranges\n",
    "        if new_timerange is not None:\n",
    "            timerange_elements = root.findall('.//time_range')\n",
    "            for timerange_element in timerange_elements:\n",
    "                timerange_element.text = new_timerange\n",
    "\n",
    "        # Update the <output_model_file> element within <MarkerPlacer> if a new value is provided\n",
    "        if new_output_model_file is not None:\n",
    "            output_model_file_element = root.find('.//MarkerPlacer/output_model_file')\n",
    "            if output_model_file_element is not None:\n",
    "                output_model_file_element.text = new_output_model_file\n",
    "\n",
    "        # Update the <output_model_file> element within <ModelScaler> if a new value is provided\n",
    "        if new_output_model_file is not None:\n",
    "            output_model_file_element = root.find('.//ModelScaler/output_model_file')\n",
    "            if output_model_file_element is not None:\n",
    "                output_model_file_element.text = new_output_model_file\n",
    "    \n",
    "    elif 'IK' in input_file:\n",
    "        # We update model_file\n",
    "        if new_model_file is not None:\n",
    "            model_file_element = root.find('.//model_file')\n",
    "            if model_file_element is not None:\n",
    "                model_file_element.text = new_model_file\n",
    "\n",
    "        # We need to update time range\n",
    "        if new_timerange is not None:\n",
    "            timerange_elements = root.findall('.//time_range')\n",
    "            for timerange_element in timerange_elements:\n",
    "                timerange_element.text = new_timerange\n",
    "\n",
    "        # And we need to update the path to trc file\n",
    "        if new_marker_file is not None:\n",
    "            marker_file_element = root.find('.//marker_file')\n",
    "            if marker_file_element is not None:\n",
    "                marker_file_element.text = new_marker_file\n",
    "\n",
    "        # And output_motion_file\n",
    "        if new_output_model_file is not None:\n",
    "            output_model_file_element = root.find('.//output_motion_file')\n",
    "            if output_model_file_element is not None:\n",
    "                output_model_file_element.text = new_output_model_file\n",
    "\n",
    "    elif 'ID' in input_file:\n",
    "        # We update model_file\n",
    "        if new_model_file is not None:\n",
    "            model_file_element = root.find('.//model_file')\n",
    "            if model_file_element is not None:\n",
    "                model_file_element.text = new_model_file\n",
    "\n",
    "        # We need to update time range\n",
    "        if new_timerange is not None:\n",
    "            timerange_elements = root.findall('.//time_range')\n",
    "            for timerange_element in timerange_elements:\n",
    "                timerange_element.text = new_timerange\n",
    "\n",
    "        # And we need to update the path to mot file\n",
    "        if new_coord_file is not None:\n",
    "            coord_file_element = root.find('.//coordinates_file')\n",
    "            if coord_file_element is not None:\n",
    "                coord_file_element.text = new_coord_file\n",
    "\n",
    "        # And output_motion_file\n",
    "        if new_output_model_file is not None:\n",
    "            output_model_file_element = root.find('.//output_gen_force_file')\n",
    "            if output_model_file_element is not None:\n",
    "                output_model_file_element.text = new_output_model_file\n",
    "\n",
    "    if 'Scaling' in input_file:\n",
    "        output_file_path = os.path.join(dir, output_file) # Scaling is saved in the participant folder\n",
    "        tree.write(output_file_path, encoding='UTF-8', xml_declaration=True)\n",
    "    else:\n",
    "        tree.write(output_file, encoding='UTF-8', xml_declaration=True)\n",
    "\n",
    "# Function to extract time range from a trial\n",
    "def extract_first_and_last_time(file_path):\n",
    "\n",
    "    df = pd.read_csv(file_path, sep='\\t', skiprows=4)\n",
    "    # Extract the first and last time values, time is the second column\n",
    "    first_time = df.iloc[0, 1]\n",
    "    last_time = df.iloc[-1, 1]\n",
    "    \n",
    "    return first_time, last_time\n",
    "\n",
    "# Function to smooth .mot file\n",
    "def smooth_data(input_path, output_path, smoothing_params, plot_column=None):\n",
    "\n",
    "    # Read the entire file\n",
    "    with open(input_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Identify header and data section\n",
    "    header_lines = []\n",
    "    data_start_index = 0\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip() == 'endheader':\n",
    "            header_lines = lines[:i + 1]\n",
    "            data_start_index = i + 1\n",
    "            break\n",
    "\n",
    "    # Extract the column headers and numerical data\n",
    "    column_headers = lines[data_start_index].split()\n",
    "    data_lines = lines[data_start_index + 1:]\n",
    "    data = np.array([list(map(float, line.split())) for line in data_lines])\n",
    "\n",
    "    # Identify the column index for plotting (if applicable)\n",
    "    plot_column_idx = column_headers.index(plot_column) if plot_column else None\n",
    "\n",
    "    # Apply smoothing to each column except 'time'\n",
    "    smoothed_data = data.copy()\n",
    "    for col_idx in range(1, data.shape[1]):  # Skip 'time' (assumed to be the first column)\n",
    "        smoothed_data[:, col_idx] = savgol_filter(\n",
    "            data[:, col_idx], \n",
    "            window_length=smoothing_params['window_length'], \n",
    "            polyorder=smoothing_params['polyorder']\n",
    "        )\n",
    "\n",
    "    # Plot unsmoothed vs smoothed data for the specified column\n",
    "    # if plot_column and plot_column_idx is not None:\n",
    "    #     plt.figure(figsize=(10, 6))\n",
    "    #     plt.plot(data[:, 0], data[:, plot_column_idx], label='Unsmoothed', alpha=0.7)\n",
    "    #     plt.plot(data[:, 0], smoothed_data[:, plot_column_idx], label='Smoothed', alpha=0.7)\n",
    "    #     plt.xlabel('Time')\n",
    "    #     plt.ylabel(plot_column)\n",
    "    #     plt.title(f'Unsmoothed vs Smoothed: {plot_column}')\n",
    "    #     plt.legend()\n",
    "    #     plt.grid(True)\n",
    "    #     plt.show()\n",
    "\n",
    "    # Write back the original structure with smoothed data\n",
    "    with open(output_path, 'w') as output_file:\n",
    "        # Write the header\n",
    "        output_file.writelines(header_lines)\n",
    "        # Write the column headers\n",
    "        output_file.write('\\t'.join(column_headers) + '\\n')\n",
    "        # Write the smoothed data row by row - this is necessary to maintain the same formatting, otherwise inverse dynamics will fail\n",
    "        for row in smoothed_data:\n",
    "            output_file.write('\\t'.join(f'{x:.6f}' for x in row) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The opensim pipeline has three steps\n",
    "- scaling\n",
    "- inverse kinematics\n",
    "- inverse dynamics\n",
    "\n",
    "In scaling, we scale the model to match the anthropometry of the subject. We use the Pose2sim model with 135 keypoints (BODY_135) and use a pre-recorded t-pose video to scale this model and create new model, scaled for each participant.\n",
    "\n",
    "In inverse kinematics, we use the scaled model to estimate the joint angles of the participant. We use the motion tracking data to estimate the joint angles. Joint angles are saved as .mot files in /ResultsInverseKinematics folder per each trial.\n",
    "\n",
    "In inverse dynamics, we use the joint angles to estimate the joint forces. Joint forces are saved as .sto files in /ResultsInverseDynamics folder per each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that session contains of two parts that have the same participants (it's always sessionID_1 and sessionID_2)\n",
    "\n",
    "for sessionID in sessionIDs:\n",
    "    # Get the session path of the first session\n",
    "    session1path = os.path.join(projectdata, 'Session_' + sessionID + '_1')\n",
    "    session2path = os.path.join(projectdata, 'Session_' + sessionID + '_2')\n",
    "    # Get p0 folders from both sessions\n",
    "    p0session1 = os.path.join(session1path, 'P0')\n",
    "    p0session2 = os.path.join(session2path, 'P0')\n",
    "    # Get p1 folders from both sessions\n",
    "    p1session1 = os.path.join(session1path, 'P1')\n",
    "    p1session2 = os.path.join(session2path, 'P1')\n",
    "\n",
    "    # Merge them\n",
    "    participants = [p0session1, p0session2, p1session1, p1session2] #p0session1,p0session2\n",
    "    print(participants)\n",
    "\n",
    "    for p in participants:\n",
    "        os.chdir(p)\n",
    "\n",
    "        ###### SCALING ######\n",
    "        # We do scaling only for Session x_1 (and copy it to x_2)\n",
    "        if 'Session_' + sessionID + '_1' in p:\n",
    "            print(p)\n",
    "\n",
    "            # Get weight from META for this pcn\n",
    "            pcn = p.split('\\\\')[-1].lower()\n",
    "            weight = META.loc[META['pcn'] == pcn, 'weight'].values[0]\n",
    "            new_mass = str(weight)\n",
    "\n",
    "            # Get the path to the input model\n",
    "            new_model_file = 'opensim\\Model_Pose2Sim_Body135.osim'\n",
    "            new_model_file = os.path.join(p, new_model_file)\n",
    "\n",
    "            # Get the path to the marker file\n",
    "            tposefolder = glob.glob(os.path.join(p, '*tpose*'))[0]\n",
    "            trcfolder = os.path.join(tposefolder, 'pose-3d')\n",
    "            trcfiles = glob.glob(os.path.join(trcfolder, '*.trc'))\n",
    "            # Keep only the one with 'butterworth' in its name (this is filtered file)\n",
    "            new_marker_file = [trc for trc in trcfiles if 'butterworth' in trc][0]\n",
    "            # Get the time range of this file\n",
    "            first_time, last_time = extract_first_and_last_time(new_marker_file)\n",
    "            new_timerange = str(first_time) + ' ' + str(last_time)\n",
    "\n",
    "            # New output model file\n",
    "            participant = p.split('\\\\')[-1]\n",
    "            new_output_model_file = 'opensim\\Model_Pose2Sim_scaled_' + sessionID + '_' + participant + '.osim'\n",
    "\n",
    "            # Update the XML file with new values\n",
    "            new_scalefile = 'Scaling_Setup_Pose2Sim_Body135_FLESH_' + sessionID + '_' + participant + '.xml'\n",
    "            update_xml_file(p, scalefile, new_scalefile, new_mass=new_mass, new_model_file=new_model_file, new_marker_file=new_marker_file, new_timerange=new_timerange, new_output_model_file=new_output_model_file)\n",
    "\n",
    "\n",
    "            print('Scaling...')\n",
    "            opensim.ScaleTool(new_scalefile).run()\n",
    "            \n",
    "            # Copy scaling setup also to session 2 of the same participant\n",
    "            session2Path = os.path.join(projectdata, 'Session_' + sessionID + '_2', participant)\n",
    "            os.makedirs(session2Path, exist_ok=True)\n",
    "            shutil.copy(new_scalefile, session2Path)\n",
    "            # And scaled model too\n",
    "            session2ScaledModelPath = os.path.join(session2Path, 'opensim')\n",
    "            os.makedirs(session2ScaledModelPath, exist_ok=True)\n",
    "            shutil.copy(new_output_model_file, session2ScaledModelPath)\n",
    "\n",
    "        # If its session x_2, we directly go to IK and ID\n",
    "        else:\n",
    "            print('Session x_2, skipping scaling...')\n",
    "\n",
    "        ###### INVERSE KINEMATICS ######\n",
    "\n",
    "        # Create folder ResultsInverseKinematics\n",
    "        if not os.path.exists(os.path.join(p, 'ResultsInverseKinematics')):\n",
    "            os.makedirs(os.path.join(p, 'ResultsInverseKinematics'))\n",
    "            \n",
    "        # Collect all folders in p\n",
    "        folders = glob.glob(os.path.join(p, '*'))\n",
    "\n",
    "        # Get rid of all folders/files that we don't want now\n",
    "        folders = [f for f in folders if 'opensim' not in f]\n",
    "        folders = [f for f in folders if 'toml' not in f]\n",
    "        folders = [f for f in folders if 'txt' not in f]\n",
    "        folders = [f for f in folders if 'xml' not in f]\n",
    "        folders = [f for f in folders if 'sto' not in f]\n",
    "        folders = [f for f in folders if 'tpose' not in f]\n",
    "        folders = [f for f in folders if 'ResultsInverseKinematics' not in f]\n",
    "        folders = [f for f in folders if 'ResultsInverseDynamics' not in f]\n",
    "        #print(folders)\n",
    "\n",
    "        for f in folders:\n",
    "            print(f)\n",
    "            trialid = f.split('\\\\')[-1]\n",
    "\n",
    "            # Get trc file\n",
    "            trcfiles = glob.glob(os.path.join(f, '*/*.trc'), recursive=True)\n",
    "            new_trc_file = [trc for trc in trcfiles if 'butterworth' in trc][0]\n",
    "\n",
    "            # Get the time range from it\n",
    "            first_time, last_time = extract_first_and_last_time(new_trc_file)\n",
    "            new_timerange = str(first_time) + ' ' + str(last_time)\n",
    "\n",
    "            # Get the scaled model\n",
    "            scaled_model = new_output_model_file\n",
    "      \n",
    "            # Output motion file\n",
    "            output_motion_file = 'ResultsInverseKinematics/' + sessionID + '_' + trialid + '.mot'\n",
    "            output_motion_file = os.path.join(p, output_motion_file)\n",
    "\n",
    "            # Update the XML file\n",
    "            new_ikfile_name = 'IK_Setup_Pose2Sim_Body135_FLESH_' + sessionID + '_' + trialid + '.xml'\n",
    "            new_ikfile = os.path.join(p, new_ikfile_name)\n",
    "            update_xml_file(p, ikfile, new_ikfile, new_model_file=scaled_model, new_marker_file=new_trc_file, new_timerange=new_timerange, new_output_model_file=output_motion_file)\n",
    "\n",
    "            print('Inverse Kinematics...')\n",
    "            try:\n",
    "                opensim.InverseKinematicsTool(new_ikfile).run()\n",
    "            except:\n",
    "                print('Error in IK')\n",
    "                continue\n",
    "\n",
    "            # opensim doesn't smooth the data, but we need to smooth them before inverse dynamics, otherwise we will magnify the noise\n",
    "            smoothing_params = {'window_length': 35, 'polyorder': 3}\n",
    "            smooth_data(output_motion_file, output_motion_file, smoothing_params, plot_column='arm_flex_r')\n",
    "\n",
    "\n",
    "            ###### INVERSE DYNAMICS ######\n",
    "\n",
    "            # Create folder ResultsInverseKinematics\n",
    "            if not os.path.exists(os.path.join(p, 'ResultsInverseDynamics')):\n",
    "                os.makedirs(os.path.join(p, 'ResultsInverseDynamics'))\n",
    "\n",
    "            # Time range is the same as in IK\n",
    "            # Scaled model is the same\n",
    "            # mot file is the new_ikfile\n",
    "            # Output force file\n",
    "            output_gen_force_file = 'ResultsInverseDynamics/' + sessionID + '_' + trialid + '_ID.sto'\n",
    "            output_gen_force_file = os.path.join(p, output_gen_force_file)\n",
    "\n",
    "            # Update the XML file\n",
    "            new_idfile_name = 'ID_Setup_Pose2Sim_Body135_FLESH_' + sessionID + '_' + trialid + '.xml'\n",
    "            new_idfile = os.path.join(p, new_idfile_name)\n",
    "            update_xml_file(p, idfile, new_idfile, new_model_file=scaled_model, new_timerange=new_timerange, new_coord_file=output_motion_file, new_output_model_file=output_gen_force_file)\n",
    "\n",
    "            print('Inverse Dynamics...')\n",
    "            try:\n",
    "                opensim.InverseDynamicsTool(new_idfile).run()\n",
    "            except:\n",
    "                print('Error in ID')\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All error information is in the opensim.log file in the */Session_x/Participant* folder\n",
    "\n",
    "(There is also erorr_markers.sto file but not sure yet what is that)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensim_scripting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
