---
title: "Overview of methodology"
format:
  html:
    code-overflow: wrap
    code-width: 1200  # Adjust the width in pixels
toc: true
---

Here is text of the methodology from preregistration with links to spceific scripts

### Preprocessing of the raw data
- In [Pre-Processing I: from XDF to raw files](01_XDF_processing/xdf_workflow.ipynb) we load and clean raw XDF data, align streams, and prepare for downstream processing.

### Motion Tracking Processing
- In [Motion tracking I: Preparation of videos](02_MotionTracking_processing/01_Video_preparation.ipynb) we crop video recordings and prepare them for motion capture.
- In [Motion tracking II: 2D pose estimation via OpenPose](02_MotionTracking_processing/02_Track_OpenPose.ipynb) we use OpenPose for 2D pose estimation.
- In [Motion tracking III: Triangulation via Pose2sim](02_MotionTracking_processing/03_Track_pose2sim.ipynb) we convert 2D coordinates to 3D using pose2sim.
- In [Motion tracking IV: Modeling inverse kinematics and dynamics](02_MotionTracking_processing/04_Track_InverseKinDyn.ipynb) we compute inverse kinematics and dynamics using OpenSim

### Signal Processing
- In [Processing I: Motion tracking and balance](03_TS_processing/01_TS_processing_motion.ipynb) we clean and interpolate motion signals, and extract derivatives such as speed, acceleration and jerk.
- In [Processing II: Acoustics](03_TS_processing/02_TS_processing_acoustics.ipynb) we extract relevant acoustic features.
- In [Processing III: Merging multimodal data](03_TS_processing/03_TS_merging.ipynb) we merge motion and acoustic time series.

### Movement Annotation
- In [Movement annotation I: Preparing training data and data for classifier](04_TS_movementAnnotation/01_Classify_preparation.ipynb) we prepare our multimodal time series for training purposes.
- In [Movement annotation II: Training movement classifier, and annotating timeseries data](04_TS_movementAnnotation/02_MovementClassifier.ipynb) we train and evaluate classifiers for movement detection.
- In [Movement annotation III: Computing interrater agreement between manual and automatic annotation](04_TS_movementAnnotation/03_InterAgreement.ipynb) we evaluate inter-annotator agreement.

### Final Merge
- In [Final merge](05_finalMerge/TS_mergeAnnotations.ipynb) we merge annotations with timeseries.

### Concept Similarity
- In [Computing concept similarity using ConceptNet word embeddings](06_ConceptSimilarity/ConceptNet_similarity.ipynb): we assess semantic similarity between concepts using ConceptNet.

### Feature Extraction
- In [Extraction of effort-related features](07_TS_featureExtraction/TS_extraction.ipynb) we extract features from the multimodal time series for modelling purposes.

### Exploratory analysis: Most predictive features of effort
- In [Exploratory Analysis I: Using PCA to identify effort dimensions](08_Analysis_XGBoost/01_PCA_featureDimensions.ipynb) we explore dimensionality of extracted features using Principal Component Analysis.
- In [Exploratory Analysis II: Identifying effort-related features contributing to misunderstanding resolution](08_Analysis_XGBoost/02_XGBoost_effortIndicators.qmd) we assess feature importance using eXtreme Gradient Boosting.

### Confirmatory nalysis: statistical modelling
- In [Statistical Analysis: Modelling the Effect of Communicative Attempt (H1) and Answer Similarity (H2) on Effort](09_Analysis_Modeling/Modelling_syntheticData.qmd) we build causal and statistical models testing our hypothesis.

