View(gesData4)
View(gesData5)
View(gesData5)
# Set seed for reproducibility
set.seed(998)
# Define the number of subsets
numSubsets <- 5
# Load MICE-imputed data (using placeholder 'data_ges' as the input dataset)
gesDataXGB <- data_ges
# Ensure 'correction_info' is a factor
gesDataXGB$correction_info <- as.factor(gesDataXGB$correction_info)
# Remove rows with only NA values
gesDataXGB <- gesDataXGB[rowSums(is.na(gesDataXGB)) < ncol(gesDataXGB), ]
# Split data by levels of 'correction_info'
correction_levels <- levels(gesDataXGB$correction_info)
split_data <- split(gesDataXGB, gesDataXGB$correction_info)
# Initialize a list to store subsets
gesSubsets <- vector("list", length = numSubsets)
# Distribute rows for each level equally across subsets
for (level in correction_levels) {
level_data <- split_data[[level]]
subset_sizes <- rep(floor(nrow(level_data) / numSubsets), numSubsets)
remainder <- nrow(level_data) %% numSubsets
# Distribute remainder rows randomly
if (remainder > 0) {
subset_sizes[seq_len(remainder)] <- subset_sizes[seq_len(remainder)] + 1
}
# Shuffle rows of the level and assign to subsets
shuffled_data <- level_data[sample(nrow(level_data)), ]
indices <- cumsum(c(0, subset_sizes))
for (i in 1:numSubsets) {
if (is.null(gesSubsets[[i]])) {
gesSubsets[[i]] <- shuffled_data[(indices[i] + 1):indices[i + 1], ]
} else {
gesSubsets[[i]] <- rbind(gesSubsets[[i]], shuffled_data[(indices[i] + 1):indices[i + 1], ])
}
}
}
# Naming the subsets
names(gesSubsets) <- paste0("gesData", 1:numSubsets)
# Verify balance in subsets
for (i in 1:numSubsets) {
cat("Subset", i, "contains rows:", nrow(gesSubsets[[i]]), "and levels:\n")
print(table(gesSubsets[[i]]$correction_info))
}
# Remove any rows with only NAs from subsets just to ensure cleanliness
gesSubsets <- lapply(gesSubsets, function(subset) {
subset[rowSums(is.na(subset)) < ncol(subset), ]
})
# Access the subsets
gesData1 <- gesSubsets$gesData1
gesData2 <- gesSubsets$gesData2
gesData3 <- gesSubsets$gesData3
gesData4 <- gesSubsets$gesData4
gesData5 <- gesSubsets$gesData5
# Combine subsets into 80% groups
gesData1234 <- rbind(gesData1, gesData2, gesData3, gesData4)
gesData1235 <- rbind(gesData1, gesData2, gesData3, gesData5)
gesData1245 <- rbind(gesData1, gesData2, gesData4, gesData5)
gesData1345 <- rbind(gesData1, gesData3, gesData4, gesData5)
gesData2345 <- rbind(gesData2, gesData3, gesData4, gesData5)
# Final verification of all levels in the combined datasets
combined_sets <- list(gesData1234, gesData1235, gesData1245, gesData1345, gesData2345)
names(combined_sets) <- c("gesData1234", "gesData1235", "gesData1245", "gesData1345", "gesData2345")
for (set_name in names(combined_sets)) {
cat("Dataset", set_name, "contains rows:", nrow(combined_sets[[set_name]]), "and levels:\n")
print(table(combined_sets[[set_name]]$correction_info))
}
gesModel1 <- caret::train(
correction_info ~ .,
data = gesData1234,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(gesModel1, file = paste0(models, "gesModel1.rds"), compress = TRUE)
gesModel2 <- caret::train(
correction_info ~ .,
data = gesData1235,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(gesModel2, file = paste0(models, "gesModel2.rds"), compress = TRUE)
gesModel3 <- caret::train(
correction_info ~ .,
data = gesData1245,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(gesModel3, file = paste0(models, "gesModel3.rds"), compress = TRUE)
gesModel4 <- caret::train(
correction_info ~ .,
data = gesData1345,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(gesModel4, file = paste0(models, "gesModel4.rds"), compress = TRUE)
gesModel5 <- caret::train(
correction_info ~ .,
data = gesData2345,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(gesModel5, file = paste0(models, "gesModel5.rds"), compress = TRUE)
gesModel1 <- readRDS(paste0(models, "gesModel1.rds"))
gesModel2 <- readRDS(paste0(models, "gesModel2.rds"))
gesModel3 <- readRDS(paste0(models, "gesModel3.rds"))
gesModel4 <- readRDS(paste0(models, "gesModel4.rds"))
gesModel5 <- readRDS(paste0(models, "gesModel5.rds"))
# Generate predictions
gesPredictions1 <- predict(gesModel1, newdata = gesData5)
gesPredictions2 <- predict(gesModel2, newdata = gesData4)
gesPredictions3 <- predict(gesModel3, newdata = gesData3)
gesPredictions4 <- predict(gesModel4, newdata = gesData2)
gesPredictions5 <- predict(gesModel5, newdata = gesData1)
# Compute confusion matrices
gesCm1 <- confusionMatrix(gesPredictions1, gesData5$correction_info)
gesCm2 <- confusionMatrix(gesPredictions2, gesData4$correction_info)
gesCm3 <- confusionMatrix(gesPredictions3, gesData3$correction_info)
gesCm4 <- confusionMatrix(gesPredictions4, gesData2$correction_info)
gesCm5 <- confusionMatrix(gesPredictions5, gesData1$correction_info)
# Extract p-values (you need to define how to extract these based on your metric, here assumed to be some metric from confusion matrix)
gesPValues <- c(gesCm1$overall['AccuracyPValue'],
gesCm2$overall['AccuracyPValue'],
gesCm3$overall['AccuracyPValue'],
gesCm4$overall['AccuracyPValue'],
gesCm5$overall['AccuracyPValue'])
# Fisher's method
gesFisher_combined <- -2 * sum(log(gesPValues))
df <- 2 * length(gesPValues)
gesPCcombined_fisher <- 1 - pchisq(gesFisher_combined, df)
print(gesPCcombined_fisher)
# Stouffer's method
gesZ_scores <- qnorm(1 - gesPValues/2)
gesCombined_z <- sum(gesZ_scores) / sqrt(length(gesPValues))
gesP_combined_stouffer <- 2 * (1 - pnorm(abs(gesCombined_z)))
print(gesP_combined_stouffer)
XGBgesModel1 <- gesModel1$finalModel
importanceXGBgesModel1 <- xgb.importance(model = XGBgesModel1)
print(importanceXGBgesModel1)
xgb.plot.importance(importanceXGBgesModel1)
XGBgesModel2 <- gesModel2$finalModel
importanceXGBgesModel2 <- xgb.importance(model = XGBgesModel2)
print(importanceXGBgesModel2)
xgb.plot.importance(importanceXGBgesModel2)
XGBgesModel3 <- gesModel3$finalModel
importanceXGBgesModel3 <- xgb.importance(model = XGBgesModel3)
print(importanceXGBgesModel3)
xgb.plot.importance(importanceXGBgesModel3)
XGBgesModel4 <- gesModel4$finalModel
importanceXGBgesModel4 <- xgb.importance(model = XGBgesModel4)
print(importanceXGBgesModel4)
xgb.plot.importance(importanceXGBgesModel4)
XGBgesModel5 <- gesModel5$finalModel
importanceXGBgesModel5 <- xgb.importance(model = XGBgesModel5)
print(importanceXGBgesModel5)
xgb.plot.importance(importanceXGBgesModel5)
# Function to extract and normalize importance
get_normalized_importance <- function(model) {
importance <- xgb.importance(model = model)
importance$Gain <- importance$Gain / sum(importance$Gain)
return(importance)
}
# Extract normalized importance for each model
gesImportance1 <- get_normalized_importance(gesModel1$finalModel)
gesImportance2 <- get_normalized_importance(gesModel2$finalModel)
gesImportance3 <- get_normalized_importance(gesModel3$finalModel)
gesImportance4 <- get_normalized_importance(gesModel4$finalModel)
gesImportance5 <- get_normalized_importance(gesModel5$finalModel)
# Combine importances
gesAllImportances <- list(gesImportance1, gesImportance2, gesImportance3, gesImportance4, gesImportance5)
# Function to merge importances
merge_importances <- function(importances) {
for (i in 2:length(importances)) {
names(importances[[i]])[2:4] <- paste0(names(importances[[i]])[2:4], "_", i)
}
merged <- Reduce(function(x, y) merge(x, y, by = "Feature", all = TRUE), importances)
merged[is.na(merged)] <- 0  # Replace NAs with 0
gain_cols <- grep("Gain", colnames(merged), value = TRUE)
merged$Cumulative <- rowSums(merged[, ..gain_cols])
return(merged[, .(Feature, Cumulative)])
}
# Merge and sort importances
gesCumulativeImportance <- merge_importances(gesAllImportances)
gesCumulativeImportance <- gesCumulativeImportance[order(-gesCumulativeImportance$Cumulative), ]
# Print cumulative feature importance
print(gesCumulativeImportance)
# Load necessary libraries
library(tidyverse)
library(factoextra)
install.packages('factoextra')
library(factoextra)
library(ggplot2)
# Data Preparation
# Only select numerical columns
data <- data_ges %>% select(where(is.numeric))
# Data Preparation
# Only select numerical columns
Gdata <- data_ges %>% select(where(is.numeric))
# Replace NA with 0
Gdata[is.na(Gdata)] <- 0
# Separate labels
labels <- data_ges$correction_info
# Standardize the features
data_scaled <- scale(Gdata)
# Perform PCA
pca <- prcomp(data_scaled, center = TRUE, scale. = TRUE)
View(Gdata)
View(Gdata)
# Identify columns with zero variance
zero_variance_cols <- apply(data_scaled, 2, var) == 0
zero_variance_cols
# Remove zero-variance columns
data_scaled <- data_scaled[, !zero_variance_cols]
# Check if any columns were removed
if (any(zero_variance_cols)) {
cat("Removed columns with zero variance:\n")
print(names(zero_variance_cols[zero_variance_cols]))
}
print(names(zero_variance_cols[zero_variance_cols]))}
if (any(zero_variance_cols)) {
cat("Removed columns with zero variance:\n")
print(names(zero_variance_cols[zero_variance_cols]))}
zero_variance_cols
# Replace NA with 0
Gdata[is.na(Gdata)] <- 0
# get rid of all gesture-superfluous cols
colstoremove <- c('numofArt')
Gdata <- Gdata %>%
select(-contains(colstoremove))
# Separate labels
labels <- data_ges$correction_info
# Standardize the features
data_scaled <- scale(Gdata)
# Perform PCA
pca <- prcomp(data_scaled, center = TRUE, scale. = TRUE)
# Explained Variance
explained_variance <- summary(pca)$importance[2, ] # Proportion of Variance
cumulative_variance <- cumsum(explained_variance)
# Plot explained variance
fviz_eig(pca, addlabels = TRUE, ylim = c(0, 1)) +
ggtitle("Explained Variance by PCA")
# Number of components explaining 95% variance
threshold <- 0.95
num_components <- which(cumulative_variance >= threshold)[1]
cat("Number of components explaining 95% variance:", num_components, "\n")
# Feature Contributions to Components
feature_contributions <- as.data.frame(pca$rotation)
feature_contributions$Feature <- rownames(feature_contributions)
rownames(feature_contributions) <- NULL
fviz_eig(pca, addlabels = TRUE, ylim = c(0, 1)) +
ggtitle("Explained Variance by PCA")
# Print feature contributions to PCs
cat("\nFeature Contributions to Principal Components:\n")
print(feature_contributions)
# Top contributing features for each principal component
top_contributors <- feature_contributions %>%
pivot_longer(-Feature, names_to = "PrincipalComponent", values_to = "Contribution") %>%
group_by(PrincipalComponent) %>%
slice_max(order_by = abs(Contribution), n = 10) %>%
arrange(PrincipalComponent, desc(abs(Contribution)))
cat("\nTop Contributing Features per Component:\n")
print(top_contributors)
pca
# Explained Variance
explained_variance <- summary(pca)$importance[2, ] # Proportion of Variance
cumulative_variance <- cumsum(explained_variance)
# Plot explained variance
fviz_eig(pca, addlabels = TRUE, ylim = c(0, 1)) +
ggtitle("Explained Variance by PCA")
biplot(pca, scale = 0, cex = 0.6)
biplot(pca, scale = 0, cex = 0.6)
screeplot(pca)
screeplot(pca)
# get rid of all gesture-superfluous cols
colstokeep <- c('envelope', 'loudness', 'roughness', 'flux', 'novelty',
'harmEnergy', 'audio', 'envelope_change', 'f0',
'f1', 'f2', 'f3', 'env_', 'duration_voc', 'COP', 'correction', 'TrialID', 'modality')
# get rid of all gesture-superfluous cols
colstokeep <- c('envelope', 'loudness', 'roughness', 'flux', 'novelty',
'harmEnergy', 'audio', 'envelope_change', 'f0',
'f1', 'f2', 'f3', 'env_', 'duration_voc', 'COP', 'correction', 'TrialID', 'modality')
data_voc <- data_voc %>%
select(matches(paste(colstokeep, collapse = "|")))
# get rid of NA columns
data_voc <- data_voc[, colSums(is.na(data_voc)) == 0] # CAREFUL - here we loose lot of cols (MICE maybe needed)
data_voc <- data_voc %>%
select(-TrialID, -modality)
# get rid of all char columns
data_voc <- data_voc[, sapply(data_voc, class) != "character"]
# prepare predictors
predictors <- setdiff(names(data_voc), "correction_info")
formula_str <- paste("correction_info ~", paste(predictors, collapse = " + "))
# Convert the formula string to a formula object
vocTree_formula <- as.formula(formula_str)
# Now use the formula in rpart
vocTree <- rpart(formula = vocTree_formula, data = data_ges,
method='class', # Specify that it's a classification tree
control = rpart.control(maxdepth = 5)  # Control parameters for the 'rpart' function
)
prp(
vocTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
set.seed(995) # Set a seed for reproducibility
# Split the data into training and testing subsets
sample_indices <- sample(1:nrow(data_voc), 0.8*nrow(data_voc)) # 80% training, 20% testing
train_data <- data_voc[sample_indices, ]
test_data <- data_voc[-sample_indices, ]
# Untuned Model with importance (permutation) option set
vocUntuned <- ranger(
y = train_data$correction_info,
x = train_data[,0:9], # FLAGGED: adapt
num.trees = 500,
importance = "permutation"
)
predictions <- predict(vocUntuned, data = test_data)$predictions
# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$correction_info)
# Print the confusion matrix
print(confusion_matrix)
# Calculate feature importance
feature_importance <- importance(vocUntuned, num.threads = 1, type = 1)
# Convert to data frame
feature_importance <- as.data.frame(feature_importance, stringsAsFactors = FALSE)
feature_importance$Feature <- rownames(feature_importance)
colnames(feature_importance) <- c("Importance", "Feature")
# Sort by importance
sorted_feature_importance <- feature_importance[order(-feature_importance$Importance), ]
# Print sorted feature importance
print(sorted_feature_importance)
# Define the number of CPU cores to use
num_cores <- detectCores()
# Create a cluster with specified number of cores
cl <- makeCluster(num_cores)
tuneVoc <- makeClassifTask(data = data_voc[,0:10], # FLAGGED: adapt
target = "correction_info")
tuneVoc <- tuneRanger(tuneVoc,
measure = list(multiclass.brier),
num.trees = 500)
View(data_voc)
View(data_voc)
View(data)
View(data)
str(data)
# Turn percProm to factor
data$correction_info <- as.factor(data$correction_info)
# Load cleaned effort data
data <- read_csv(paste0(processfolder, "\\datasets\\features_df_final.csv"))
str(data)
# Turn percProm to factor
data$correction_info <- as.factor(data$correction_info)
data$TrialID <- as.factor(data$TrialID)
data$modality <- as.factor(data$modality)
# First, remove the specified columns
data <- data %>%
select(-concept, -answer_fol, -answer_fol_dist,
-answer_prev, -answer_prev_dist, -concept_id, -expressibility, -response_time_sec,
-correction)
# Create three dfs separately for each modality
data_ges <- data %>%
filter(modality == "gebaren")
data_voc <- data %>%
filter(modality == "geluiden")
data_mult <- data %>%
filter(modality == "combinatie")
View(data)
View(data)
View(data_voc)
View(data_voc)
# get rid of all gesture-superfluous cols
colstokeep <- c('envelope', 'loudness', 'roughness', 'flux', 'novelty',
'harmEnergy', 'audio', 'envelope_change', 'f0',
'f1', 'f2', 'f3', 'env_', 'duration_voc', 'COP', 'correction', 'TrialID', 'modality')
data_voc <- data_voc %>%
select(matches(paste(colstokeep, collapse = "|")))
View(data_voc)
View(data_voc)
# get rid of NA columns
data_voc <- data_voc[, colSums(is.na(data_voc)) == 0] # CAREFUL - here we loose lot of cols (MICE maybe needed)
View(data_voc)
View(data_voc)
# Load cleaned effort data
data <- read_csv(paste0(processfolder, "\\datasets\\features_df_final.csv"))
str(data)
# Turn percProm to factor
data$correction_info <- as.factor(data$correction_info)
data$TrialID <- as.factor(data$TrialID)
data$modality <- as.factor(data$modality)
# First, remove the specified columns
data <- data %>%
select(-concept, -answer_fol, -answer_fol_dist,
-answer_prev, -answer_prev_dist, -concept_id, -expressibility, -response_time_sec,
-correction)
# Create three dfs separately for each modality
data_ges <- data %>%
filter(modality == "gebaren")
data_voc <- data %>%
filter(modality == "geluiden")
data_mult <- data %>%
filter(modality == "combinatie")
# get rid of all gesture-superfluous cols
colstokeep <- c('envelope', 'loudness', 'roughness', 'flux', 'novelty',
'harmEnergy', 'audio', 'envelope_change', 'f0',
'f1', 'f2', 'f3', 'env_', 'duration_voc', 'COP', 'correction', 'TrialID', 'modality')
data_voc <- data_voc %>%
select(matches(paste(colstokeep, collapse = "|")))
# get rid of NA columns
data_voc[is.na(data_voc)] <- 0 # CAREFUL - here we loose lot of cols (MICE maybe needed)
colstoremove <- c('sync')
data_voc <- data_voc %>%
select(-contains(colstoremove))
# get rid of NA columns
data_voc[is.na(data_voc)] <- 0 # CAREFUL - here we loose lot of cols (MICE maybe needed)
colstoremove <- c('sync', 'time')
data_voc <- data_voc %>%
select(-contains(colstoremove))
# get rid of NA columns
data_voc[is.na(data_voc)] <- 0 # CAREFUL - here we loose lot of cols (MICE maybe needed)
data_voc <- data_voc %>%
select(-TrialID, -modality)
# get rid of all char columns
data_voc <- data_voc[, sapply(data_voc, class) != "character"]
# prepare predictors
predictors <- setdiff(names(data_voc), "correction_info")
formula_str <- paste("correction_info ~", paste(predictors, collapse = " + "))
# Convert the formula string to a formula object
vocTree_formula <- as.formula(formula_str)
# Now use the formula in rpart
vocTree <- rpart(formula = vocTree_formula, data = data_ges,
method='class', # Specify that it's a classification tree
control = rpart.control(maxdepth = 5)  # Control parameters for the 'rpart' function
)
prp(
vocTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
set.seed(995) # Set a seed for reproducibility
# Split the data into training and testing subsets
sample_indices <- sample(1:nrow(data_voc), 0.8*nrow(data_voc)) # 80% training, 20% testing
train_data <- data_voc[sample_indices, ]
test_data <- data_voc[-sample_indices, ]
# Untuned Model with importance (permutation) option set
vocUntuned <- ranger(
y = train_data$correction_info,
x = train_data[,0:118], # FLAGGED: adapt
num.trees = 500,
importance = "permutation"
)
predictions <- predict(vocUntuned, data = test_data)$predictions
# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$correction_info)
# Print the confusion matrix
print(confusion_matrix)
# Calculate feature importance
feature_importance <- importance(vocUntuned, num.threads = 1, type = 1)
# Convert to data frame
feature_importance <- as.data.frame(feature_importance, stringsAsFactors = FALSE)
feature_importance$Feature <- rownames(feature_importance)
colnames(feature_importance) <- c("Importance", "Feature")
# Sort by importance
sorted_feature_importance <- feature_importance[order(-feature_importance$Importance), ]
# Print sorted feature importance
print(sorted_feature_importance)
# Define the number of CPU cores to use
num_cores <- detectCores()
# Create a cluster with specified number of cores
cl <- makeCluster(num_cores)
tuneVoc <- makeClassifTask(data = data_voc[,0:119], # FLAGGED: adapt
target = "correction_info")
tuneVoc <- tuneRanger(tuneVoc,
measure = list(multiclass.brier),
num.trees = 500)
tuneVoc <- tuneRanger(tuneVoc,
measure = list(multiclass.brier),
num.trees = 500)
tuneVoc <- makeClassifTask(data = data_voc[,0:119], # FLAGGED: adapt
target = "correction_info")
tuneVoc <- tuneRanger(tuneVoc,
measure = list(multiclass.brier),
num.trees = 500)
tuneVoc <- tuneRanger(tuneVoc,
measure = list(multiclass.brier),
num.trees = 400)
tuneVoc <- tuneRanger(tuneVoc,
measure = list(multiclass.brier),
mtry = 50
num.trees = 400)
tuneVoc <- tuneRanger(tuneVoc,
measure = list(multiclass.brier),
mtry = 50,
num.trees = 400)
tuneVoc <- tuneRanger(tuneVoc,
measure = list(multiclass.brier),
num.trees = 100)
tuneVoc <- tuneRanger(tuneVoc,
measure = list(multiclass.brier),
num.trees = 1000)
tuneVoc <- tuneRanger(tuneVoc,
measure = list(multiclass.brier),
num.trees = 500)
tuneVoc <- tuneRanger(tuneVoc,
measure = list(multiclass.brier),
num.trees = 500)
