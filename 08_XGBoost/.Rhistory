data_ges <- data_ges[, sapply(data_ges, class) != "character"]
# prepare predictors
predictors <- setdiff(names(data), "correction_info")
formula_str <- paste("correction_info ~", paste(predictors, collapse = " + "))
# Convert the formula string to a formula object
erTree_formula <- as.formula(formula_str)
# Now use the formula in rpart
erTree <- rpart(formula = erTree_formula, data = data_ges)
# prepare predictors
predictors <- setdiff(names(data_ges), "correction_info")
formula_str <- paste("correction_info ~", paste(predictors, collapse = " + "))
# Convert the formula string to a formula object
erTree_formula <- as.formula(formula_str)
# Now use the formula in rpart
erTree <- rpart(formula = erTree_formula, data = data_ges)
print(erTree_formula)
# prepare predictors
predictors <- setdiff(names(data_ges), "correction_info")
formula_str <- paste("correction_info ~", paste(predictors, collapse = " + "))
# Convert the formula string to a formula object
erTree_formula <- as.formula(formula_str)
# Now use the formula in rpart
erTree <- rpart(formula = erTree_formula, data = data_ges,
method='class', # Specify that it's a classification tree
control = rpart.control(maxdepth = 5)  # Control parameters for the 'rpart' function
)
# prepare predictors
predictors <- setdiff(names(data_ges), "correction_info")
formula_str <- paste("correction_info ~", paste(predictors, collapse = " + "))
# Convert the formula string to a formula object
erTree_formula <- as.formula(formula_str)
# Now use the formula in rpart
erTree <- rpart(formula = erTree_formula, data = data_ges,
method='class', # Specify that it's a classification tree
control = rpart.control(maxdepth = 5)  # Control parameters for the 'rpart' function
)
prp(
gerTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
# prepare predictors
predictors <- setdiff(names(data_ges), "correction_info")
formula_str <- paste("correction_info ~", paste(predictors, collapse = " + "))
# Convert the formula string to a formula object
erTree_formula <- as.formula(formula_str)
# Now use the formula in rpart
erTree <- rpart(formula = erTree_formula, data = data_ges,
method='class', # Specify that it's a classification tree
control = rpart.control(maxdepth = 5)  # Control parameters for the 'rpart' function
)
prp(
erTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
prp(
erTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 4     # Length of factor levels displayed on the plot (increase as needed)
)
prp(
erTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 3     # Length of factor levels displayed on the plot (increase as needed)
)
prp(
erTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
set.seed(998) # Set a seed for reproducibility
# Split the data into training and testing subsets
sample_indices <- sample(1:nrow(data_ges), 0.7*nrow(data_ges)) # 70% training, 30% testing
train_data <- data_ges[sample_indices, ]
test_data <- data_ges[-sample_indices, ]
train_data[,14:52]
train_data[,0:165]
train_data[,0:166]
prp(
gesTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
# Now use the formula in rpart
gesTree <- rpart(formula = gesTree_formula, data = data_ges,
method='class', # Specify that it's a classification tree
control = rpart.control(maxdepth = 5)  # Control parameters for the 'rpart' function
)
# prepare predictors
predictors <- setdiff(names(data_ges), "correction_info")
formula_str <- paste("correction_info ~", paste(predictors, collapse = " + "))
# Convert the formula string to a formula object
gesTree_formula <- as.formula(formula_str)
# Now use the formula in rpart
gesTree <- rpart(formula = gesTree_formula, data = data_ges,
method='class', # Specify that it's a classification tree
control = rpart.control(maxdepth = 5)  # Control parameters for the 'rpart' function
)
prp(
gesTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
set.seed(998) # Set a seed for reproducibility
# Split the data into training and testing subsets
sample_indices <- sample(1:nrow(data_ges), 0.7*nrow(data_ges)) # 70% training, 30% testing
train_data <- data_ges[sample_indices, ]
test_data <- data_ges[-sample_indices, ]
# Untuned Model with importance (permutation) option set
gesUntuned <- ranger(
y = train_data$correction_info,
x = train_data[,0:165],
num.trees = 500,
importance = "permutation"
)
predictions <- predict(gesUntuned, data = test_data)$predictions
# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$correction_info)
# Print the confusion matrix
print(confusion_matrix)
# Calculate feature importance
feature_importance <- importance(gesUntuned, num.threads = 1, type = 1)
# Convert to data frame
feature_importance <- as.data.frame(feature_importance, stringsAsFactors = FALSE)
feature_importance$Feature <- rownames(feature_importance)
colnames(feature_importance) <- c("Importance", "Feature")
# Sort by importance
sorted_feature_importance <- feature_importance[order(-feature_importance$Importance), ]
# Print sorted feature importance
print(sorted_feature_importance)
# Split the data into training and testing subsets
sample_indices <- sample(1:nrow(data_ges), 0.8*nrow(data_ges)) # 80% training, 30% testing
train_data <- data_ges[sample_indices, ]
test_data <- data_ges[-sample_indices, ]
# Untuned Model with importance (permutation) option set
gesUntuned <- ranger(
y = train_data$correction_info,
x = train_data[,0:165],
num.trees = 500,
importance = "permutation"
)
predictions <- predict(gesUntuned, data = test_data)$predictions
# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$correction_info)
# Print the confusion matrix
print(confusion_matrix)
# Calculate feature importance
feature_importance <- importance(gesUntuned, num.threads = 1, type = 1)
# Convert to data frame
feature_importance <- as.data.frame(feature_importance, stringsAsFactors = FALSE)
feature_importance$Feature <- rownames(feature_importance)
colnames(feature_importance) <- c("Importance", "Feature")
# Sort by importance
sorted_feature_importance <- feature_importance[order(-feature_importance$Importance), ]
# Print sorted feature importance
print(sorted_feature_importance)
# Untuned Model with importance (permutation) option set
gesUntuned <- ranger(
y = train_data$correction_info,
x = train_data[,0:165],
num.trees = 500,
importance = "permutation"
)
predictions <- predict(gesUntuned, data = test_data)$predictions
# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$correction_info)
# Print the confusion matrix
print(confusion_matrix)
# Calculate feature importance
feature_importance <- importance(gesUntuned, num.threads = 1, type = 1)
# Convert to data frame
feature_importance <- as.data.frame(feature_importance, stringsAsFactors = FALSE)
feature_importance$Feature <- rownames(feature_importance)
colnames(feature_importance) <- c("Importance", "Feature")
# Sort by importance
sorted_feature_importance <- feature_importance[order(-feature_importance$Importance), ]
# Print sorted feature importance
print(sorted_feature_importance)
# Define the number of CPU cores to use
num_cores <- detectCores()
# Create a cluster with specified number of cores
cl <- makeCluster(num_cores)
tuneGes <- makeClassifTask(data = data_ges[,0:165],
target = "correction_info")
tuneGes <- makeClassifTask(data = data_ges[,0:166],
target = "correction_info")
tuneGes <- tuneRanger(tuneGes,
measure = list(multiclass.brier),
num.trees = 500)
#Return hyperparameter values
tuneGes
View(tuneGes)
View(tuneGes)
tuneGes[["recommended.pars"]][["sample.fraction"]]
tuneGes[["recommended.pars"]][["multiclass.brier"]]
gerTuned <- ranger(
y = train_data$percProm,
x = train_data[, 14:52],
num.trees = 5000,
mtry = 5,
min.node.size = 2,
sample.fraction = 0.4882922,
importance = "permutation"
)
gesTuned <- ranger(
y = train_data$correction_info,
x = train_data[,0:165],
num.trees = 5000,
mtry = 20, # Set the recommended mtry value (number of features).
min.node.size = 4, # Set the recommended min.node.size value (number of samples before a node terminates).
sample.fraction = 0.2387222, # Set the recommended sample fraction value.(% of data for bagging).
importance = "permutation" # Permutation is a computationally intensive test.
)
predictions <- predict(gesTuned, data = test_data)$predictions
# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$correction_info)
# Print the confusion matrix
print(confusion_matrix)
# Calculate feature importance
feature_importance <- importance(gesTuned, num.threads = 1, type = 1)
# Convert to data frame
feature_importance <- as.data.frame(feature_importance, stringsAsFactors = FALSE)
feature_importance$Feature <- rownames(feature_importance)
colnames(feature_importance) <- c("Importance", "Feature")
# Sort by importance
sorted_feature_importance <- feature_importance[order(-feature_importance$Importance), ]
# Print sorted feature importance
print(sorted_feature_importance)
# Create a classification task for tuning
tuneGes <- makeClassifTask(data = train_data[, 0:166], target = "correction_info")
# Tune the model
tuneGes <- tuneRanger(tuneGes, measure = list(multiclass.brier), num.trees = 500)
# Return hyperparameter values
tuneGes
View(tuneGes)
View(tuneGes)
tuneGes[["recommended.pars"]][["sample.fraction"]]
tuneGes[["recommended.pars"]][["multiclass.brier"]]
gesTuned <- ranger(
y = train_data$correction_info,
x = train_data[, 0:165],
num.trees = 5000,
mtry = 66,
min.node.size = 3,
sample.fraction = 0.2254135,
importance = "permutation"
)
i
# Predict on the test data
predictions <- predict(gesTuned, data = test_data)$predictions
# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$correction_info)
# Print the confusion matrix
print(confusion_matrix)
# Calculate feature importance
feature_importance <- importance(gesTuned, num.threads = 1, type = 1)
# Convert to data frame
feature_importance_df <- as.data.frame(feature_importance, stringsAsFactors = FALSE)
feature_importance_df$Feature <- rownames(feature_importance_df)
colnames(feature_importance_df) <- c("Importance", "Feature")
# Sort by importance
sorted_feature_importance <- feature_importance_df[order(-feature_importance_df$Importance), ]
# Print sorted feature importance
print(sorted_feature_importance)
# Detect the number of available cores
cores <- detectCores() #- 1  # Leave one core free
# Create a cluster with the detected number of cores
cl <- makeCluster(cores)
# Register the parallel backend
registerDoParallel(cl)
grid_tune <- expand.grid(
nrounds = c(5000, 10000),
max_depth = c(3, 6),
eta = c(0.05, 0.1),
gamma = c(0.1),
colsample_bytree = c(0.6, 0.8),
min_child_weight = c(1),
subsample = c(0.75, 1.0)
)
# Calculate total combinations
total_combinations <- nrow(grid_tune)
# Estimate single model run time (assume 1 minute per run)
single_model_time <- 10 # minute
# Total runs for cross-validation
folds <- 5
total_runs <- total_combinations * folds
# Total time estimation without parallel processing
total_time <- total_runs * single_model_time # in minutes
# Convert to hours
total_time_hours <- total_time / 60
# Output estimated time without parallel processing
print(paste("Estimated time for grid search without parallel processing:", total_time_hours, "hours"))
# Parallel processing with 4 cores
cores <- 24
total_time_parallel <- total_time / cores # in minutes
# Convert to hours
total_time_parallel_hours <- total_time_parallel / 60
# Output estimated time with parallel processing
print(paste("Estimated time for grid search with", cores, "cores:", total_time_parallel_hours, "hours"))
rm(total_combinations,single_model_time,folds,total_runs,total_time,total_time_hours,total_time_parallel,total_time_parallel_hours,cores)
write.csv(data_ges, file = paste0(datasets, "gesDataXGB.csv"), row.names = FALSE)
write.csv(data_ges, file = paste0(datasets, "gesDataXGB.csv"), row.names = FALSE)
write.csv(data_ges, file = paste0(datasets, "gesDataXGB.csv"), row.names = FALSE)
write.csv(data_ges, file = paste0(datasets, "gesDataXGB.csv"), row.names = FALSE)
write.csv(data_ges, file = paste0(datasets, "gesDataXGB.csv"), row.names = FALSE)
# Set seed for reproducibility
set.seed(998)
train_control <- trainControl(
method = "cv",        # Cross-validation
number = 5,           # 5-fold cross-validation
allowParallel = TRUE  # Enable parallel processing
)
# Define the number of subsets
numSubsets <- 5
# Create an empty list to store subsets
gesSubsets <- vector("list", length = numSubsets)
# load MICE imputed data
#gerDataXGB <- read_csv(paste0(datasets, "gerDataXGB.csv"))
gesDataXGB <- data_ges
# ensure percProm is factor
gesDataXGB$correction_info <- as.factor(gesDataXGB$correction_info)
levels(gesDataXGB$correction_info)
# Calculate the number of samples in each subset
subsetSize <- nrow(gesDataXGB) %/% numSubsets
# Randomly assign samples to subsets
for (i in 1:numSubsets) {
if (i < numSubsets) {
gesSubsets[[i]] <- gesDataXGB[sample((1:nrow(gesDataXGB)), size = subsetSize), ]
} else {
gesSubsets[[i]] <- gesDataXGB[sample((1:nrow(gesDataXGB)), size = subsetSize + (nrow(gesDataXGB) %% numSubsets)), ]
}
}
# Naming the subsets
names(gesSubsets) <- paste0("gesData", 1:numSubsets)
# Access the subsets (e.g., gerData1, gerData2, etc.)
gesData1 <- gesSubsets$gesData1
gesData2 <- gesSubsets$gesData2
gesData3 <- gesSubsets$gesData3
gesData4 <- gesSubsets$gesData4
gesData5 <- gesSubsets$gesData5
# Combine subsets into 80% groups.
gesData1234 <- rbind(gesData1, gesData2, gesData3, gesData4)
gesData1235 <- rbind(gesData1, gesData2, gesData3, gesData5)
gesData1245 <- rbind(gesData1, gesData2, gesData4, gesData5)
gesData1345 <- rbind(gesData1, gesData3, gesData4, gesData5)
gesData2345 <- rbind(gesData2, gesData3, gesData4, gesData5)
gesModel1 <- caret::train(
correction_info ~ .,
data = gesData1234,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(gesModel1, file = paste0(models, "gesModel1.rds"), compress = TRUE)
########## folders ##########
# current folder (first go to session -> set working directory -> to source file location)
parentfolder <- dirname(getwd())
processfolder <- paste0(parentfolder, '/TS_processing/')
data          <- paste0(processfolder, '/Datasets/')
datasets      <- paste0(parentfolder, '/XGBoost/datasets/')
models        <- paste0(parentfolder, '/XGBoost/models/')
plots         <- paste0(parentfolder, '/XGBoost/plots/')
scripts       <- paste0(parentfolder, '/XGBoost/scripts/')
########## source file ##########
#source(paste0(scripts, "adjectives-preparation.R"))
#################### packages ####################
# Data Manipulation
library(tibble)
library(stringr)
library(tidyverse) # includes readr, tidyr, dplyr, ggplot2
library(data.table)
# Plotting
library(ggforce)
library(ggpubr)
library(gridExtra)
# Random Forests and XGBoost
library(rpart)
library(rpart.plot)
library(ranger)
library(tuneRanger)
library(caret)
library(xgboost)
library(parallel)
library(mice)
library(doParallel)
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())
colorBlindBlack8  <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
"#F0E442", "#0072B2", "#D55E00", "#CC79A7")
write.csv(data_ges, file = paste0(datasets, "gesDataXGB.csv"), row.names = FALSE)
saveRDS(gesModel1, file = paste0(models, "gesModel1.rds"), compress = TRUE)
gesModel2 <- caret::train(
correction_info ~ .,
data = gesData1235,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(gesModel2, file = paste0(models, "gesModel2.rds"), compress = TRUE)
gesModel3 <- caret::train(
correction_info ~ .,
data = gesData1245,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(gesModel3, file = paste0(models, "gesModel3.rds"), compress = TRUE)
gesModel4 <- caret::train(
correction_info ~ .,
data = gesData1345,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(gesModel4, file = paste0(models, "gesModel4.rds"), compress = TRUE)
gesModel5 <- caret::train(
correction_info ~ .,
data = gesData2345,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(gesModel5, file = paste0(models, "gesModel5.rds"), compress = TRUE)
# Generate predictions
gesPredictions1 <- predict(gesModel1, newdata = gesData5)
gesPredictions2 <- predict(gesModel2, newdata = gesData4)
gesPredictions3 <- predict(gesModel3, newdata = gesData3)
gesPredictions4 <- predict(gesModel4, newdata = gesData2)
gesPredictions5 <- predict(gesModel5, newdata = gesData1)
# Compute confusion matrices
gesCm1 <- confusionMatrix(gesPredictions1, gesData5$correction_info)
gesCm2 <- confusionMatrix(gesPredictions2, gesData4$correction_info)
gesCm3 <- confusionMatrix(gesPredictions3, gesData3$correction_info)
gesCm4 <- confusionMatrix(gesPredictions4, gesData2$correction_info)
gesCm5 <- confusionMatrix(gesPredictions5, gesData1$correction_info)
# Extract p-values (you need to define how to extract these based on your metric, here assumed to be some metric from confusion matrix)
gesPValues <- c(gesCm1$overall['AccuracyPValue'],
gesCm2$overall['AccuracyPValue'],
gesCm3$overall['AccuracyPValue'],
gesCm4$overall['AccuracyPValue'],
gesCm5$overall['AccuracyPValue'])
# Fisher's method
gesFisher_combined <- -2 * sum(log(gesPValues))
df <- 2 * length(gesPValues)
gesPCcombined_fisher <- 1 - pchisq(gesFisher_combined, df)
print(gesPCcombined_fisher)
# Stouffer's method
gesZ_scores <- qnorm(1 - gesPValues/2)
gesCombined_z <- sum(gesZ_scores) / sqrt(length(gesPValues))
gesP_combined_stouffer <- 2 * (1 - pnorm(abs(gesCombined_z)))
print(gesP_combined_stouffer)
xgb.plot.importance(importanceXGBgesModel1)
XGBgesModel1 <- gesModel1$finalModel
importanceXGBgesModel1 <- xgb.importance(model = XGBgesModel1)
print(importanceXGBgesModel1)
xgb.plot.importance(importanceXGBgesModel1)
XGBgesModel2 <- gesModel2$finalModel
importanceXGBgesModel2 <- xgb.importance(model = XGBgesModel2)
print(importanceXGBgesModel2)
xgb.plot.importance(importanceXGBgesModel2)
XGBgerModel3 <- gesModel3$finalModel
importanceXGBgesModel3 <- xgb.importance(model = XGBgesModel3)
XGBgesModel3 <- gesModel3$finalModel
importanceXGBgesModel3 <- xgb.importance(model = XGBgesModel3)
print(importanceXGBgesModel3)
xgb.plot.importance(importanceXGBgesModel3)
XGBgesModel4 <- gesModel4$finalModel
importanceXGBgesModel4 <- xgb.importance(model = XGBgesModel4)
print(importanceXGBgesModel4)
xgb.plot.importance(importanceXGBgesModel4)
XGBgesModel5 <- gesModel5$finalModel
importanceXGBgesModel5 <- xgb.importance(model = XGBgesModel5)
print(importanceXGBgesModel5)
xgb.plot.importance(importanceXGBgesModel5)
# Function to extract and normalize importance
get_normalized_importance <- function(model) {
importance <- xgb.importance(model = model)
importance$Gain <- importance$Gain / sum(importance$Gain)
return(importance)
}
# Extract normalized importance for each model
gesImportance1 <- get_normalized_importance(gesModel1$finalModel)
gesImportance2 <- get_normalized_importance(gesModel2$finalModel)
gesImportance3 <- get_normalized_importance(gesModel3$finalModel)
gesImportance4 <- get_normalized_importance(gesModel4$finalModel)
gesImportance5 <- get_normalized_importance(gesModel5$finalModel)
# Combine importances
gesAllImportances <- list(gesImportance1, gesImportance2, gesImportance3, gesImportance4, gesImportance5)
# Function to merge importances
merge_importances <- function(importances) {
for (i in 2:length(importances)) {
names(importances[[i]])[2:4] <- paste0(names(importances[[i]])[2:4], "_", i)
}
merged <- Reduce(function(x, y) merge(x, y, by = "Feature", all = TRUE), importances)
merged[is.na(merged)] <- 0  # Replace NAs with 0
gain_cols <- grep("Gain", colnames(merged), value = TRUE)
merged$Cumulative <- rowSums(merged[, ..gain_cols])
return(merged[, .(Feature, Cumulative)])
}
# Merge and sort importances
gesCumulativeImportance <- merge_importances(gesAllImportances)
gesCumulativeImportance <- gesCumulativeImportance[order(-gesCumulativeImportance$Cumulative), ]
# Print cumulative feature importance
print(gesCumulativeImportance)
